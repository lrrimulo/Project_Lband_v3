"""
This is the main program of the L-band project. 
"""

import sys
import numpy as np
import pyhdust.phc as phc
import pyhdust.spectools as spt
import pyhdust.lrr as lrr
import matplotlib.pyplot as plt
import emcee
import corner as corner
import glob as glob
import read_data as read_data
import read_everything as read_everything


#############################
### This is the zeroth part of the analysis: reading everything (or almost!).
### We will read the observables calculated from the SED's (which were calculated 
### in another program, because this task takes time) and we will
### also read the available observational data on the Be stars.
### With this data, it is possible to make the analysis intended by this 
### program.

#############################
### Full name of the file containing the observables generated from 
### HDUST's output. 
### (This file was generated by 'observables_OldBeAtlas.py'.)
fileobservables = "observables_BeAtlas.inp" 

### Reading that file.
g0 = open(fileobservables,'r')
g0linhas = g0.readlines()
g0.close()
### Splitting the contents of each line (to be used below).
for ilinha in range(0,len(g0linhas)):
    g0linhas[ilinha] = g0linhas[ilinha].split()

### Declaring the lists that will receive the different observables. 
### This is a preliminary step, before making the arrays for each observable.

### The lists of observables of 4 model parameters
### (n, Sig, M, ob)
TEMP_read = []
SOURCE_read = []

### The lists of observables of the 4 model parameters + cosi
SNRATIOS_read = []
###    
VSINI_read = []
### 
UBVRI_read = []; poldegUBVRI_read = []
JHK_read = []; poldegJHK_read = []
HALPHA_SOAR_read = []; poldegHALPHA_SOAR_read = []
WISE_filters_read = []; poldegWISE_filters_read = []
ALPHA_WISE_read = []
IRAC_filters_read = []; poldegIRAC_filters_read = []
### 
LINE_HALPHA_read = []
LINE_HBETA_read = []
LINE_HGAMMA_read = []    
###
LINE_BRALPHA_read = []   
LINE_BRGAMMA_read = []    
### 
LINE_PFGAMMA_read = []    
###
LINE_HUMPHREY14_read = []
LINE_HUMPHREY15_read = []
LINE_HUMPHREY16_read = []
LINE_HUMPHREY18_read = []
LINE_HUMPHREY19_read = []
LINE_HUMPHREY20_read = []
LINE_HUMPHREY21_read = []
LINE_HUMPHREY22_read = []
LINE_HUMPHREY23_read = []
LINE_HUMPHREY24_read = []
LINE_HUMPHREY25_read = []
###
BL_FLUX_read = []    
RL_FLUX_read = []    


### Filling the lists with the data from the file

MODEL_key = 0 ### will be equal to 1 when in the subfolder of some model.
COSI_key = 0  ### will be equal to 1 when in the subfolder of some cosi.
for ilinha in range(0,len(g0linhas)):
    ### Check if entering a new model. If yes, read the model's parameters.
    if g0linhas[ilinha][0] == "MODEL" and MODEL_key == 0:
        current_MODEL = [g0linhas[ilinha][ii] for ii in range(1,5)]
        MODEL_key = 1
    ### Check if entering a SOURCE line. If yes, read the source parameters.
    if g0linhas[ilinha][0] == "SOURCE" and MODEL_key == 1:
        ### 'SOURCE_read' will receive a new element composed of 2 lists:
        ### 0: model parameters (not including cosi)
        ### 1: elements of 'SOURCE_read'
        current_SOURCE = [g0linhas[ilinha][ii] for ii in range(1,6)]
        SOURCE_read.append([current_MODEL,current_SOURCE])
        #print(SOURCE_read[-1])
    ### Check if entering the two TEMP_R and TEMP_T lines.
    ### If yes, read these parameters.
    if g0linhas[ilinha][0] == "TEMP_R" and MODEL_key == 1:
        ### 'TEMP_read' will receive a new element composed of 3 lists:
        ### 0: model parameters (not including cosi)
        ### 1: radial distances in the plane of the disk (R/Req)
        ### 2: temperatures of the disk [K]
        current_TEMP_R = [g0linhas[ilinha][ii] \
            for ii in range(1,len(g0linhas[ilinha]))]
        current_TEMP_T = [g0linhas[ilinha+1][ii] \
            for ii in range(1,len(g0linhas[ilinha+1]))]
        TEMP_read.append([current_MODEL,current_TEMP_R,current_TEMP_T])
    ### Check if entering a new cosi. If yes, read the cosi.
    if g0linhas[ilinha][0] == "COSI" and MODEL_key == 1 and COSI_key == 0:
        ### For a certain model, entering a new inclination (cosi)
        current_COSI = g0linhas[ilinha][1]
        COSI_key = 1
        
    
    def reading_procedure(lista,linename,Nelems):
        """
        This procedure attributes elements to 'lista', according to the 
        chosen 'linename'.
        """
        ### Check if entering a new 'linename'. 
        if g0linhas[ilinha][0] == linename and COSI_key == 1:
            ### 'lista' will receive a new element composed of 2 lists:
            ### 0: model parameters (including cosi)
            ### 1: elements of 'lista'
            auxi = [current_MODEL[ii] for ii in range(0,len(current_MODEL))]
            auxi.append(current_COSI)
            auxi2 = [g0linhas[ilinha][ii] for ii in range(1,Nelems)]
            lista.append([auxi,auxi2])
        return 

    ### 
    reading_procedure(SNRATIOS_read,"SNRATIOS",len(g0linhas[ilinha]))
    ###
    reading_procedure(VSINI_read,"VSINI",1+1)
    ### 
    reading_procedure(UBVRI_read,"UBVRI",1+5)
    reading_procedure(poldegUBVRI_read,"poldegUBVRI",1+5)
    reading_procedure(JHK_read,"JHK",1+3)
    reading_procedure(poldegJHK_read,"poldegJHK",1+3)
    reading_procedure(HALPHA_SOAR_read,"HALPHA_SOAR",1+1)
    reading_procedure(poldegHALPHA_SOAR_read,"poldegHALPHA_SOAR",1+1)
    reading_procedure(WISE_filters_read,"WISE_filters",1+4)
    reading_procedure(poldegWISE_filters_read,"poldegWISE_filters",1+4)
    reading_procedure(ALPHA_WISE_read,"ALPHA_WISE",1+3)
    reading_procedure(IRAC_filters_read,"IRAC_filters",1+4)
    reading_procedure(poldegIRAC_filters_read,"poldegIRAC_filters",1+4)
    ###
    reading_procedure(LINE_HALPHA_read,"LINE_HALPHA",1+5)
    reading_procedure(LINE_HBETA_read,"LINE_HBETA",1+5)
    reading_procedure(LINE_HGAMMA_read,"LINE_HGAMMA",1+5)    
    ###
    reading_procedure(LINE_BRALPHA_read,"LINE_BRALPHA",1+5)
    reading_procedure(LINE_BRGAMMA_read,"LINE_BRGAMMA",1+5)    
    ###
    reading_procedure(LINE_PFGAMMA_read,"LINE_PFGAMMA",1+5)    
    ###
    reading_procedure(LINE_HUMPHREY14_read,"LINE_HUMPHREY14",1+5)
    reading_procedure(LINE_HUMPHREY15_read,"LINE_HUMPHREY15",1+5)
    reading_procedure(LINE_HUMPHREY16_read,"LINE_HUMPHREY16",1+5)
    reading_procedure(LINE_HUMPHREY18_read,"LINE_HUMPHREY18",1+5)
    reading_procedure(LINE_HUMPHREY19_read,"LINE_HUMPHREY19",1+5)
    reading_procedure(LINE_HUMPHREY20_read,"LINE_HUMPHREY20",1+5)
    reading_procedure(LINE_HUMPHREY21_read,"LINE_HUMPHREY21",1+5)
    reading_procedure(LINE_HUMPHREY22_read,"LINE_HUMPHREY22",1+5)
    reading_procedure(LINE_HUMPHREY23_read,"LINE_HUMPHREY23",1+5)
    reading_procedure(LINE_HUMPHREY24_read,"LINE_HUMPHREY24",1+5)
    reading_procedure(LINE_HUMPHREY25_read,"LINE_HUMPHREY25",1+5)
    ###
    reading_procedure(BL_FLUX_read,"BL_FLUX",1+3)    
    reading_procedure(RL_FLUX_read,"RL_FLUX",1+3)    

    ### Check if finishing the cosi subfolder
    if g0linhas[ilinha][0] == "END_COSI" and COSI_key == 1:
        COSI_key = 0
    ### Check if finishing the model subfolder
    if g0linhas[ilinha][0] == "END_MODEL" and MODEL_key == 1:
        MODEL_key = 0





### The domain of the grids:
npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()


### Now, creating the arrays for the observables of 4+1 model parameters
### The arrays will be functions of: (i_n, i_Sig, i_M, i_ob, i_cosi, #)

def attribution_procedure5(lista_read,Nelems):
    """
    This function creates the 6-array associated with the 'lista_read' 
    given. (5 of these dimensions are the 5 dimensions of the BeAtlas grid.)
    """
    
    array = np.zeros((len(npar),len(sigpar),len(Mpar),len(obpar),\
            len(cosipar),Nelems))
    array[:] = np.nan

    if len(lista_read) > 0:
        
        exc_list = read_everything.exclude_models()

        for i in range(0,len(lista_read)):
            idxnpar = npar.index(lista_read[i][0][0])
            idxsigpar = sigpar.index(lista_read[i][0][1])
            idxMpar = Mpar.index(lista_read[i][0][2])
            idxobpar = obpar.index(lista_read[i][0][3])
            idxcosipar = cosipar.index(lista_read[i][0][4])
            
            if [npar[idxnpar],sigpar[idxsigpar],\
                    Mpar[idxMpar],obpar[idxobpar],\
                    cosipar[idxcosipar]] not in exc_list:
                for j in range(0,Nelems):
                    array[idxnpar,idxsigpar,idxMpar,idxobpar,idxcosipar,j] = \
                        float(lista_read[i][1][j])
            else:
                for j in range(0,Nelems):
                    array[idxnpar,idxsigpar,idxMpar,idxobpar,idxcosipar,j] = \
                        np.nan
                    
    return array
    
    
    
### 
if len(SNRATIOS_read) > 0:
    SNRATIOS = attribution_procedure5(SNRATIOS_read,len(SNRATIOS_read[0][1]))
else:
    SNRATIOS = attribution_procedure5(SNRATIOS_read,0)
### 
VSINI = attribution_procedure5(VSINI_read,1)
### 
UBVRI = attribution_procedure5(UBVRI_read,5)
poldegUBVRI = attribution_procedure5(poldegUBVRI_read,5)
JHK = attribution_procedure5(JHK_read,3)
poldegJHK = attribution_procedure5(poldegJHK_read,3)
HALPHA_SOAR = attribution_procedure5(HALPHA_SOAR_read,1)
poldegHALPHA_SOAR = attribution_procedure5(poldegHALPHA_SOAR_read,1)
WISE = attribution_procedure5(WISE_filters_read,4)
poldegWISE = attribution_procedure5(poldegWISE_filters_read,4)
ALPHA_WISE = attribution_procedure5(ALPHA_WISE_read,3)
IRAC = attribution_procedure5(IRAC_filters_read,4)
poldegIRAC = attribution_procedure5(poldegIRAC_filters_read,4)
###
LINE_HALPHA = attribution_procedure5(LINE_HALPHA_read,5)
LINE_HBETA = attribution_procedure5(LINE_HBETA_read,5)
LINE_HGAMMA = attribution_procedure5(LINE_HGAMMA_read,5)
###
LINE_BRGAMMA = attribution_procedure5(LINE_BRGAMMA_read,5)
###
LINE_BRALPHA = attribution_procedure5(LINE_BRALPHA_read,5)
###
LINE_PFGAMMA = attribution_procedure5(LINE_PFGAMMA_read,5)
###
LINE_HUMPHREY14 = attribution_procedure5(LINE_HUMPHREY14_read,5)
LINE_HUMPHREY15 = attribution_procedure5(LINE_HUMPHREY15_read,5)
LINE_HUMPHREY16 = attribution_procedure5(LINE_HUMPHREY16_read,5)
LINE_HUMPHREY18 = attribution_procedure5(LINE_HUMPHREY18_read,5)
LINE_HUMPHREY19 = attribution_procedure5(LINE_HUMPHREY19_read,5)
LINE_HUMPHREY20 = attribution_procedure5(LINE_HUMPHREY20_read,5)
LINE_HUMPHREY21 = attribution_procedure5(LINE_HUMPHREY21_read,5)
LINE_HUMPHREY22 = attribution_procedure5(LINE_HUMPHREY22_read,5)
LINE_HUMPHREY23 = attribution_procedure5(LINE_HUMPHREY23_read,5)
LINE_HUMPHREY24 = attribution_procedure5(LINE_HUMPHREY24_read,5)
LINE_HUMPHREY25 = attribution_procedure5(LINE_HUMPHREY25_read,5)
###
BL_FLUX = attribution_procedure5(BL_FLUX_read,3)
RL_FLUX = attribution_procedure5(RL_FLUX_read,3)

### A few derived quantities:
### Obtaining alphaL
ALPHAL = read_data.alphaL(BL_FLUX[:,:,:,:,:,0],\
            BL_FLUX[:,:,:,:,:,1],BL_FLUX[:,:,:,:,:,2],\
            RL_FLUX[:,:,:,:,:,0],\
            RL_FLUX[:,:,:,:,:,1],RL_FLUX[:,:,:,:,:,2])
### Vega fluxes in the regions defined by Mennickent et al. 2009.
FBL_Vega = read_data.Vegaflux(3.41,3.47,Nnpts = 50)
FRL_Vega = read_data.Vegaflux(3.93,4.00,Nnpts = 50)
### Absolute magnitudes associated with Mennickent's fluxes
MBL = read_data.ap_mag_Menn(BL_FLUX[:,:,:,:,:,0],FBL_Vega)
MRL = read_data.ap_mag_Menn(RL_FLUX[:,:,:,:,:,0],FRL_Vega)


### Attribution procedure for the TEMP_T (assuming that all TEMP_R are equal)
def attribution_procedure4(lista_read,Nelems):
    """
    This function creates the 5-array associated with the 'lista_read' 
    given. (4 of these dimensions are the 5-1 
    dimensions of the BeAtlas grid, minus cosi.)
    """
    
    array = np.zeros((len(npar),len(sigpar),len(Mpar),len(obpar),Nelems))
    array[:] = np.nan

    if len(lista_read) > 0:

        for i in range(0,len(lista_read)):
            idxnpar = npar.index(lista_read[i][0][0])
            idxsigpar = sigpar.index(lista_read[i][0][1])
            idxMpar = Mpar.index(lista_read[i][0][2])
            idxobpar = obpar.index(lista_read[i][0][3])

            for j in range(0,Nelems):
                array[idxnpar,idxsigpar,idxMpar,idxobpar,j] = np.nan
            for j in range(0,len(lista_read[i][1])):
                array[idxnpar,idxsigpar,idxMpar,idxobpar,j] = \
                    float(lista_read[i][1][j])
                    
    return array

### 
SOURCE = attribution_procedure4(SOURCE_read,5)
### TEMP_read.append([current_MODEL,current_TEMP_R,current_TEMP_T])
TEMP_R_read = [[elem[0],elem[1]] for elem in TEMP_read]
TEMP_T_read = [[elem[0],elem[2]] for elem in TEMP_read]

elemm = [np.nan, np.nan]
ielemm = 0
while np.isnan(float(elemm[0])) and np.isnan(float(elemm[1])) \
        and ielemm < len(TEMP_R_read):
    elemm = TEMP_R_read[ielemm][1]
    ielemm += 1

TEMP_R = np.array([float(x) for x in elemm])


Nelems = len(TEMP_R)
TEMP_T = attribution_procedure4(TEMP_T_read,Nelems)






### 
def fillingNaNs(folder_filledNaNs,nameval,axis,vals,tp,\
            allow_extrapolation,prints,overwrite = False):
    """
    This function applies the "powerful interpolation" in order to fill
    some or all of the NaNs in the 'vals' vector, but only if there isn't
    an already saved correspondent file in folder 'folder_filledNaNs'.
    
    The output of this function is a new 'vals' vector, with some of its 
    NaNs filled by the "powerful interpolation".
    """

    ### 
    list_filledNaNs = glob.glob(folder_filledNaNs + "*")
    
    ### 'found_fileNaN' will be True if there is a file with the same name
    ### as 'nameval' in the folder 'folder_filledNaNs'. If this isn't the case
    ### or if 'overwrite' is True, the filling the NaNs procedure will be 
    ### activated and, after that, the file with the calculated 'vals' will be 
    ### created. If, however, this is the case (else), the 'vals' will 
    ### be read from the external file.
    found_fileNaN = True in [folder_filledNaNs + nameval == \
                        x.replace(".inp","") for x in list_filledNaNs]
    if not found_fileNaN or overwrite:
        if prints != "no":
            print("FILLING THE NANS PROCEDURE FOR "+nameval)
            print("    (This may take some time!)")
        ### 
        vals = lrr.fill_NaNs_interp(axis,\
                vals,\
                tp,allow_extrapolation,prints)
        ### 
        f0 = open(folder_filledNaNs + nameval + ".inp","w")
        for elem in vals:
            f0.write(str(elem)+"\n")        
        f0.close()        
    ### 
    else:
        ### 
        f0 = open(folder_filledNaNs + nameval + ".inp","r")
        f0linhas = f0.readlines()
        f0.close()
        ### 
        vals = []
        for iline in range(0,len(f0linhas)):
            vals.append(float(f0linhas[iline]))

    return vals








#############################
### Central wavelength of each line [microns]
LINE_HALPHA_lbd = spt.hydrogenlinewl(3, 2)*1e6
LINE_HBETA_lbd = spt.hydrogenlinewl(4, 2)*1e6
LINE_HGAMMA_lbd = spt.hydrogenlinewl(5, 2)*1e6
LINE_BRGAMMA_lbd = spt.hydrogenlinewl(7, 4)*1e6
LINE_BRALPHA_lbd = spt.hydrogenlinewl(5, 4)*1e6
LINE_PFGAMMA_lbd = spt.hydrogenlinewl(8, 5)*1e6
LINE_HUMPHREY14_lbd = spt.hydrogenlinewl(14, 6)*1e6
LINE_HUMPHREY15_lbd = spt.hydrogenlinewl(15, 6)*1e6
LINE_HUMPHREY16_lbd = spt.hydrogenlinewl(16, 6)*1e6
LINE_HUMPHREY18_lbd = spt.hydrogenlinewl(18, 6)*1e6
LINE_HUMPHREY19_lbd = spt.hydrogenlinewl(19, 6)*1e6
LINE_HUMPHREY20_lbd = spt.hydrogenlinewl(20, 6)*1e6
LINE_HUMPHREY21_lbd = spt.hydrogenlinewl(21, 6)*1e6
LINE_HUMPHREY22_lbd = spt.hydrogenlinewl(22, 6)*1e6
LINE_HUMPHREY23_lbd = spt.hydrogenlinewl(23, 6)*1e6
LINE_HUMPHREY24_lbd = spt.hydrogenlinewl(24, 6)*1e6
LINE_HUMPHREY25_lbd = spt.hydrogenlinewl(25, 6)*1e6









###########
if 1==1:

    ### The domain of the grids:
    npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
    ### Converting strings to float
    npar_vals = np.array([float(x) for x in npar])
    logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
            for x in sigpar])
    Mpar_vals = np.array([float(x) for x in Mpar])
    obpar_vals = np.array([float(x) for x in obpar])
    cosipar_vals = np.array([float(x) for x in cosipar])

    ### Defining the domain of the grid
    axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
    ndim = len(axis)

    ### Attributing values for every element of the grid
    vals_B = []
    vals_V = []
    vals_R = []
    vals_I = []
    vals_poldegB = []
    vals_poldegV = []
    vals_poldegR = []
    vals_poldegI = []
    vals_J = []
    vals_H = []
    vals_K = []
    vals_vsini = []
    vals_alphaW1W2 = []
    vals_alphaW2W3 = []
    vals_alphaW3W4 = []
    vals_MW1 = []
    vals_MW2 = []
    vals_MW3 = []
    vals_MW4 = []
    vals_MIRAC1 = []
    vals_MIRAC2 = []
    vals_MIRAC3 = []
    vals_MIRAC4 = []
    vals_alphaL = []
    vals_MBL = []
    vals_Halpha = []; vals_FWHMHalpha = []; vals_EWHalpha = []; vals_PSHalpha = []
    vals_Hu14 = []; vals_FWHMHu14 = []
    vals_Hu15 = []; vals_FWHMHu15 = []
    vals_Hu16 = []; vals_FWHMHu16 = []
    #vals_Hu17 = []; vals_FWHMHu17 = []
    vals_Hu18 = []; vals_FWHMHu18 = []
    vals_Hu19 = []; vals_FWHMHu19 = []
    vals_Hu20 = []; vals_FWHMHu20 = []
    vals_Hu21 = []; vals_FWHMHu21 = []
    vals_Hu22 = []; vals_FWHMHu22 = []
    vals_Hu23 = []; vals_FWHMHu23 = []
    vals_Hu24 = []; vals_FWHMHu24 = []
    vals_Hu25 = []; vals_FWHMHu25 = []
    vals_Bra = []
    vals_Pfg = []
    vals_FBL = []
    i4 = obpar.index("1.40")
    for i1 in range(0,len(npar_vals)):
        for i2 in range(0,len(logsigpar_vals)):
            for i3 in range(0,len(Mpar_vals)):
                #for i4_notused in range(0,len(obpar_vals)):
                for i4 in range(0,len(obpar_vals)):
                    for i5 in range(0,len(cosipar_vals)):
                        vals_B.append(UBVRI[i1,i2,i3,i4,i5,1])
                        vals_V.append(UBVRI[i1,i2,i3,i4,i5,2])
                        vals_R.append(UBVRI[i1,i2,i3,i4,i5,3])
                        vals_I.append(UBVRI[i1,i2,i3,i4,i5,4])
                        vals_poldegB.append(poldegUBVRI[i1,i2,i3,i4,i5,1])
                        vals_poldegV.append(poldegUBVRI[i1,i2,i3,i4,i5,2])
                        vals_poldegR.append(poldegUBVRI[i1,i2,i3,i4,i5,3])
                        vals_poldegI.append(poldegUBVRI[i1,i2,i3,i4,i5,4])
                        vals_J.append(JHK[i1,i2,i3,i4,i5,0])
                        vals_H.append(JHK[i1,i2,i3,i4,i5,1])
                        vals_K.append(JHK[i1,i2,i3,i4,i5,2])
                        vals_vsini.append(VSINI[i1,i2,i3,i4,i5,0])
                        vals_alphaW1W2.append(ALPHA_WISE[i1,i2,i3,i4,i5,0])
                        vals_alphaW2W3.append(ALPHA_WISE[i1,i2,i3,i4,i5,1])
                        vals_alphaW3W4.append(ALPHA_WISE[i1,i2,i3,i4,i5,2])
                        vals_MW1.append(WISE[i1,i2,i3,i4,i5,0])
                        vals_MW2.append(WISE[i1,i2,i3,i4,i5,1])
                        vals_MW3.append(WISE[i1,i2,i3,i4,i5,2])
                        vals_MW4.append(WISE[i1,i2,i3,i4,i5,3])
                        vals_MIRAC1.append(IRAC[i1,i2,i3,i4,i5,0])
                        vals_MIRAC2.append(IRAC[i1,i2,i3,i4,i5,1])
                        vals_MIRAC3.append(IRAC[i1,i2,i3,i4,i5,2])
                        vals_MIRAC4.append(IRAC[i1,i2,i3,i4,i5,3])
                        vals_alphaL.append(ALPHAL[i1,i2,i3,i4,i5])
                        vals_MBL.append(MBL[i1,i2,i3,i4,i5])
                        vals_Halpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,0])
                        vals_EWHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,1])
                        vals_PSHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,2])
                        vals_FWHMHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,3])
                        vals_Hu14.append(LINE_HUMPHREY14[i1,i2,i3,i4,i5,0])
                        vals_Hu15.append(LINE_HUMPHREY15[i1,i2,i3,i4,i5,0])
                        vals_Hu16.append(LINE_HUMPHREY16[i1,i2,i3,i4,i5,0])
                        #vals_Hu17.append(LINE_HUMPHREY17[i1,i2,i3,i4,i5,0])
                        vals_Hu18.append(LINE_HUMPHREY18[i1,i2,i3,i4,i5,0])
                        vals_Hu19.append(LINE_HUMPHREY19[i1,i2,i3,i4,i5,0])
                        vals_Hu20.append(LINE_HUMPHREY20[i1,i2,i3,i4,i5,0])
                        vals_Hu21.append(LINE_HUMPHREY21[i1,i2,i3,i4,i5,0])
                        vals_Hu22.append(LINE_HUMPHREY22[i1,i2,i3,i4,i5,0])
                        vals_Hu23.append(LINE_HUMPHREY23[i1,i2,i3,i4,i5,0])
                        vals_Hu24.append(LINE_HUMPHREY24[i1,i2,i3,i4,i5,0])
                        vals_Hu25.append(LINE_HUMPHREY25[i1,i2,i3,i4,i5,0])
                        #vals_FWHMHu14.append(LINE_HUMPHREY14[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu15.append(LINE_HUMPHREY15[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu16.append(LINE_HUMPHREY16[i1,i2,i3,i4,i5,3])
                        ##vals_FWHMHu17.append(LINE_HUMPHREY17[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu18.append(LINE_HUMPHREY18[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu19.append(LINE_HUMPHREY19[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu20.append(LINE_HUMPHREY20[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu21.append(LINE_HUMPHREY21[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu22.append(LINE_HUMPHREY22[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu23.append(LINE_HUMPHREY23[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu24.append(LINE_HUMPHREY24[i1,i2,i3,i4,i5,3])
                        #vals_FWHMHu25.append(LINE_HUMPHREY25[i1,i2,i3,i4,i5,3])
                        vals_Bra.append(LINE_BRALPHA[i1,i2,i3,i4,i5,0])
                        vals_Pfg.append(LINE_PFGAMMA[i1,i2,i3,i4,i5,0])
                        vals_FBL.append(BL_FLUX[i1,i2,i3,i4,i5,0])
                
                
                            
    ### Turn this on to fill the NaNs in the values (probably due to 
    ### the fact that the grid was not entirely computed).
    if 1==1:
        ### folder for printing the results
        folder_filledNaNs = "./extrap03/"
        ### Below, "yes" means printing the progress of the 
        ### filling NaNs procedure
        prints = "yes"
        ### 
        tp = "linear"
        ### Allowing extrapolation for the filling the NaNs procedure
        allow_extrapolation_fill = "yes"
        
        ### filling the NaNs of XXXX
        def filling_NaNs_XXXX(vals_XXXX,vals_XXXX_name):
            
            vals_XXXX = fillingNaNs(folder_filledNaNs,\
                    vals_XXXX_name,axis,\
                    vals_XXXX,\
                    tp,allow_extrapolation_fill,prints,overwrite = False)
            
            return vals_XXXX
        
        ### Execution...
        vals_B = filling_NaNs_XXXX(vals_B,"vals_B")
        vals_V = filling_NaNs_XXXX(vals_V,"vals_V")
        vals_R = filling_NaNs_XXXX(vals_R,"vals_R")
        vals_I = filling_NaNs_XXXX(vals_I,"vals_I")
        vals_poldegB = filling_NaNs_XXXX(vals_poldegB,"vals_poldegB")
        vals_poldegV = filling_NaNs_XXXX(vals_poldegV,"vals_poldegV")
        vals_poldegR = filling_NaNs_XXXX(vals_poldegR,"vals_poldegR")
        vals_poldegI = filling_NaNs_XXXX(vals_poldegI,"vals_poldegI")
        vals_J = filling_NaNs_XXXX(vals_J,"vals_J")
        vals_H = filling_NaNs_XXXX(vals_H,"vals_H")
        vals_K = filling_NaNs_XXXX(vals_K,"vals_K")
        vals_vsini = filling_NaNs_XXXX(vals_vsini,"vals_vsini")
        vals_alphaW1W2 = filling_NaNs_XXXX(vals_alphaW1W2,"vals_alphaW1W2")
        vals_alphaW2W3 = filling_NaNs_XXXX(vals_alphaW2W3,"vals_alphaW2W3")
        vals_alphaW3W4 = filling_NaNs_XXXX(vals_alphaW3W4,"vals_alphaW3W4")
        vals_MW1 = filling_NaNs_XXXX(vals_MW1,"vals_MW1")
        vals_MW2 = filling_NaNs_XXXX(vals_MW2,"vals_MW2")
        vals_MW3 = filling_NaNs_XXXX(vals_MW3,"vals_MW3")
        vals_MW4 = filling_NaNs_XXXX(vals_MW4,"vals_MW4")
        vals_MIRAC1 = filling_NaNs_XXXX(vals_MIRAC1,"vals_MIRAC1")
        vals_MIRAC2 = filling_NaNs_XXXX(vals_MIRAC2,"vals_MIRAC2")
        vals_MIRAC3 = filling_NaNs_XXXX(vals_MIRAC3,"vals_MIRAC3")
        vals_MIRAC4 = filling_NaNs_XXXX(vals_MIRAC4,"vals_MIRAC4")
        vals_alphaL = filling_NaNs_XXXX(vals_alphaL,"vals_alphaL")
        vals_MBL = filling_NaNs_XXXX(vals_MBL,"vals_MBL")
        vals_Halpha = filling_NaNs_XXXX(vals_Halpha,"vals_Halpha")
        vals_EWHalpha = filling_NaNs_XXXX(vals_EWHalpha,"vals_EWHalpha")
        vals_PSHalpha = filling_NaNs_XXXX(vals_PSHalpha,"vals_PSHalpha")
        vals_FWHMHalpha = filling_NaNs_XXXX(vals_FWHMHalpha,"vals_FWHMHalpha")
        vals_Hu14 = filling_NaNs_XXXX(vals_Hu14,"vals_Hu14")
        vals_Hu15 = filling_NaNs_XXXX(vals_Hu15,"vals_Hu15")
        vals_Hu16 = filling_NaNs_XXXX(vals_Hu16,"vals_Hu16")
        #vals_Hu17 = filling_NaNs_XXXX(vals_Hu17,"vals_Hu17")
        vals_Hu18 = filling_NaNs_XXXX(vals_Hu18,"vals_Hu18")
        vals_Hu19 = filling_NaNs_XXXX(vals_Hu19,"vals_Hu19")
        vals_Hu20 = filling_NaNs_XXXX(vals_Hu20,"vals_Hu20")
        vals_Hu21 = filling_NaNs_XXXX(vals_Hu21,"vals_Hu21")
        vals_Hu22 = filling_NaNs_XXXX(vals_Hu22,"vals_Hu22")
        vals_Hu23 = filling_NaNs_XXXX(vals_Hu23,"vals_Hu23")
        vals_Hu24 = filling_NaNs_XXXX(vals_Hu24,"vals_Hu24")
        vals_Hu25 = filling_NaNs_XXXX(vals_Hu25,"vals_Hu25")
        #vals_FWHMHu14 = filling_NaNs_XXXX(vals_FWHMHu14,"vals_FWHMHu14")
        #vals_FWHMHu15 = filling_NaNs_XXXX(vals_FWHMHu15,"vals_FWHMHu15")
        #vals_FWHMHu16 = filling_NaNs_XXXX(vals_FWHMHu16,"vals_FWHMHu16")
        ##vals_FWHMHu17 = filling_NaNs_XXXX(vals_FWHMHu17,"vals_FWHMHu17")
        #vals_FWHMHu18 = filling_NaNs_XXXX(vals_FWHMHu18,"vals_FWHMHu18")
        #vals_FWHMHu19 = filling_NaNs_XXXX(vals_FWHMHu19,"vals_FWHMHu19")
        #vals_FWHMHu20 = filling_NaNs_XXXX(vals_FWHMHu20,"vals_FWHMHu20")
        #vals_FWHMHu21 = filling_NaNs_XXXX(vals_FWHMHu21,"vals_FWHMHu21")
        #vals_FWHMHu22 = filling_NaNs_XXXX(vals_FWHMHu22,"vals_FWHMHu22")
        #vals_FWHMHu23 = filling_NaNs_XXXX(vals_FWHMHu23,"vals_FWHMHu23")
        #vals_FWHMHu24 = filling_NaNs_XXXX(vals_FWHMHu24,"vals_FWHMHu24")
        #vals_FWHMHu25 = filling_NaNs_XXXX(vals_FWHMHu25,"vals_FWHMHu25")
        vals_Bra = filling_NaNs_XXXX(vals_Bra,"vals_Bra")
        vals_Pfg = filling_NaNs_XXXX(vals_Pfg,"vals_Pfg")
        vals_FBL = filling_NaNs_XXXX(vals_FBL,"vals_FBL")


























##########################################################
### The list DATA_LBAND will contain important parameters derived from the 
### observables of our stars. Check the program 'read_data.py' to know the 
### contents of DATA_LBAND.
DATA_LBAND = read_data.returnDATA_LBAND()
### 
fluxhumphreys, EWhumphreys, GFWHMhumphreys, \
fluxBra, EWBra, GFWHMBra, \
fluxPfg, EWPfg, GFWHMPfg = read_data.LBAND_lines_extract(DATA_LBAND)


### If you want to make the tables of data for the paper, turn this on:
if 1==1:
    lixo = read_data.make_table_obs1(DATA_LBAND,"./tables/table_obs1.out")
    lixo = read_data.make_table_obs2(DATA_LBAND,"./tables/table_obs2.out")
    lixo = read_data.make_bigtables_obs(DATA_LBAND,"./tables/bigtables_obs.out")
    
    #print(read_data.Vegaflux(3.41,3.47)/(3.47e4-3.41e4))
    #print(read_data.Vegaflux(3.93,4.00)/(4.00e4-3.93e4))
    



if 1==2:
    
    from scipy.optimize import curve_fit
    
    def linear_funct(x,A):
        
        return 1.+A*x
    
    xplt = []
    yplt = []
    for ifile in range(0,len(fluxhumphreys)):

        num19 = 19
        lambdass = [spt.hydrogenlinewl(i, 6)*1e10 for i in range(14,26)]
        lambda19 = spt.hydrogenlinewl(num19, 6)*1e10    

        fluxrr = [fluxhumphreys[ifile][i,0]/fluxhumphreys[ifile][num19,0] \
                for i in range(14,26)]
        auxif = []
        auxil = []
        for ifl in range(0,len(fluxrr)):
            if ~np.isnan(fluxrr[ifl]):
                auxil.append(lambdass[ifl])
                auxif.append(fluxrr[ifl])
        if len(auxil) > 0:
            lambdass = [x for x in auxil]
            fluxrr = [x for x in auxif]
        
                
        
            popt, pcov = curve_fit(linear_funct, \
                    [x-lambda19 for x in lambdass],fluxrr,p0=[0.])
    

            xplt.append(np.arcsinh(popt[0]*(lambdass[0]-lambda19)))
            yplt.append(np.arcsinh(2e4/DATA_LBAND[ifile][7][1][0]))
            #yplt.append(DATA_LBAND[ifile][10][0])
            #yplt.append(DATA_LBAND[ifile][9])
            #yplt.append(DATA_LBAND[ifile][5][3][0])
            
            plt.annotate("HD "+DATA_LBAND[ifile][0],[xplt[-1],yplt[-1]])

    plt.scatter(xplt,yplt)
    plt.show()
            
    import sys; sys.exit()



if 1==2:

    xxx = [x[10][0] for x in DATA_LBAND]
    yyy = [x[9] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("EW$/\lambda$")
    plt.ylabel("$v\sin i\,[\\mathrm{km\,s^{-1}}]$")
    plt.show()
    
    xxx = [x[6][5][4] for x in DATA_LBAND]
    yyy = [2e4/x[7][0][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("$M_{W3}$")
    plt.ylabel("$\\arcsinh(2\\times 10^4 \\tau_0^{-1})$")
    plt.show()

    xxx = [x[5][3][0] for x in DATA_LBAND]
    yyy = [2e4/x[7][1][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("$M_{B_L}$")
    plt.ylabel("$\\arcsinh(2\\times 10^4 \\tau_1^{-1})$")
    plt.show()
    
    xxx = [x[5][3][0] for x in DATA_LBAND]
    yyy = [x[10][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("$M_{B_L}$")
    plt.ylabel("EW$/\lambda$")
    plt.show()

    xxx = [x[5][4][0] for x in DATA_LBAND]
    yyy = [x[10][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("$\\alpha_L$")
    plt.ylabel("EW$/\lambda$")
    plt.show()

    xxx = [x[10][0] for x in DATA_LBAND]
    yyy = [2e4/x[7][1][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("EW$/\lambda$")
    plt.ylabel("$\\arcsinh(2\\times 10^4 \\tau_1^{-1})$")
    plt.show()

    xxx = [x[5][4][0] for x in DATA_LBAND]
    yyy = [x[6][4][0] for x in DATA_LBAND]
    tex = ["HD "+x[0] for x in DATA_LBAND]
    plt.scatter(xxx,yyy)
    for i in range(0,len(xxx)):
        plt.annotate(tex[i],[xxx[i],yyy[i]])
    plt.xlabel("$\\alpha_L$")
    plt.ylabel("$\\alpha_{W3W4}$")
    plt.show()
    
    import sys; sys.exit()



##########################################################
### TODO Fredy's task: Generate prior distribution and save in external file.
### I will use it to plot qs in the observed diagrams.



### Se define la funcion necesaria para la Theta Big
def fBe(M,A):
   
    ell = 1.4*M**3.5
    log10ell = np.log10(1.4)+3.5*np.log10(M)
   
   
    A0 = -16.17045
    ### A0 = -14.09101
    A1 = 8.71656
    A2 = -1.95159
    A3 = 0.11596
    A4 = 0.
    A5 = 0.
    A6 = 0.
   
    logf = A0+\
            A1*log10ell+\
            A2*log10ell**2.+\
            A3*log10ell**3.+\
            A4*log10ell**4.+\
            A5*log10ell**5.+\
            A6*log10ell**6.
   
    return A*np.exp(logf)



def find_area():

    Ar = (12+7+23+12+15+14+10+7)/800.
    x = np.array([1.+0.01*float(i) for i in range(0,3500+1)])
    y = np.array([fBe(elem,Ar) for elem in x])

    ymin = 0.
    ymax = np.nanmax(y)
    xmin = np.nanmin(x)
    xmax = np.nanmax(x)

    icount = 0.
    incount = 0.
    for i in range(0,1000000):
        icount += 1.
        xr = np.random.uniform(xmin,xmax,None)
        yr = np.random.uniform(ymin,ymax,None)
        if yr <= fBe(xr,Ar):
            incount += 1.

    print(incount/icount*(xmax-xmin)*(ymax-ymin))

    return

#find_area()



if 1==2:

    A = 1./8.
    x = np.array([1.+0.01*float(i) for i in range(0,3500+1)])
    y = np.array([fBe(elem,A) for elem in x])


    plt.figure(figsize=(5.5,2.5))
    plt.plot(x,y)
    plt.xlabel("$M/M_\odot$")
    plt.ylabel("$f_\mathrm{Be}$")
    plt.xscale("log")
    #plt.yscale("log")
    plt.tight_layout()
    plt.show()
    
    sys.exit()








### En esta parte se define la ThetaBig, 
### poniendo los intervalos para cada parametro

def thetabig(n,logSig,M,W,cosi):
   
    if 4.2 <= M <= 20. and \
            0. <= W <= 1. and \
            -np.inf <= logSig <= 0.6020599913279624 and \
            2. <= n <= 6.5 and \
            1. <= n <= 7. and \
            0. <= cosi <= 1.:
        return 1
    else:
        return 0


### Se define la funcion Prior
def lnprior(theta,other):
   


    ### Se definen los parametros de la Prior
    n = theta[0]
    logSig = theta[1]
    M = theta[2]
    W = np.sqrt(2.*(theta[3]-1.))
    cosi = theta[4]
   

   
    thetab = thetabig(n,logSig,M,W,cosi)
   
    if thetab == 0:
        return -np.inf
    else:
        mean_W = other[0]
        std_W = other[1]
        fbe = fBe(M,1.)
        return -2.3*np.log(M) + np.log(fbe) \
                    - 0.5*(W-mean_W)*(W-mean_W)/std_W/std_W




###########
### Uncheck this to generate output file with the prior distribution and 
### some derived quantities:
if 1==2:

    ### Number of dimensions of the problem
    ndim = 5
    ### Good values for emcee:
    nwalkers = 500
    Nchain = 1300
    nburnin = 300


    ### 
    def thetabig_only(n,logSig,M,W,cosi):
   
        if 4.2 <= M <= 20. and \
                0. <= W <= 1. and \
                -2. <= logSig <= 0.6020599913279624 and \
                3.0 <= n <= 4.5 and \
                0. <= cosi <= 1.:
            return 1
        else:
            return 0

    ###
    def prior_Sigma(logSig):
        
        return 10.**logSig

    ### 
    def lnprior_only(theta,other):
        """
        Prior with IMF.
        """


        ### Se definen los parametros de la Prior
        n = theta[0]
        logSig = theta[1]
        M = theta[2]
        W = np.sqrt(2.*(theta[3]-1.))
        cosi = theta[4]
   

        ### 'thetab' is 1 or 0, depending of the walker
        thetab = thetabig_only(n,logSig,M,W,cosi)
   
        if thetab == 0:
            return -np.inf
        else:
            mean_W = other[0]
            std_W = other[1]
            fbe = fBe(M,1.)
            lgS = np.log(prior_Sigma(logSig))
            return lgS -5.3*np.log(M) + np.log(fbe) \
                        - 0.5*(W-mean_W)*(W-mean_W)/std_W/std_W

    ### 
    def lnprior2_only(theta,other):
        """
        Prior without IMF.
        """


        ### Se definen los parametros de la Prior
        n = theta[0]
        logSig = theta[1]
        M = theta[2]
        W = np.sqrt(2.*(theta[3]-1.))
        cosi = theta[4]
   

        ### 'thetab' is 1 or 0, depending of the walker
        thetab = thetabig_only(n,logSig,M,W,cosi)
   
        if thetab == 0:
            return -np.inf
        else:
            mean_W = other[0]
            std_W = other[1]
            fbe = fBe(M,1.)
            lgS = np.log(prior_Sigma(logSig))
            return lgS + np.log(fbe)-0.5*(W-mean_W)*(W-mean_W)/std_W/std_W

    ### Parameters for the distribution of Rivinius et al. 2006
    mean_W = 0.81
    std_W = 0.12
    means = [mean_W, std_W]

    ### Choose an initial set of positions for the walkers.
    ### (It is a list of ndim-dimensional arrays.)
    thetalims = [\
                [2.,4.5],\
                [read_data.newlog10abs(0.02,1e5),read_data.newlog10abs(4.,1e5)],\
                [4.2,20.],\
                [1.,1.5],\
                [0.,1.]\
                ]
    p0 = [ np.array([thetalims[idim][0]+\
            (thetalims[idim][1]-thetalims[idim][0])*np.random.rand() \
            for idim in range(0,len(thetalims))]) for i in range(nwalkers)]
    
    
    ### Running emcee for the prior with IMF
    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprior_only,args=[means])
    
    print("Sampling prior #1...")
    state = sampler.run_mcmc(p0, Nchain)
    print("Sampling DONE.")


    ### Uncheck this to see the evolution of the probabilities 
    if 1==2:
        lnprobability = sampler.lnprobability
    
        poslnprob=np.arange(1,len(lnprobability[0])+1)
        fig=plt.figure(figsize=(6,6))
        ax=plt.subplot(1,1,1)
            
        for iwalker in range(0,len(lnprobability)):
            plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][j]) \
                for j in range(0,len(lnprobability[0]))], \
                color='black', linewidth=0.05, linestyle='-')
        plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
        plt.xlabel("position in the chain")
        plt.show()

    
    samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
    #samples = np.array([
    #        [samples[i][0],10.**samples[i][1],samples[i][2],\
    #        samples[i][3],samples[i][4]] for i in range(0,len(samples))
    #        ])
    if 1==2:
        fig = corner.corner(samples, \
        labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
        "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
        plt.show()



    ### Running emcee for the prior without IMF
    sampler2 = emcee.EnsembleSampler(nwalkers, ndim, lnprior2_only,args=[means])
    
    print("Sampling prior #2...")
    state2 = sampler2.run_mcmc(p0, Nchain)
    print("Sampling DONE.")

    ### Uncheck this to see the evolution of the probabilities 
    if 1==2:
        lnprobability = sampler2.lnprobability
    
        poslnprob=np.arange(1,len(lnprobability[0])+1)
        fig=plt.figure(figsize=(6,6))
        ax=plt.subplot(1,1,1)
            
        for iwalker in range(0,len(lnprobability)):
            plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][j]) \
                for j in range(0,len(lnprobability[0]))], \
                color='black', linewidth=0.05, linestyle='-')
        plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
        plt.xlabel("position in the chain")
        plt.show()

    
    samples2 = sampler2.chain[:, nburnin:, :].reshape((-1, ndim))
    #samples2 = np.array([
    #        [samples2[i][0],10.**samples2[i][1],samples2[i][2],\
    #        samples2[i][3],samples2[i][4]] for i in range(0,len(samples2))
    #        ])
    if 1==2:
        fig = corner.corner(samples2, \
        labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
        "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
        plt.show()






    lnprobs = []
    n_print = []; logSig_print = []; M_print = []; ob_print = []; cosi_print = []
    points = []
    
    ###
    if 1==2:
        ### Output file containing the walkers and derived quantities for 
        ### the prior:
        prior_file = "prior_and_derivs_IMF_logSig.out"
        
        for ichain in range(nburnin,len(sampler.chain[:][0])):
            for iwalker in range(0,len(sampler.chain)):
                ### 
                point = sampler.chain[iwalker][ichain]
                points.append(point)
                ### 
                lnprobs.append(sampler.lnprobability[iwalker][ichain])
                n_print.append(point[0])
                logSig_print.append(point[1])
                M_print.append(point[2])
                ob_print.append(point[3])
                cosi_print.append(point[4])
    ###
    if 1==1:
        ### Output file containing the walkers and derived quantities for 
        ### the prior:
        prior_file = "prior2_and_derivs_logSig.out"
        
        for ichain in range(nburnin,len(sampler2.chain[:][0])):
            for iwalker in range(0,len(sampler2.chain)):
                ### 
                point = sampler2.chain[iwalker][ichain]
                points.append(point)
                ### 
                lnprobs.append(sampler2.lnprobability[iwalker][ichain])
                n_print.append(point[0])
                logSig_print.append(point[1])
                M_print.append(point[2])
                ob_print.append(point[3])
                cosi_print.append(point[4])
    
    allow_extrapolation = "no"

    
    def evaluating_XXX(name,vals_XXX):
        print("Evaluating "+name+"...")
        XXX_print = []
        [XXX_print.append(lrr.interpLinND(points[ipoint],axis,\
                vals_XXX,\
                tp,allow_extrapolation)) for ipoint in range(0,len(points))]    
        
        return XXX_print


    B_print = evaluating_XXX("B",vals_B)
    V_print = evaluating_XXX("V",vals_V)
    R_print = evaluating_XXX("R",vals_R)
    I_print = evaluating_XXX("I",vals_I)
    poldegB_print = evaluating_XXX("poldegB",vals_poldegB)
    poldegV_print = evaluating_XXX("poldegV",vals_poldegV)
    poldegR_print = evaluating_XXX("poldegR",vals_poldegR)
    poldegI_print = evaluating_XXX("poldegI",vals_poldegI)
    J_print = evaluating_XXX("J",vals_J)
    H_print = evaluating_XXX("H",vals_H)
    K_print = evaluating_XXX("K",vals_K)
    vsini_print = evaluating_XXX("vsini",vals_vsini)
    alphaW1W2_print = evaluating_XXX("alphaW1W2",vals_alphaW1W2)
    alphaW2W3_print = evaluating_XXX("alphaW2W3",vals_alphaW2W3)
    alphaW3W4_print = evaluating_XXX("alphaW3W4",vals_alphaW3W4)
    MW1_print = evaluating_XXX("MW1",vals_MW1)
    MW2_print = evaluating_XXX("MW2",vals_MW2)
    MW3_print = evaluating_XXX("MW3",vals_MW3)
    MW4_print = evaluating_XXX("MW4",vals_MW4)
    MIRAC1_print = evaluating_XXX("MIRAC1",vals_MIRAC1)
    MIRAC2_print = evaluating_XXX("MIRAC2",vals_MIRAC2)
    MIRAC3_print = evaluating_XXX("MIRAC3",vals_MIRAC3)
    MIRAC4_print = evaluating_XXX("MIRAC4",vals_MIRAC4)
    alphaL_print = evaluating_XXX("alphaL",vals_alphaL)
    MBL_print = evaluating_XXX("MBL",vals_MBL)
    Halpha_print = evaluating_XXX("Halpha",vals_Halpha)
    EWHalpha_print = evaluating_XXX("EWHalpha",vals_EWHalpha)
    PSHalpha_print = evaluating_XXX("PSHalpha",vals_PSHalpha)
    FWHMHalpha_print = evaluating_XXX("FWHMHalpha",vals_FWHMHalpha)
    Hu14_print = evaluating_XXX("Hu14",vals_Hu14)
    Hu15_print = evaluating_XXX("Hu15",vals_Hu15)
    Hu16_print = evaluating_XXX("Hu16",vals_Hu16)
    #Hu17_print = evaluating_XXX("Hu17",vals_Hu17)
    Hu18_print = evaluating_XXX("Hu18",vals_Hu18)
    Hu19_print = evaluating_XXX("Hu19",vals_Hu19)
    Hu20_print = evaluating_XXX("Hu20",vals_Hu20)
    Hu21_print = evaluating_XXX("Hu21",vals_Hu21)
    Hu22_print = evaluating_XXX("Hu22",vals_Hu22)
    Hu23_print = evaluating_XXX("Hu23",vals_Hu23)
    Hu24_print = evaluating_XXX("Hu24",vals_Hu24)
    Hu25_print = evaluating_XXX("Hu25",vals_Hu25)
    #FWHMHu14_print = evaluating_XXX("FWHMHu14",vals_FWHMHu14)
    #FWHMHu15_print = evaluating_XXX("FWHMHu15",vals_FWHMHu15)
    #FWHMHu16_print = evaluating_XXX("FWHMHu16",vals_FWHMHu16)
    ##FWHMHu17_print = evaluating_XXX("FWHMHu17",vals_FWHMHu17)
    #FWHMHu18_print = evaluating_XXX("FWHMHu18",vals_FWHMHu18)
    #FWHMHu19_print = evaluating_XXX("FWHMHu19",vals_FWHMHu19)
    #FWHMHu20_print = evaluating_XXX("FWHMHu20",vals_FWHMHu20)
    #FWHMHu21_print = evaluating_XXX("FWHMHu21",vals_FWHMHu21)
    #FWHMHu22_print = evaluating_XXX("FWHMHu22",vals_FWHMHu22)
    #FWHMHu23_print = evaluating_XXX("FWHMHu23",vals_FWHMHu23)
    #FWHMHu24_print = evaluating_XXX("FWHMHu24",vals_FWHMHu24)
    #FWHMHu25_print = evaluating_XXX("FWHMHu25",vals_FWHMHu25)
    Bra_print = evaluating_XXX("Br alpha",vals_Bra)
    Pfg_print = evaluating_XXX("Pf gamma",vals_Pfg)
    FBL_print = evaluating_XXX("BL flux",vals_FBL)
    
    
                        
            
    ### Writing the sample in the external file:
    fp = open(prior_file,"w")
    
    def print_in_file(name,XX_print):
        
        fp.write(name)
        [fp.write(" "+str(XX_print[iline])) for iline in range(0,len(XX_print))]
        fp.write("\n")        
        
        return

    
    print_in_file("LNPROB",lnprobs)
    print_in_file("THETA_0",n_print)
    print_in_file("THETA_1",logSig_print)
    print_in_file("THETA_2",M_print)
    print_in_file("THETA_3",ob_print)
    print_in_file("THETA_4",cosi_print)

    print_in_file("B",B_print)
    print_in_file("V",V_print)
    print_in_file("R",R_print)
    print_in_file("I",I_print)
    print_in_file("poldegB",poldegB_print)
    print_in_file("poldegV",poldegV_print)
    print_in_file("poldegR",poldegR_print)
    print_in_file("poldegI",poldegI_print)
    print_in_file("J",J_print)
    print_in_file("H",H_print)
    print_in_file("K",K_print)
    print_in_file("VSINI",vsini_print)
    print_in_file("ALPHAW1W2",alphaW1W2_print)
    print_in_file("ALPHAW2W3",alphaW2W3_print)
    print_in_file("ALPHAW3W4",alphaW3W4_print)
    print_in_file("MW1",MW1_print)
    print_in_file("MW2",MW2_print)
    print_in_file("MW3",MW3_print)
    print_in_file("MW4",MW4_print)
    print_in_file("MIRAC1",MIRAC1_print)
    print_in_file("MIRAC2",MIRAC2_print)
    print_in_file("MIRAC3",MIRAC3_print)
    print_in_file("MIRAC4",MIRAC4_print)
    print_in_file("ALPHAL",alphaL_print)
    print_in_file("MBL",MBL_print)
    print_in_file("HALPHA",Halpha_print)
    print_in_file("EWHALPHA",EWHalpha_print)
    print_in_file("PSHALPHA",PSHalpha_print)
    print_in_file("FWHMHALPHA",FWHMHalpha_print)
    print_in_file("Hu14",Hu14_print)
    print_in_file("Hu15",Hu15_print)
    print_in_file("Hu16",Hu16_print)
    #print_in_file("Hu17",Hu17_print)
    print_in_file("Hu18",Hu18_print)
    print_in_file("Hu19",Hu19_print)
    print_in_file("Hu20",Hu20_print)
    print_in_file("Hu21",Hu21_print)
    print_in_file("Hu22",Hu22_print)
    print_in_file("Hu23",Hu23_print)
    print_in_file("Hu24",Hu24_print)
    print_in_file("Hu25",Hu25_print)
    #print_in_file("FWHMHu14",FWHMHu14_print)
    #print_in_file("FWHMHu15",FWHMHu15_print)
    #print_in_file("FWHMHu16",FWHMHu16_print)
    ##print_in_file("FWHMHu17",FWHMHu17_print)
    #print_in_file("FWHMHu18",FWHMHu18_print)
    #print_in_file("FWHMHu19",FWHMHu19_print)
    #print_in_file("FWHMHu20",FWHMHu20_print)
    #print_in_file("FWHMHu21",FWHMHu21_print)
    #print_in_file("FWHMHu22",FWHMHu22_print)
    #print_in_file("FWHMHu23",FWHMHu23_print)
    #print_in_file("FWHMHu24",FWHMHu24_print)
    #print_in_file("FWHMHu25",FWHMHu25_print)
    print_in_file("BRALPHA",Bra_print)
    print_in_file("PFGAMMA",Pfg_print)
    print_in_file("BL_FLUX",FBL_print)


    fp.close()

    sys.exit()


### Uncheck this to generate several output files in windows on the 
### Lenorzer diagram 
### with the previously calculated prior distribution and 
### some derived quantities:
if 1==2:

    def is_inside_ellipsoid(xvec,x0vec,sigma2vec):
        """
        Returns 'True', if 'xvec' is inside ND ellipsoid.
        Returns 'False', if not.
        """
        
        ellipsoid = -1.
        for ix in range(0,len(xvec)):
            ellipsoid += (xvec[ix]-x0vec[ix])*(xvec[ix]-x0vec[ix])/\
                        (sigma2vec[ix]*sigma2vec[ix])
    
        if not np.isnan(ellipsoid):
            if ellipsoid <= 0.:
                return True
            else:
                return False
        else: return False


    N_logH14Pfg = 5; minc = -1.; maxc = 0.
    centers_logH14Pfg = np.array([minc+(maxc-minc)*float(i)/float(N_logH14Pfg-1) \
            for i in range(0,N_logH14Pfg)])
    sigma2s_logH14Pfg = np.array([2.0*(maxc-minc)/float(N_logH14Pfg-1)*\
            2.0*(maxc-minc)/float(N_logH14Pfg-1) for i in range(0,N_logH14Pfg)])

    N_logH14Bra = 5; minc = -1.5; maxc = 0.
    centers_logH14Bra = np.array([minc+(maxc-minc)*float(i)/float(N_logH14Bra-1) \
            for i in range(0,N_logH14Bra)])
    sigma2s_logH14Bra = np.array([2.0*(maxc-minc)/float(N_logH14Bra-1)*\
            2.0*(maxc-minc)/float(N_logH14Bra-1) for i in range(0,N_logH14Bra)])

    N_logH14cont = 3; minc = 0.0; maxc = 7.0
    centers_logH14cont = np.array([minc+(maxc-minc)*float(i)/float(N_logH14cont-1) \
            for i in range(0,N_logH14cont)])
    sigma2s_logH14cont = np.array([2.0*(maxc-minc)/float(N_logH14cont-1)*\
            2.0*(maxc-minc)/float(N_logH14cont-1) for i in range(0,N_logH14cont)])


    centers = []
    sigma2s = []
    for ix in range(0,N_logH14Pfg):
        for iy in range(0,N_logH14Bra):
            for iz in range(0,N_logH14cont):
                centers.append([centers_logH14Pfg[ix],\
                        centers_logH14Bra[iy],centers_logH14cont[iz]])
                sigma2s.append([sigma2s_logH14Pfg[ix],\
                        sigma2s_logH14Bra[iy],sigma2s_logH14cont[iz]])




    ### Output file containing the walkers and derived quantities for 
    ### the prior:
    prior_file = "prior2_and_derivs.out"
    ### 
    fp = open(prior_file,"r")
    linesprior = fp.readlines()
    fp.close()
    linesprior = [x.split() for x in linesprior]

    ### 
    for iline in range(0,len(linesprior)):
            
        if linesprior[iline][0] == "THETA_0": # n
            idx_THETA_0 = iline
        if linesprior[iline][0] == "THETA_1": # Sig
            idx_THETA_1 = iline
        if linesprior[iline][0] == "THETA_2": # M
            idx_THETA_2 = iline
        if linesprior[iline][0] == "THETA_3": # ob
            idx_THETA_3 = iline
        if linesprior[iline][0] == "THETA_4": # cosi
            idx_THETA_4 = iline
    
        if linesprior[iline][0] == "Hu14":
            idx_Hu14 = iline
        if linesprior[iline][0] == "BRALPHA":
            idx_BRALPHA = iline
        if linesprior[iline][0] == "PFGAMMA":
            idx_PFGAMMA = iline
        if linesprior[iline][0] == "BL_FLUX":
            idx_BL_FLUX = iline

    ### 
    output_filename = "./Lenorzer_windows/window_XXX.out"


    if len(linesprior[idx_THETA_0]) > 1:
        minmax0 = \
            [np.nanmin([float(x) for x in linesprior[idx_THETA_0][1:]]),\
            np.nanmax([float(x) for x in linesprior[idx_THETA_0][1:]])]
    else:
        minmax0 = [np.nan,np.nan]
    if len(linesprior[idx_THETA_1]) > 1:
        minmax1 = \
            [np.nanmin([float(x) for x in linesprior[idx_THETA_1][1:]]),\
            np.nanmax([float(x) for x in linesprior[idx_THETA_1][1:]])]
    else:
        minmax1 = [np.nan,np.nan]        
    if len(linesprior[idx_THETA_2]) > 1:
        minmax2 = \
            [np.nanmin([float(x) for x in linesprior[idx_THETA_2][1:]]),\
            np.nanmax([float(x) for x in linesprior[idx_THETA_2][1:]])]
    else:
        minmax2 = [np.nan,np.nan]        
    if len(linesprior[idx_THETA_3]) > 1:
        minmax3 = \
            [np.nanmin([float(x) for x in linesprior[idx_THETA_3][1:]]),\
            np.nanmax([float(x) for x in linesprior[idx_THETA_3][1:]])]
    else:
        minmax3 = [np.nan,np.nan]                
    if len(linesprior[idx_THETA_4]) > 1:
        minmax4 = \
            [np.nanmin([float(x) for x in linesprior[idx_THETA_4][1:]]),\
            np.nanmax([float(x) for x in linesprior[idx_THETA_4][1:]])]
    else:
        minmax4 = [np.nan,np.nan]    

    print(minmax2)
    print(minmax3)
    print(minmax0)
    print(minmax1)
    print(minmax4)

    for iwind in range(0,len(centers)):
    
        f0 = open(output_filename.replace("XXX",str(iwind)),"w")
    
        lines_write = [[] for iline in range(0,len(linesprior))]
        for iline in range(0,len(linesprior)):
            lines_write[iline].append(linesprior[iline][0])
    
        for iel in range(1,len(linesprior[0])):
        
            xvec = [float(linesprior[idx_Hu14][iel])/\
                            float(linesprior[idx_PFGAMMA][iel]),\
                    float(linesprior[idx_Hu14][iel])/\
                            float(linesprior[idx_BRALPHA][iel]),\
                    float(linesprior[idx_Hu14][iel])/\
                            float(linesprior[idx_BL_FLUX][iel])*(3.47-3.41)*1e4]
        
            if is_inside_ellipsoid(xvec,centers[iwind],sigma2s[iwind]) \
                    and xvec[2] >= 0.:
                for iline in range(0,len(linesprior)):
                    lines_write[iline].append(linesprior[iline][iel])
    
        model_pars = []; x_pars = []
        for iel in range(1,50+1):
            if len(lines_write[0]) > 1:
                iell = np.random.random_integers(1,len(lines_write[0])-1)
                model_pars.append([\
                        (float(lines_write[idx_THETA_2][iell])-minmax2[0])/\
                                (minmax2[1]-minmax2[0]),\
                        (float(lines_write[idx_THETA_3][iell])-minmax3[0])/\
                                (minmax3[1]-minmax3[0]),\
                        (float(lines_write[idx_THETA_0][iell])-minmax0[0])/\
                                (minmax0[1]-minmax0[0]),\
                        (float(lines_write[idx_THETA_1][iell])-minmax1[0])/\
                                (minmax1[1]-minmax1[0]),\
                        (float(lines_write[idx_THETA_4][iell])-minmax4[0])/\
                                (minmax4[1]-minmax4[0])\
                        ])
            else:
                model_pars.append([np.nan,np.nan,np.nan,np.nan,np.nan])
            x_pars.append([0,1,2,3,4])
        
        fig = plt.figure(figsize = (2.2,2.2))
        for iel in range(0,len(x_pars)):
            plt.plot(x_pars[iel],model_pars[iel],\
                    color=(0,0,0),\
                    linewidth=0.3)
        plt.ylim([0.,1.])
        plt.savefig("parallell_"+str(iwind)+".png")
        plt.close()
            
        
        for iline in range(0,len(lines_write)):
            [f0.write(str(lines_write[iline][iel])+" ") \
                    for iel in range(0,len(lines_write[iline]))]
            f0.write("\n")


        f0.close()


    sys.exit()





##########################################################
##########################################################
### Now, comes the PART-1 of the analysis: making lots of plots!
### Some of these plots will be on the paper.

### Directory for the figures:
figures = "Figures/"

#############################
### Plotting Big-corner diagram (FOR PAPER)
if 1==2:

    ### Output file containing the walkers and derived quantities for 
    ### the prior:
    prior_file = "prior2_and_derivs.out"
    ### 
    fp = open(prior_file,"r")
    linesprior = fp.readlines()
    fp.close()
    linesprior = [x.split() for x in linesprior]
    ### 
    Nprior = np.nanmin([100000,len(linesprior[0])-1])

    ### 
    for iline in range(0,len(linesprior)):
        
        if linesprior[iline][0] == "THETA_0": # n
            idx_THETA_0 = iline
        if linesprior[iline][0] == "THETA_1": # Sig
            idx_THETA_1 = iline
        if linesprior[iline][0] == "THETA_2": # M
            idx_THETA_2 = iline
        if linesprior[iline][0] == "THETA_3": # ob
            idx_THETA_3 = iline
        if linesprior[iline][0] == "THETA_4": # cosi
            idx_THETA_4 = iline

        if linesprior[iline][0] == "MBL":
            idx_MBL = iline
        if linesprior[iline][0] == "Hu14":
            idx_Hu14 = iline
        if linesprior[iline][0] == "BRALPHA":
            idx_BRALPHA = iline
        if linesprior[iline][0] == "PFGAMMA":
            idx_PFGAMMA = iline
        if linesprior[iline][0] == "BL_FLUX":
            idx_BL_FLUX = iline
        if linesprior[iline][0] == "VSINI":
            idx_VSINI = iline
            
            
    samples = np.zeros((Nprior,9)); samples[:,:] = np.nan
    
    ii = 0
    i = 0
    while ii < Nprior and i < len(linesprior[0])-1:
    
        if \
                ~np.isnan(float(linesprior[idx_Hu14][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_Hu14][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_PFGAMMA][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_PFGAMMA][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_BRALPHA][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_BRALPHA][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_BL_FLUX][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_BL_FLUX][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_VSINI][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_VSINI][-1-i]))) and \
                -1.8 <= np.log10(float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_PFGAMMA][-1-i])) <= 0.5 and \
                -1.8 <= np.log10(float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_BRALPHA][-1-i])) <= 0.5 and \
                -3. <= float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_BL_FLUX][-1-i])*(3.47-3.41)*1e4 <= 9. \
                :
            
            samples[ii,0] = float(linesprior[idx_THETA_0][-1-i])
            samples[ii,1] = float(linesprior[idx_THETA_1][-1-i])
            samples[ii,2] = float(linesprior[idx_THETA_2][-1-i])
            samples[ii,3] = float(linesprior[idx_THETA_3][-1-i])
            samples[ii,4] = float(linesprior[idx_THETA_4][-1-i])
            samples[ii,5] = np.log10(float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_PFGAMMA][-1-i]))
            samples[ii,6] = np.log10(float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_BRALPHA][-1-i]))
            samples[ii,7] = float(linesprior[idx_Hu14][-1-i])/\
                        float(linesprior[idx_BL_FLUX][-1-i])*(3.47-3.41)*1e4
            samples[ii,8] = float(linesprior[idx_VSINI][-1-i])
            
            ii += 1
            
        i += 1
        
    if 1==1:
        ranges = []
        for i in range(0,len(samples[0,:])):
            mini = np.nanmin([samples[j,i] \
                for j in range(0,len(samples[:,i]))])
            maxi = np.nanmax([samples[j,i] \
                for j in range(0,len(samples[:,i]))])
        
            if i == 0:
                ranges.append((3.,4.5))
            elif i == 1:
                ranges.append((np.log10(0.02),np.log10(4.0)))
            elif i == 2:
                ranges.append((4.,20.))
            elif i == 3:
                ranges.append((1.2,1.4))
            elif i == 4:
                ranges.append((0.,1.))
            elif i == 5:
                ranges.append((np.log10(0.02),np.log10(3.0)))
            elif i == 6:
                ranges.append((np.log10(0.02),np.log10(3.0)))
            elif i == 7:
                ranges.append((-3.,9.))
            else:
                ranges.append((mini+0.0*(maxi-mini),\
                                maxi-0.0*(maxi-mini)) )
                
        
        fig = corner.corner(samples, \
        range=ranges, \
        labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
        "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$",\
        "$\log\left(\\frac{F(\\mathrm{Hu}14)}{F(\\mathrm{Pf}\gamma)}\\right)$",\
        "$\log\left(\\frac{F(\\mathrm{Hu}14)}{F(\\mathrm{Br}\\alpha)}\\right)$",\
        "$\\frac{F(\\mathrm{Hu}14)}{F(\lambda_B^*)}\,[\\mathrm{A}]$",\
        "$v\sin i\,[\\mathrm{km/s}]$"],\
        bins=60)
        #plt.tight_layout()
        plt.savefig("corner_Lenorzer.png")
        plt.close()
            
            
    sys.exit()



### 
if 1==2:

    ### Output file containing the walkers and derived quantities for 
    ### the prior:
    prior_file = "prior2_and_derivs.out"
    ### 
    fp = open(prior_file,"r")
    linesprior = fp.readlines()
    fp.close()
    linesprior = [x.split() for x in linesprior]
    ### 
    Nprior = np.nanmin([100000,len(linesprior[0])-1])

    ### 
    for iline in range(0,len(linesprior)):
        
        if linesprior[iline][0] == "THETA_0": # n
            idx_THETA_0 = iline
        if linesprior[iline][0] == "THETA_1": # Sig
            idx_THETA_1 = iline
        if linesprior[iline][0] == "THETA_2": # M
            idx_THETA_2 = iline
        if linesprior[iline][0] == "THETA_3": # ob
            idx_THETA_3 = iline
        if linesprior[iline][0] == "THETA_4": # cosi
            idx_THETA_4 = iline

        if linesprior[iline][0] == "VSINI":
            idx_VSINI = iline
        if linesprior[iline][0] == "EWHALPHA":
            idx_EWHALPHA = iline
        if linesprior[iline][0] == "PSHALPHA":
            idx_PSHALPHA = iline

        if linesprior[iline][0] == "I":
            idx_I = iline            
        if linesprior[iline][0] == "poldegV":
            idx_poldegV = iline
            
    samples = np.zeros((Nprior,10)); samples[:,:] = np.nan
    
    ii = 0
    i = 0
    while ii < Nprior and i < len(linesprior[0])-1:
    
        if \
                ~np.isnan(float(linesprior[idx_VSINI][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_VSINI][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_EWHALPHA][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_EWHALPHA][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_PSHALPHA][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_PSHALPHA][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_I][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_I][-1-i]))) and \
                ~np.isnan(float(linesprior[idx_poldegV][-1-i])) and \
                ~np.isinf(abs(float(linesprior[idx_poldegV][-1-i]))) \
                :
            
            if -0.6 <= float(linesprior[idx_THETA_1][-1-i]) <= 0.0 and \
                3.2 <= float(linesprior[idx_THETA_0][-1-i]) <= 3.8 and \
                10. <= float(linesprior[idx_THETA_2][-1-i]) <= 14. and \
                0.0 <= float(linesprior[idx_PSHALPHA][-1-i]) and \
                0.0 <= float(linesprior[idx_poldegV][-1-i]) \
                :
            
            
            
                samples[ii,0] = float(linesprior[idx_THETA_0][-1-i])
                samples[ii,1] = float(linesprior[idx_THETA_1][-1-i])
                samples[ii,2] = float(linesprior[idx_THETA_2][-1-i])
                samples[ii,3] = float(linesprior[idx_THETA_3][-1-i])
                samples[ii,4] = float(linesprior[idx_THETA_4][-1-i])
                samples[ii,5] = float(linesprior[idx_VSINI][-1-i])
                samples[ii,6] = float(linesprior[idx_EWHALPHA][-1-i])
                samples[ii,7] = float(linesprior[idx_PSHALPHA][-1-i])
                samples[ii,8] = float(linesprior[idx_I][-1-i])
                samples[ii,9] = float(linesprior[idx_poldegV][-1-i])

            
                ii += 1
            
        i += 1
        
    if 1==1:
        ranges = []
        for i in range(0,len(samples[0,:])):
            mini = np.nanmin([samples[j,i] \
                for j in range(0,len(samples[:,i]))])
            maxi = np.nanmax([samples[j,i] \
                for j in range(0,len(samples[:,i]))])
        
            #if i == 5:
            #    ranges.append((np.log10(0.02),np.log10(3.0)))
            #elif i == 6:
            #    ranges.append((np.log10(0.02),np.log10(3.0)))
            #if i == 7:
            #    ranges.append((0.,maxi-0.0*(maxi-mini)))
            #elif i == 9:
            #    ranges.append((0.,maxi-0.0*(maxi-mini)))
            #else:
            ranges.append(  (mini+0.0*(maxi-mini),\
                                maxi-0.0*(maxi-mini)) )
                
        
        fig = corner.corner(samples, \
        range=ranges, \
        labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
        "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$",\
        "$v\sin i\,[\\mathrm{km/s}]$",\
        "$EW\,[\\mathrm{A}]$","$PS\,[km/s]$",\
        "$I\,[\\mathrm{mag}]$","$P_V$"],
        bins=60)
        #plt.tight_layout()
        plt.savefig("corner_EW_PS_vsini.png")
        plt.close()
            
            
    sys.exit()








#############################
### Plotting Mennickent-based CMD (FOR PAPER)
if 1==2:


    ### Output file containing the walkers and derived quantities for 
    ### the prior:
    prior_file = "prior_and_derivs.out"
    
    fp = open(prior_file,"r")
    linesprior = fp.readlines()
    fp.close()
    
    linesprior = [x.split() for x in linesprior]

    Nprior = np.nanmin([5000,len(linesprior[0])-1])

    ###     
    for iline in range(0,len(linesprior)):
        if linesprior[iline][0] == "ALPHAL":
            idx_alphaL = iline
        if linesprior[iline][0] == "MBL":
            idx_MBL = iline
        if linesprior[iline][0] == "ALPHAW3W4":
            idx_alphaW3W4 = iline
        if linesprior[iline][0] == "MW3":
            idx_MW3 = iline
    ### 
    Wal_alphaL = []
    Wal_MBL = []
    Wal_alphaW3W4 = []
    Wal_MW3 = []
    el_count = 1
    i = 1
    while el_count <= Nprior and i < len(linesprior[iline]):
        if not np.isnan(float(linesprior[idx_alphaL][i])) \
                and not np.isnan(float(linesprior[idx_MBL][i])) \
                and not np.isnan(float(linesprior[idx_alphaW3W4][i])) \
                and not np.isnan(float(linesprior[idx_MW3][i])):
            Wal_alphaL.append(float(linesprior[idx_alphaL][i]))
            Wal_MBL.append(float(linesprior[idx_MBL][i]))
            Wal_alphaW3W4.append(float(linesprior[idx_alphaW3W4][i]))
            Wal_MW3.append(float(linesprior[idx_MW3][i]))
            el_count += 1
        i += 1    
        

    ### 
    names = []
    alphaL = []
    erralphaL = []
    BL = []
    errBL = []
    MW3 = []
    errMW3 = []
    alphaW1W2 = []
    erralphaW1W2 = []
    alphaW2W3 = []
    erralphaW2W3 = []
    alphaW3W4 = []
    erralphaW3W4 = []

    for ifile in range(0,len(DATA_LBAND)):
        names.append(DATA_LBAND[ifile][0])
    
        alphaL.append(DATA_LBAND[ifile][5][4][0])
        erralphaL.append(DATA_LBAND[ifile][5][4][1]) 
        BL.append(DATA_LBAND[ifile][5][3][0])
        errBL.append(DATA_LBAND[ifile][5][3][1])

        MW3.append(DATA_LBAND[ifile][6][5][4])
        errMW3.append(DATA_LBAND[ifile][6][5][5])
        alphaW1W2.append(DATA_LBAND[ifile][6][2][0])
        erralphaW1W2.append(DATA_LBAND[ifile][6][2][1])
        alphaW2W3.append(DATA_LBAND[ifile][6][3][0])
        erralphaW2W3.append(DATA_LBAND[ifile][6][3][1])
        alphaW3W4.append(DATA_LBAND[ifile][6][4][0])
        erralphaW3W4.append(DATA_LBAND[ifile][6][4][1])

    H14BL = []
    errH14BL = []
    for ifile in range(0,len(DATA_LBAND)):
        H14BL.append(fluxhumphreys[ifile,14,0]/DATA_LBAND[ifile][5][0][0]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]))
        errH14BL.append(
                read_data.err_frac(fluxhumphreys[ifile,14,0]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]),\
                DATA_LBAND[ifile][5][0][0],fluxhumphreys[ifile,14,1]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]),\
                DATA_LBAND[ifile][5][0][1])\
                )

    plt.figure(figsize=(11,8))
    ### 
    plt.subplot(121)
    ### 
    plt.scatter(Wal_alphaL,Wal_MBL,alpha=0.1)
    ### 
    for i in range(0,len(DATA_LBAND)):
        plt.errorbar(alphaL[i],BL[i],xerr=erralphaL[i],yerr=errMW3[i],\
                color="red",\
                linewidth=0.5)
        plt.annotate("HD "+names[i],[alphaL[i],BL[i]],size=7.)
    cs = [np.arcsinh(2e4/x[7][1][0]) for x in DATA_LBAND]
    N = 11
    theticks = [-0.5*(np.nanmax(cs)-np.nanmin(cs))+\
            (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
            for i in range(0,N)]
    inv_theticks = [np.sinh(x) for x in theticks]
    ss=plt.scatter(alphaL[:],BL[:],c=cs,\
            s=1e4*(np.abs(H14BL[:])+np.abs(errH14BL[:]))/0.06e4,\
            cmap = 'gnuplot',marker = "o",alpha=0.8)
    cbar = plt.colorbar(ss, ticks = theticks)
    cbar.ax.set_yticklabels([round(x,2) for x in inv_theticks])
    cbar.set_label("$\\tau_1^{-1}\,[2\\times 10^4\mathrm{day^{-1}}]$")
    ### 
    plt.xlabel("$\\alpha_L$")
    plt.ylabel("$M_{B_L}\,\mathrm{[mag]}$")
    plt.xlim([-5.,1.6])
    plt.ylim([0.,-7.])
    ### 
    plt.subplot(122)
    ### 
    plt.scatter(Wal_alphaW3W4,Wal_MW3,alpha=0.1)
    ### 
    for i in range(0,len(DATA_LBAND)):
        varx = [alphaW1W2[i],alphaW2W3[i],alphaW3W4[i]]
        plt.plot([np.nanmin(varx),np.nanmax(varx)],[MW3[i],MW3[i]],\
                color = "black", linewidth=1.)
        plt.errorbar(alphaW1W2[i],MW3[i],xerr=erralphaW1W2[i],\
                yerr=errMW3[i],color="green",linewidth=2.)
        plt.errorbar(alphaW2W3[i],MW3[i],xerr=erralphaW2W3[i],\
                yerr=errMW3[i],color="blue",linewidth=2.)
        plt.errorbar(alphaW3W4[i],MW3[i],xerr=erralphaW3W4[i],\
                yerr=errMW3[i],color="purple",linewidth=2.)
        if not np.isnan(alphaW1W2[i]):
            plt.annotate("HD "+names[i],[alphaW1W2[i],MW3[i]],size=7.)
        elif not np.isnan(alphaW2W3[i]):
            plt.annotate("HD "+names[i],[alphaW2W3[i],MW3[i]],size=7.)
        else:
            plt.annotate("HD "+names[i],[alphaW3W4[i],MW3[i]],size=7.)
    ### 
    plt.xlabel("$\\alpha$")
    plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
    plt.xlim([-5.,1.6])
    plt.ylim([0.,-7.])
    ### 
    plt.tight_layout()
    plt.savefig(figures+"CMDDATA.png")
    
    sys.exit()


#############################
### TODO: plots of the SEDs and line profiles
if 1==2:

    import read_everything
    
    ### Reading fullsed, source and temperature files
    files_fullsed_new, files_source_new, files_temps_new, fullsed_contents, \
            fullsed_path, source_path, temps_path, dist_std = \
            read_everything.read_everything()




#############################
### Plotting observed Lenorzer Diagrams
if 1==2:
    

    ### Parameters for the double arcsinh scaling:
    up1 = 1.
    up2 = 5.  ### since most of the measured flux ratios are between 
                ### 0.1 and 1, the choice of up2 = 100 garantees the 
                ### nearly logarithmic behaviour of the scale for them.
    down1 = 0.2 * up1   ### This makes a "compression" of the negative axis.
    down2 = 5.
    ### Defining the labels of the axis
    axisvalsy=np.array([5.,2.,1.,0.5,0.2,0.1,0.05,0.,\
                            -0.1,-0.5,-5.,-50.,-500.])
    axisvalsx=np.array([5.,2.,1.,0.5,0.2,0.1,0.05,0.,\
                            -0.5,-50.,-500.])
    ### Obtaing the positions of the above defined labels of the axis
    transf_axisvalsy=np.array([lrr.scale_two_arcsinh(axisvalsy[i],\
            up1,up2,down1,down2) for i in xrange(0,len(axisvalsy))])
    transf_axisvalsx=np.array([lrr.scale_two_arcsinh(axisvalsx[i],\
            up1,up2,down1,down2) for i in xrange(0,len(axisvalsx))])


    ### 
    names = []
    XL = []
    errXL = []
    YL = []
    errYL = []
    H14BL = []
    errH14BL = []
    for ifile in range(0,len(DATA_LBAND)):
        names.append(DATA_LBAND[ifile][0])
        
        XL.append(fluxhumphreys[ifile,14,0]/fluxPfg[ifile,0])
        YL.append(fluxhumphreys[ifile,14,0]/fluxBra[ifile,0])
        H14BL.append(fluxhumphreys[ifile,14,0]/DATA_LBAND[ifile][5][0][0]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]))
        
        errXL.append(
                read_data.err_frac(fluxhumphreys[ifile,14,0],\
                fluxPfg[ifile,0],fluxhumphreys[ifile,14,1],\
                fluxPfg[ifile,1])\
                )
        errYL.append(
                read_data.err_frac(fluxhumphreys[ifile,14,0],\
                fluxBra[ifile,0],fluxhumphreys[ifile,14,1],\
                fluxBra[ifile,1])\
                )
        errH14BL.append(
                read_data.err_frac(fluxhumphreys[ifile,14,0]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]),\
                DATA_LBAND[ifile][5][0][0],fluxhumphreys[ifile,14,1]*\
                (DATA_LBAND[ifile][5][0][3]-DATA_LBAND[ifile][5][0][2]),\
                DATA_LBAND[ifile][5][0][1])\
                )


    ### Converting to the double arcsinh scale, for plotting:
    XLplot=np.array([lrr.scale_two_arcsinh(XL[i],up1,up2,down1,down2) \
        for i in range(0,len(XL))])
    YLplot=np.array([lrr.scale_two_arcsinh(YL[i],up1,up2,down1,down2) \
        for i in range(0,len(YL))])
    errXLplot=np.array([abs(lrr.scale_two_arcsinh(XL[i],up1,up2,down1,down2,\
        m="deriv"))*errXL[i] for i in range(0,len(errXL))])
    errYLplot=np.array([abs(lrr.scale_two_arcsinh(YL[i],up1,up2,down1,down2,\
        m="deriv"))*errYL[i] for i in range(0,len(errYL))])


    ### 
    plt.figure(1,figsize=(11,9), dpi=100)

    ### 
    plt.plot([0.,0.],[-1e32,1e32],linestyle=":",color="black",\
        linewidth=0.6)  ### Vertical dotted line
    plt.plot([-1e32,1e32],[0.,0.],linestyle=":",color="black",\
        linewidth=0.6)  ### Horizontal dotted line
    plt.plot([-1e5,1e5],[-1e5,1e5],linestyle=":",color="black",\
        linewidth=0.6)  ### Diagonal dotted line
    ### 
    type1_x = -0.1
    type1_y = -0.2
    plt.plot([lrr.scale_two_arcsinh(10.**type1_x,\
            up1,up2,down1,down2),lrr.scale_two_arcsinh(10.**type1_x,\
            up1,up2,down1,down2)],\
            [lrr.scale_two_arcsinh(10.**type1_y,\
            up1,up2,down1,down2),1e32],linestyle=":",color="blue",\
            linewidth=0.5)  ### Vertical line delimiting "type 1 region"
    plt.plot([lrr.scale_two_arcsinh(10.**type1_x,\
            up1,up2,down1,down2),1e32],[lrr.scale_two_arcsinh(10.**type1_y,\
            up1,up2,down1,down2),lrr.scale_two_arcsinh(10.**type1_y,\
            up1,up2,down1,down2)],linestyle=":",color="blue",\
            linewidth=0.5)  ### Horizontal line delimiting "type 1 region"
    
    ### 
    if 1==1:
        
        ### Output file containing the walkers and derived quantities for 
        ### the prior:
        prior_file = "prior2_and_derivs.out"
        ### 
        fp = open(prior_file,"r")
        linesprior = fp.readlines()
        fp.close()
        linesprior = [x.split() for x in linesprior]
        ### 
        Nprior = np.nanmin([5000,len(linesprior[0])-1])
    
        ### 
        for iline in range(0,len(linesprior)):
            if linesprior[iline][0] == "Hu14":
                idx_Hu14 = iline
            if linesprior[iline][0] == "BRALPHA":
                idx_Bra = iline
            if linesprior[iline][0] == "PFGAMMA":
                idx_Pfg = iline
            if linesprior[iline][0] == "BL_FLUX":
                idx_FBL = iline
            if linesprior[iline][0] == "THETA_0": # n
                idx_GRAD1 = iline
            if linesprior[iline][0] == "THETA_1": # Sig
            #if linesprior[iline][0] == "THETA_2": # M
            #if linesprior[iline][0] == "THETA_3": # ob
            #if linesprior[iline][0] == "THETA_4": # cosi
                idx_GRAD2 = iline
        ### 
        Wal_len_x = []
        Wal_len_y = []
        Wal_len_z = []
        grad1_len = []
        grad2_len = []
        el_count = 1
        i = 1
        while el_count <= Nprior and i < len(linesprior[iline]):
            if not np.isnan(float(linesprior[idx_Hu14][i])) \
                    and not np.isnan(float(linesprior[idx_Bra][i])) \
                    and not np.isnan(float(linesprior[idx_Pfg][i])) \
                    and not np.isnan(float(linesprior[idx_FBL][i])):
                Wal_len_x.append(float(linesprior[idx_Hu14][i])/\
                        float(linesprior[idx_Pfg][i]))
                Wal_len_y.append(float(linesprior[idx_Hu14][i])/\
                        float(linesprior[idx_Bra][i]))
                Wal_len_z.append(float(linesprior[idx_Hu14][i])/\
                        float(linesprior[idx_FBL][i])*(3.47-3.41)*1e4)
                grad1_len.append(float(linesprior[idx_GRAD1][i]))
                grad2_len.append(float(linesprior[idx_GRAD2][i]))
                el_count += 1
            i += 1    
    

        ### 
        Wal_len_x_plot = [lrr.scale_two_arcsinh(Wal_len_x[i],up1,up2,down1,down2) \
                for i in range(0,len(Wal_len_x))]
        Wal_len_y_plot = [lrr.scale_two_arcsinh(Wal_len_y[i],up1,up2,down1,down2) \
                for i in range(0,len(Wal_len_x))]

        for i in range(0,len(Wal_len_x_plot)):
            if Wal_len_z[i] >= 0.:
                markk="o"
            else:
                markk="^"    
            plt.scatter([Wal_len_x_plot[i]],[Wal_len_y_plot[i]],marker=markk,\
                    s=1e4*(np.abs(Wal_len_z[i]))/0.06e4,\
                    c=(
                    (grad1_len[i]-np.nanmin(grad1_len))/\
                    (np.nanmax(grad1_len)-np.nanmin(grad1_len)),\
                    0.0,\
                    0.0\
                    #(grad2_len[i]-np.nanmin(grad2_len))/\
                    #(np.nanmax(grad2_len)-np.nanmin(grad2_len)), \
                    ),\
                    facecolors="None",alpha=0.07)
                    
                    
    ### tau1^-1
    if 1==1:
        cs = [np.arcsinh(2e4/x[7][1][0]) for x in DATA_LBAND]
        N = 11
        theticks = [-0.5*(np.nanmax(cs)-np.nanmin(cs))+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [np.sinh(x) for x in theticks]
    ### MB [mag]
    if 1==2:
        cs = [x[5][3][0] for x in DATA_LBAND]
        N = 11
        theticks = [np.nanmin(cs)+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [x for x in theticks]    
    ### alphaL
    if 1==2:
        cs = [x[5][4][0] for x in DATA_LBAND]
        N = 11
        theticks = [np.nanmin(cs)+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [x for x in theticks]
    ### vsini [km/s]
    if 1==2:
        cs = [x[9] for x in DATA_LBAND]
        N = 11
        theticks = [np.nanmin(cs)+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [x for x in theticks]
    ### -EW/lambda(Halpha)
    if 1==2:
        cs = [-x[10][0] for x in DATA_LBAND]
        N = 11
        theticks = [np.nanmin(cs)+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [x for x in theticks]
    ### -EW/lambda(Halpha)*vsini [km/s]
    if 1==2:
        cs = [-x[10][0]*x[9] for x in DATA_LBAND]
        N = 11
        theticks = [np.nanmin(cs)+\
                (np.nanmax(cs)-np.nanmin(cs))*float(i)/float(N-1) \
                for i in range(0,N)]
        inv_theticks = [x for x in theticks]
    
    
    markers = []
    for i in range(0,len(XLplot)):
        if ~np.isnan(H14BL[i]):
            if H14BL[i] >= 0.:
                markk="o"
            else:
                markk="^"
        else:
            markk = "."
        markers.append(markk)
    
    ss = plt.scatter(XLplot[:],YLplot[:],marker="o",\
            s=1e4*(np.abs(H14BL[:])+np.abs(errH14BL[:]))/0.06e4,\
            facecolors="None",\
            c=cs,cmap = 'gnuplot',alpha = 0.8)    
    plt.scatter(XLplot[:],YLplot[:],marker="o",\
            s=1e4*(np.abs(H14BL[:])+np.abs(errH14BL[:]))/0.06e4,\
            facecolors="None",\
            color = "black")
    plt.scatter(XLplot[:],YLplot[:],marker="o",\
            s=1e4*(np.abs(H14BL[:])-np.abs(errH14BL[:]))/0.06e4,\
            facecolors="None",\
            color = "black")
    

    cbar = plt.colorbar(ss, ticks = theticks)
    cbar.ax.set_yticklabels([round(x,2) for x in inv_theticks])
    cbar.set_label("$\\tau_1^{-1}\,[2\\times 10^4\mathrm{day^{-1}}]$")
    for i in range(0,len(XLplot)):
        plt.errorbar([XLplot[i]],[YLplot[i]],xerr=errXLplot[i],\
                yerr=errYLplot[i],color="black")
        plt.annotate("HD "+names[i],[XLplot[i],YLplot[i]],size=7.,\
                color="green")
    
    if 1==2:

        GranadaDATA, MennickentDATA = read_data.get_otherpapers()
        
        names_granada = [GranadaDATA[i][0] \
                for i in range(0,len(GranadaDATA))]
        
        x_granada = [GranadaDATA[i][2][14,0]/GranadaDATA[i][8][0] \
                for i in range(0,len(GranadaDATA))]
        y_granada = [GranadaDATA[i][2][14,0]/GranadaDATA[i][5][0] \
                for i in range(0,len(GranadaDATA))]
        
        x_granada_plot = [lrr.scale_two_arcsinh(x_granada[i],up1,up2,down1,down2) \
                for i in range(0,len(x_granada))]
        y_granada_plot = [lrr.scale_two_arcsinh(y_granada[i],up1,up2,down1,down2) \
                for i in range(0,len(y_granada))]

        err_x_granada = [read_data.err_frac(GranadaDATA[i][2][14,0],\
                GranadaDATA[i][8][0],GranadaDATA[i][2][14,1],\
                GranadaDATA[i][8][1]) for i in range(0,len(x_granada))]
        err_y_granada = [read_data.err_frac(GranadaDATA[i][2][14,0],\
                GranadaDATA[i][5][0],GranadaDATA[i][2][14,1],\
                GranadaDATA[i][5][1]) for i in range(0,len(x_granada))]

        err_x_granada_plot = [abs(lrr.scale_two_arcsinh(x_granada[i],\
                up1,up2,down1,down2,m="deriv"))*err_x_granada[i] \
                for i in range(0,len(x_granada))]
        err_y_granada_plot = [abs(lrr.scale_two_arcsinh(y_granada[i],\
                up1,up2,down1,down2,m="deriv"))*err_y_granada[i] \
                for i in range(0,len(y_granada))]
        
        for i in range(0,len(x_granada_plot)):
            plt.errorbar([x_granada_plot[i]],[y_granada_plot[i]],\
                    xerr = err_x_granada_plot[i], yerr = err_y_granada_plot[i],\
                    color="red")
            plt.annotate("HD "+names_granada[i],\
                    [x_granada_plot[i],y_granada_plot[i]],size=7.,color="red")

    if 1==2:

        GranadaDATA, MennickentDATA = read_data.get_otherpapers()

        names_mennick = [MennickentDATA[i][0] \
                for i in range(0,len(MennickentDATA))]

        x_mennick = [MennickentDATA[i][2][14,0]/MennickentDATA[i][8][0] \
                for i in range(0,len(MennickentDATA))]
        y_mennick = [MennickentDATA[i][2][14,0]/MennickentDATA[i][5][0] \
                for i in range(0,len(MennickentDATA))]
        
        x_mennick_plot = [lrr.scale_two_arcsinh(x_mennick[i],up1,up2,down1,down2) \
            for i in range(0,len(x_mennick))]
        y_mennick_plot = [lrr.scale_two_arcsinh(y_mennick[i],up1,up2,down1,down2) \
            for i in range(0,len(y_mennick))]


        err_x_mennick = [read_data.err_frac(MennickentDATA[i][2][14,0],\
                MennickentDATA[i][8][0],MennickentDATA[i][2][14,1],\
                MennickentDATA[i][8][1]) for i in range(0,len(x_mennick))]
        err_y_mennick = [read_data.err_frac(MennickentDATA[i][2][14,0],\
                MennickentDATA[i][5][0],MennickentDATA[i][2][14,1],\
                MennickentDATA[i][5][1]) for i in range(0,len(x_mennick))]

        err_x_mennick_plot = [abs(lrr.scale_two_arcsinh(x_mennick[i],\
                up1,up2,down1,down2,m="deriv"))*err_x_mennick[i] \
                for i in range(0,len(x_mennick))]
        err_y_mennick_plot = [abs(lrr.scale_two_arcsinh(y_mennick[i],\
                up1,up2,down1,down2,m="deriv"))*err_y_mennick[i] \
                for i in range(0,len(y_mennick))]

        
        for i in range(0,len(x_granada_plot)):
            plt.errorbar([x_mennick_plot[i]],[y_mennick_plot[i]],\
                    xerr = err_x_mennick_plot[i], yerr = err_y_mennick_plot[i],\
                    color="brown")
            plt.annotate("HD "+names_mennick[i],\
                    [x_mennick_plot[i],y_mennick_plot[i]],size=7.,color="brown")
                    
    
    plt.scatter([1e32], [1e32],marker="o",s=1e4*0.01,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = 0.01$")
    plt.scatter([1e32], [1e32],marker="o",s=1e4*0.003,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = 0.003$")
    plt.scatter([1e32], [1e32],marker="o",s=1e4*0.001,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = 0.001$")
    plt.scatter([1e32], [1e32],marker="o",s=1e4*0.0003,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = 0.0003$")
    plt.scatter([1e32], [1e32],marker="^",s=1e4*0.0003,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = -0.0003$")
    plt.scatter([1e32], [1e32],marker="^",s=1e4*0.001,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = -0.001$")
    plt.scatter([1e32], [1e32],marker="^",s=1e4*0.003,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = -0.003$")
    plt.scatter([1e32], [1e32],marker="^",s=1e4*0.01,\
        color="black",facecolors="none", \
        label="$F(\mathrm{H}_{14})/B_L = -0.01$")
    ### Add a legend
    plt.legend()

    plt.xscale('linear')
    plt.yscale('linear')
    plt.xlabel("$F(\mathrm{H}_{14})/F(\mathrm{Pf}_{\gamma})$")
    plt.ylabel("$F(\mathrm{H}_{14})/F(\mathrm{Br}_{\\alpha})$")
    plt.xticks(transf_axisvalsx,axisvalsx)
    plt.yticks(transf_axisvalsy,axisvalsy)
    plt.xlim([lrr.scale_two_arcsinh(-80.,\
            up1,up2,down1,down2),lrr.scale_two_arcsinh(8.,\
            up1,up2,down1,down2)])
    plt.ylim([lrr.scale_two_arcsinh(-80.,\
            up1,up2,down1,down2),lrr.scale_two_arcsinh(8.,\
            up1,up2,down1,down2)])
    
    plt.gca().set_aspect('equal', adjustable='box')
    plt.tight_layout()
    plt.savefig(figures+"LENORZERDATA.png")

    sys.exit()




#############################
### Plotting theoretical Lenorzer Diagrams
if 1==2:

    ### Parameters for the double arcsinh scaling:
    up1 = 1.
    up2 = 5.  ### since most of the measured flux ratios are between 
                ### 0.1 and 1, the choice of up2 = 100 garantees the 
                ### nearly logarithmic behaviour of the scale for them.
    down1 = 0.2 * up1   ### This makes a "compression" of the negative axis.
    down2 = 5.

    
    XL=[]
    YL=[]
    H14BL=[]
    figname=[]
    figtitle=[]
    annotate_vec=[]
    i_n = npar.index("4.5")
    i_sig = sigpar.index("1.65")
    i_M = Mpar.index("04.20")
    i_ob = obpar.index("1.40")
    i_cosi = cosipar.index("1.0")
    
    ###
    if 1==2:
        kinit = 1
        colorvec=[  "gray","black","brown","red","orange","green","blue","purple"]
        for iplot1 in range(0,len(sigpar)):
            auxi_XL=[]
            auxi_YL=[]
            auxi_H14BL=[]
            auxi_annotate_vec=[]
            for iplot2 in range(0,len(cosipar)):
                auxi_XL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    LINE_PFGAMMA[i_n,iplot1,i_M,i_ob,iplot2,0])
                auxi_YL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    LINE_BRALPHA[i_n,iplot1,i_M,i_ob,iplot2,0])
                auxi_H14BL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]*\
                           (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2]-\
                           BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1])*1e4)
                auxi_annotate_vec.append("$\cos i$ = "+\
                        str(round(abs(float(cosipar[iplot2])),2)))
            XL.append(auxi_XL)
            YL.append(auxi_YL)
            H14BL.append(auxi_H14BL)
            annotate_vec.append(auxi_annotate_vec)
            figname.append("n{0}_sig{1}_M{2}_ob{3}_cosi_X.png".format(\
                npar[i_n],sigpar[iplot1],Mpar[i_M],obpar[i_ob]))
            figtitle.append("$n="+npar[i_n]+"$, $\Sigma_0="+sigpar[iplot1]+\
                "\,\mathrm{g\,cm^{-2}}$")

    ###
    if 1==1:
        kinit = 0
        colorvec=["black","black","black","black","black","black","black",\
                        "black","black","black"]
        for iplot2 in range(0,len(cosipar)):
            auxi_XL=[]
            auxi_YL=[]
            auxi_H14BL=[]
            auxi_annotate_vec=[]
            for iplot1 in range(0,len(sigpar)):
                auxi_XL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    LINE_PFGAMMA[i_n,iplot1,i_M,i_ob,iplot2,0])
                auxi_YL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    LINE_BRALPHA[i_n,iplot1,i_M,i_ob,iplot2,0])
                auxi_H14BL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]*\
                            (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2]-\
                            BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1])*1e4)
                auxi_annotate_vec.append("$\Sigma_0$ = "+sigpar[iplot1])
            XL.append(auxi_XL)
            YL.append(auxi_YL)
            H14BL.append(auxi_H14BL)
            annotate_vec.append(auxi_annotate_vec)
            figname.append("n{0}_sigX.XX_M{1}_ob{2}_cosi_{3}.png".format(\
                npar[i_n],Mpar[i_M],obpar[i_ob],\
                str(round(abs(float(cosipar[iplot2])),2)) ))
            figtitle.append("$n="+npar[i_n]+"$, $\cos i = "+\
                        str(round(abs(float(cosipar[iplot2])),2))+"$")


    ### 
    XL=[np.array(XL[k]) for k in range(0,len(XL))]
    YL=[np.array(YL[k]) for k in range(0,len(XL))]
    H14BL=[np.array(H14BL[k]) for k in range(0,len(XL))]
        
    ### Defining the labels of the axis
    axisvalsy=np.array([5.,2.,1.,0.5,0.2,0.1,0.05,0.02,0.01,0.,\
                            -0.05,-0.5,-5.,-50.,500.])
    axisvalsx=np.array([5.,2.,1.,0.5,0.2,0.1,0.05,0.01,0.,\
                            -0.5,-50.,500.])
    ### Obtaing the positions of the above defined labels of the axis
    transf_axisvalsy=np.array([lrr.scale_two_arcsinh(axisvalsy[i],\
            up1,up2,down1,down2) for i in xrange(0,len(axisvalsy))])
    transf_axisvalsx=np.array([lrr.scale_two_arcsinh(axisvalsx[i],\
            up1,up2,down1,down2) for i in xrange(0,len(axisvalsx))])

    ### Converting to the double arcsinh scale, for plotting:
    XLplot=[np.array([lrr.scale_two_arcsinh(XL[k][i],up1,up2,down1,down2) \
        for i in range(0,len(XL[k]))]) for k in range(0,len(XL))]
    YLplot=[np.array([lrr.scale_two_arcsinh(YL[k][i],up1,up2,down1,down2) \
        for i in range(0,len(YL[k]))]) for k in range(0,len(YL))]


    for k in range(kinit,len(XL)):
        
        plt.figure(k,figsize=(5.5, 5.5), dpi=100)

        plt.plot([0.,0.],[-1e32,1e32],linestyle=":",color="black",\
            linewidth=0.6)  ### Vertical dotted line
        plt.plot([-1e32,1e32],[0.,0.],linestyle=":",color="black",\
            linewidth=0.6)  ### Horizontal dotted line
    
        type1_x = -0.1
        type1_y = -0.2
        plt.plot([lrr.scale_two_arcsinh(10.**type1_x,\
                up1,up2,down1,down2),lrr.scale_two_arcsinh(10.**type1_x,\
                up1,up2,down1,down2)],\
                    [lrr.scale_two_arcsinh(10.**type1_y,\
                up1,up2,down1,down2),1e32],linestyle=":",color="blue",\
            linewidth=0.5)  ### Vertical line delimiting "type 1 region"
        plt.plot([lrr.scale_two_arcsinh(10.**type1_x,\
                up1,up2,down1,down2),1e32],[lrr.scale_two_arcsinh(10.**type1_y,\
                up1,up2,down1,down2),lrr.scale_two_arcsinh(10.**type1_y,\
                up1,up2,down1,down2)],linestyle=":",color="blue",\
            linewidth=0.5)  ### Horizontal line delimiting "type 1 region"
    
    
        plt.plot(XLplot[k],YLplot[k],linewidth=0.3,color=colorvec[k])
        for i in xrange(0,len(XLplot[k])):
            if H14BL[k][i] >= 0.:
                markk="o"
            else:
                markk="^"
            plt.scatter([XLplot[k][i]],[YLplot[k][i]],marker=markk,\
                s=1e4*np.abs(H14BL[k][i])/0.06e4,\
                color=colorvec[k],facecolors="None")
                #alpha=0.5+0.5*float(i)/float(len(XLplot[k])-1))
                #color="black",facecolors="none")
        
        i_init = -1; key_i_init = 0
        i_final = len(XLplot[k]); key_i_final = 0
        while i_init < len(XLplot[k])-1 and key_i_init == 0:
            i_init += 1
            if (XLplot[k][i_init] is not None) and \
                        (YLplot[k][i_init] is not None):
                if (~np.isnan(XLplot[k][i_init])) and \
                        (~np.isnan(YLplot[k][i_init])):
                    key_i_init = 1
        while i_final > 0 and key_i_final == 0:
            i_final -= 1
            if (XLplot[k][i_final] is not None) and \
                        (YLplot[k][i_final] is not None):
                if (~np.isnan(XLplot[k][i_final])) and \
                        (~np.isnan(YLplot[k][i_final])):
                    key_i_final = 1
        
        if (XLplot[k][i_init] is not None) and \
                    (YLplot[k][i_init] is not None):
            if (~np.isnan(XLplot[k][i_init])) and \
                    (~np.isnan(YLplot[k][i_init])):
                plt.text(XLplot[k][i_init],YLplot[k][i_init], \
                        annotate_vec[k][i_init])
        if (XLplot[k][i_final] is not None) and \
                    (YLplot[k][i_final] is not None):
            if (~np.isnan(XLplot[k][i_final])) and \
                    (~np.isnan(YLplot[k][i_final])):
                plt.text(XLplot[k][i_final],YLplot[k][i_final], \
                        annotate_vec[k][i_final])
            
    
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.01,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.01$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.003$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.001,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.001$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.0003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.0003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.0003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.0003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.001,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.001$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.01,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.01$")
        ### Add a legend
        plt.legend()

        plt.title(figtitle[k])
        plt.xscale('linear')
        plt.yscale('linear')
        plt.xlabel("$F(\mathrm{H}_{14})/F(\mathrm{Pf}_{\gamma})$")
        plt.ylabel("$F(\mathrm{H}_{14})/F(\mathrm{Br}_{\\alpha})$")
        plt.xticks(transf_axisvalsx,axisvalsx)
        plt.yticks(transf_axisvalsy,axisvalsy)
        plt.xlim([lrr.scale_two_arcsinh(-80.,\
                up1,up2,down1,down2),lrr.scale_two_arcsinh(8.,\
                up1,up2,down1,down2)])
        plt.ylim([lrr.scale_two_arcsinh(-80.,\
                up1,up2,down1,down2),lrr.scale_two_arcsinh(8.,\
                up1,up2,down1,down2)])
        
        plt.savefig(figures+"LENORZER_"+figname[k])







#############################
### Plotting Humphrey's diagrams
if 1==2:
    
    ### Parameters for the double arcsinh scaling:
    up1 = 1.
    up2 = 5.    ### since most of the measured flux ratios are between 
                ### 0.1 and 1, the choice of up2 = 100 garantees the 
                ### nearly logarithmic behaviour of the scale for them.
    down1 = 0.2 * up1   ### This makes a "compression" of the negative axis.
    down2 = up2
    
    H14H19=[]; EWL_H14=[]
    H15H19=[]; EWL_H15=[]
    H16H19=[]; EWL_H16=[]
    H18H19=[]; EWL_H18=[]
    H19H19=[]; EWL_H19=[]
    H20H19=[]; EWL_H20=[]
    H21H19=[]; EWL_H21=[]
    H22H19=[]; EWL_H22=[]
    H23H19=[]; EWL_H23=[]
    H24H19=[]; EWL_H24=[]
    H25H19=[]; EWL_H25=[]
    H14BL=[]
    figname=[]
    figtitle=[]
    annotate_vec=[]
    
    i_n = npar.index("3.5")
    i_sig = sigpar.index("1.65")
    i_M = Mpar.index("14.60")
    i_ob = obpar.index("1.40")
    i_cosi = cosipar.index("1.0")


    ### 
    kinit = 1
    colorvec=[  "gray","black","brown","red","orange","green","blue","purple"]
    for iplot1 in range(0,len(sigpar)):
        auxi_H14H19=[]; auxi_EWL_H14=[]
        auxi_H15H19=[]; auxi_EWL_H15=[]
        auxi_H16H19=[]; auxi_EWL_H16=[]
        auxi_H18H19=[]; auxi_EWL_H18=[]
        auxi_H19H19=[]; auxi_EWL_H19=[]
        auxi_H20H19=[]; auxi_EWL_H20=[]
        auxi_H21H19=[]; auxi_EWL_H21=[]
        auxi_H22H19=[]; auxi_EWL_H22=[]
        auxi_H23H19=[]; auxi_EWL_H23=[]
        auxi_H24H19=[]; auxi_EWL_H24=[]
        auxi_H25H19=[]; auxi_EWL_H25=[]
        auxi_H14BL=[]
        auxi_annotate_vec=[]
        for iplot2 in range(0,len(cosipar)):
            
            def making_fluxratio(auxilist,NUM,DEN):
                auxilist.append(\
                NUM[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                DEN[i_n,iplot1,i_M,i_ob,iplot2,0])
                return
            
            making_fluxratio(auxi_H14H19,LINE_HUMPHREY14,LINE_HUMPHREY19)
            making_fluxratio(auxi_H15H19,LINE_HUMPHREY15,LINE_HUMPHREY19)
            making_fluxratio(auxi_H16H19,LINE_HUMPHREY16,LINE_HUMPHREY19)
            making_fluxratio(auxi_H18H19,LINE_HUMPHREY18,LINE_HUMPHREY19)
            making_fluxratio(auxi_H19H19,LINE_HUMPHREY19,LINE_HUMPHREY19)
            making_fluxratio(auxi_H20H19,LINE_HUMPHREY20,LINE_HUMPHREY19)
            making_fluxratio(auxi_H21H19,LINE_HUMPHREY21,LINE_HUMPHREY19)
            making_fluxratio(auxi_H22H19,LINE_HUMPHREY22,LINE_HUMPHREY19)
            making_fluxratio(auxi_H23H19,LINE_HUMPHREY23,LINE_HUMPHREY19)
            making_fluxratio(auxi_H24H19,LINE_HUMPHREY24,LINE_HUMPHREY19)
            making_fluxratio(auxi_H25H19,LINE_HUMPHREY25,LINE_HUMPHREY19)

            auxi_H14BL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]*\
                    (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2]-\
                    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1])*1e4)

            def making_ew(auxilist,NUM,DEN):
                auxilist.append(\
                NUM[i_n,iplot1,i_M,i_ob,iplot2,1]/\
                DEN*1e-4)                
                return
            
            making_ew(auxi_EWL_H14,LINE_HUMPHREY14,LINE_HUMPHREY14_lbd)
            making_ew(auxi_EWL_H15,LINE_HUMPHREY15,LINE_HUMPHREY15_lbd)
            making_ew(auxi_EWL_H16,LINE_HUMPHREY16,LINE_HUMPHREY16_lbd)
            making_ew(auxi_EWL_H18,LINE_HUMPHREY18,LINE_HUMPHREY18_lbd)
            making_ew(auxi_EWL_H19,LINE_HUMPHREY19,LINE_HUMPHREY19_lbd)
            making_ew(auxi_EWL_H20,LINE_HUMPHREY20,LINE_HUMPHREY20_lbd)
            making_ew(auxi_EWL_H21,LINE_HUMPHREY21,LINE_HUMPHREY21_lbd)
            making_ew(auxi_EWL_H22,LINE_HUMPHREY22,LINE_HUMPHREY22_lbd)
            making_ew(auxi_EWL_H23,LINE_HUMPHREY23,LINE_HUMPHREY23_lbd)
            making_ew(auxi_EWL_H24,LINE_HUMPHREY24,LINE_HUMPHREY24_lbd)
            making_ew(auxi_EWL_H25,LINE_HUMPHREY25,LINE_HUMPHREY25_lbd)
                        
            auxi_annotate_vec.append("$\cos i$ = "+\
                    str(round(abs(float(cosipar[iplot2])),2)))
                    
        H14H19.append(auxi_H14H19); EWL_H14.append(auxi_EWL_H14)
        H15H19.append(auxi_H15H19); EWL_H15.append(auxi_EWL_H15)
        H16H19.append(auxi_H16H19); EWL_H16.append(auxi_EWL_H16)
        H18H19.append(auxi_H18H19); EWL_H18.append(auxi_EWL_H18)
        H19H19.append(auxi_H19H19); EWL_H19.append(auxi_EWL_H19)
        H20H19.append(auxi_H20H19); EWL_H20.append(auxi_EWL_H20)
        H21H19.append(auxi_H21H19); EWL_H21.append(auxi_EWL_H21)
        H22H19.append(auxi_H22H19); EWL_H22.append(auxi_EWL_H22)
        H23H19.append(auxi_H23H19); EWL_H23.append(auxi_EWL_H23)
        H24H19.append(auxi_H24H19); EWL_H24.append(auxi_EWL_H24)
        H25H19.append(auxi_H25H19); EWL_H25.append(auxi_EWL_H25)
        H14BL.append(auxi_H14BL)
        annotate_vec.append(auxi_annotate_vec)
        figname.append("n{0}_sig{1}_M{2}_ob{3}_cosi_X.png".format(\
            npar[i_n],sigpar[iplot1],Mpar[i_M],obpar[i_ob]))
        figtitle.append("$n="+npar[i_n]+"$, $\Sigma_0="+sigpar[iplot1]+\
            "\,\mathrm{g\,cm^{-2}}$")





    ### 
    H14H19=[np.array(H14H19[k]) for k in range(0,len(H14H19))]
    H15H19=[np.array(H15H19[k]) for k in range(0,len(H15H19))]
    H16H19=[np.array(H16H19[k]) for k in range(0,len(H16H19))]
    H18H19=[np.array(H18H19[k]) for k in range(0,len(H18H19))]
    H19H19=[np.array(H19H19[k]) for k in range(0,len(H19H19))]
    H20H19=[np.array(H20H19[k]) for k in range(0,len(H20H19))]
    H21H19=[np.array(H21H19[k]) for k in range(0,len(H21H19))]
    H22H19=[np.array(H22H19[k]) for k in range(0,len(H22H19))]
    H23H19=[np.array(H23H19[k]) for k in range(0,len(H23H19))]
    H24H19=[np.array(H24H19[k]) for k in range(0,len(H24H19))]
    H25H19=[np.array(H25H19[k]) for k in range(0,len(H25H19))]
    H14BL=[np.array(H14BL[k]) for k in range(0,len(H14BL))]
    EWL_H14=[np.array(EWL_H14[k]) for k in range(0,len(EWL_H14))]
    EWL_H15=[np.array(EWL_H15[k]) for k in range(0,len(EWL_H15))]
    EWL_H16=[np.array(EWL_H16[k]) for k in range(0,len(EWL_H16))]
    EWL_H18=[np.array(EWL_H18[k]) for k in range(0,len(EWL_H18))]
    EWL_H19=[np.array(EWL_H19[k]) for k in range(0,len(EWL_H19))]
    EWL_H20=[np.array(EWL_H20[k]) for k in range(0,len(EWL_H20))]
    EWL_H21=[np.array(EWL_H21[k]) for k in range(0,len(EWL_H21))]
    EWL_H22=[np.array(EWL_H22[k]) for k in range(0,len(EWL_H22))]
    EWL_H23=[np.array(EWL_H23[k]) for k in range(0,len(EWL_H23))]
    EWL_H24=[np.array(EWL_H24[k]) for k in range(0,len(EWL_H24))]
    EWL_H25=[np.array(EWL_H25[k]) for k in range(0,len(EWL_H25))]
        
    ### Defining the labels of the axis
    axisvalsy=np.array([10.,5.,3.,2.,1.,0.5,0.2,0.1,0.,\
                            -0.5,-5.])
    ### Obtaing the positions of the above defined labels of the axis
    transf_axisvalsy=np.array([lrr.scale_two_arcsinh(axisvalsy[i],\
            up1,up2,down1,down2) for i in xrange(0,len(axisvalsy))])

    for k in range(kinit,len(H14H19)):

        Dlamb = 0.03
        
        def making_lambdas(lbdcenter,array,Dlamb):
            return np.array([lbdcenter - \
                0.5*Dlamb + Dlamb*float(i)/float(len(array)-1) \
                for i in xrange(0,len(array))])
                
        H14lamb = making_lambdas(LINE_HUMPHREY14_lbd,H14H19[k],Dlamb)
        H15lamb = making_lambdas(LINE_HUMPHREY15_lbd,H15H19[k],Dlamb)
        H16lamb = making_lambdas(LINE_HUMPHREY16_lbd,H16H19[k],Dlamb)
        H18lamb = making_lambdas(LINE_HUMPHREY18_lbd,H18H19[k],Dlamb)
        H19lamb = making_lambdas(LINE_HUMPHREY19_lbd,H19H19[k],Dlamb)
        H20lamb = making_lambdas(LINE_HUMPHREY20_lbd,H20H19[k],Dlamb)
        H21lamb = making_lambdas(LINE_HUMPHREY21_lbd,H21H19[k],Dlamb)
        H22lamb = making_lambdas(LINE_HUMPHREY22_lbd,H22H19[k],Dlamb)
        H23lamb = making_lambdas(LINE_HUMPHREY23_lbd,H23H19[k],Dlamb)
        H24lamb = making_lambdas(LINE_HUMPHREY24_lbd,H24H19[k],Dlamb)
        H25lamb = making_lambdas(LINE_HUMPHREY25_lbd,H25H19[k],Dlamb)
        
        plt.figure(k,figsize=(11, 7), dpi=100)

        plt.subplot(211)
            
        ymax = 15
        horlines = np.array([float(-15+ii) for ii in range(0,2*ymax+2)])
        for elem in horlines:
            plt.plot([-1e32,1e32],
            [lrr.scale_two_arcsinh(elem,up1,up2,down1,down2),\
            lrr.scale_two_arcsinh(elem,up1,up2,down1,down2)],
            linestyle=":",color="black",\
                linewidth=0.6)  ### Horizontal dotted lines
        
        colorvec=["red","green","blue"]
        kcolor=0
        
        def plot_ratio_line(x,y):
            plt.plot(x,np.array([\
                lrr.scale_two_arcsinh(y[j],up1,up2,down1,down2) \
                for j in range(0,len(y))]),\
                linewidth=0.3,color=colorvec[kcolor%3])
            return
        
        plot_ratio_line(H14lamb,H14H19[k]); kcolor+=1
        plot_ratio_line(H15lamb,H15H19[k]); kcolor+=1
        plot_ratio_line(H16lamb,H16H19[k]); kcolor+=1
        plot_ratio_line(H18lamb,H18H19[k]); kcolor+=1
        plot_ratio_line(H19lamb,H19H19[k]); kcolor+=1
        plot_ratio_line(H20lamb,H20H19[k]); kcolor+=1
        plot_ratio_line(H21lamb,H21H19[k]); kcolor+=1
        plot_ratio_line(H22lamb,H22H19[k]); kcolor+=1
        plot_ratio_line(H23lamb,H23H19[k]); kcolor+=1
        plot_ratio_line(H24lamb,H24H19[k]); kcolor+=1
        plot_ratio_line(H25lamb,H25H19[k]); kcolor+=1
        
                
        colorvec=["red","green","blue"]
        kcolor=0
        
        def plot_ratio_scatter(x,y):
            for i in xrange(0,len(y)):
                if H14BL[k][i] >= 0.:
                    markk="o"
                else:
                    markk="^"
                plt.scatter([x[i]],\
                    [lrr.scale_two_arcsinh(y[i],up1,up2,down1,down2)],\
                    marker=markk,\
                    s=1e4*np.abs(H14BL[k][i])/0.06e4,\
                    color=colorvec[kcolor%3],facecolors="None")
            return
            
        plot_ratio_scatter(H14lamb,H14H19[k]); kcolor+=1
        plot_ratio_scatter(H15lamb,H15H19[k]); kcolor+=1
        plot_ratio_scatter(H16lamb,H16H19[k]); kcolor+=1
        plot_ratio_scatter(H18lamb,H18H19[k]); kcolor+=1
        plot_ratio_scatter(H19lamb,H19H19[k]); kcolor+=1
        plot_ratio_scatter(H20lamb,H20H19[k]); kcolor+=1
        plot_ratio_scatter(H21lamb,H21H19[k]); kcolor+=1
        plot_ratio_scatter(H22lamb,H22H19[k]); kcolor+=1
        plot_ratio_scatter(H23lamb,H23H19[k]); kcolor+=1
        plot_ratio_scatter(H24lamb,H24H19[k]); kcolor+=1
        plot_ratio_scatter(H25lamb,H25H19[k]); kcolor+=1
            
            
    
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.01,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.01$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.003$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.001,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.001$")
        plt.scatter([1e32], [1e32],marker="o",s=1e4*0.0003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = 0.0003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.0003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.0003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.001,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.001$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.003,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.003$")
        plt.scatter([1e32], [1e32],marker="^",s=1e4*0.01,\
            color="black",facecolors="none", \
            label="$F(\mathrm{H}_{14})/B_L = -0.01$")
        ### Add a legend
        #plt.legend()

        plt.subplot(212)

        plt.plot([-1e32,1e32],[0.,0.],linestyle=":",color="black",\
            linewidth=0.6)  ### Horizontal dotted line
            
        colorvec=["red","green","blue"]
        kcolor=0

        def plot_ew_line(x,y):
            plt.plot(x,y*1e4,linewidth=0.3,color=colorvec[kcolor%3])
            return

        plot_ew_line(H14lamb,EWL_H14[k]); kcolor+=1
        plot_ew_line(H15lamb,EWL_H15[k]); kcolor+=1
        plot_ew_line(H16lamb,EWL_H16[k]); kcolor+=1
        plot_ew_line(H18lamb,EWL_H18[k]); kcolor+=1
        plot_ew_line(H19lamb,EWL_H19[k]); kcolor+=1
        plot_ew_line(H20lamb,EWL_H20[k]); kcolor+=1
        plot_ew_line(H21lamb,EWL_H21[k]); kcolor+=1
        plot_ew_line(H22lamb,EWL_H22[k]); kcolor+=1
        plot_ew_line(H23lamb,EWL_H23[k]); kcolor+=1
        plot_ew_line(H24lamb,EWL_H24[k]); kcolor+=1
        plot_ew_line(H25lamb,EWL_H25[k]); kcolor+=1
        
            
        colorvec=["red","green","blue"]
        kcolor=0
        
        def plot_ew_scatter(x,y):
            for i in xrange(0,len(y)):
                if H14BL[k][i] >= 0.:
                    markk="o"
                else:
                    markk="^"
                plt.scatter([x[i]],[y[i]*1e4],marker=markk,\
                    s=1e4*np.abs(H14BL[k][i])/0.06e4,\
                    color=colorvec[kcolor%3],facecolors="None")
            return        
        
        plot_ew_scatter(H14lamb,EWL_H14[k]); kcolor+=1
        plot_ew_scatter(H15lamb,EWL_H15[k]); kcolor+=1
        plot_ew_scatter(H16lamb,EWL_H16[k]); kcolor+=1
        plot_ew_scatter(H18lamb,EWL_H18[k]); kcolor+=1
        plot_ew_scatter(H19lamb,EWL_H19[k]); kcolor+=1
        plot_ew_scatter(H20lamb,EWL_H20[k]); kcolor+=1
        plot_ew_scatter(H21lamb,EWL_H21[k]); kcolor+=1
        plot_ew_scatter(H22lamb,EWL_H22[k]); kcolor+=1
        plot_ew_scatter(H23lamb,EWL_H23[k]); kcolor+=1
        plot_ew_scatter(H24lamb,EWL_H24[k]); kcolor+=1
        plot_ew_scatter(H25lamb,EWL_H25[k]); kcolor+=1
        



        plt.subplot(211)
        plt.title(figtitle[k])
        plt.xscale('linear')
        plt.yscale('linear')
        plt.yticks(transf_axisvalsy,axisvalsy)
        plt.ylabel("$F(\mathrm{H}_{n})/F(\mathrm{H}_{19})$")
        plt.xlabel("$\lambda\,[\mathrm{\mu m}]$")
        plt.xlim([3.4,4.1])
        plt.ylim([lrr.scale_two_arcsinh(-15.,up1,up2,down1,down2),\
            lrr.scale_two_arcsinh(15.,up1,up2,down1,down2)])

        plt.subplot(212)
        plt.xscale('linear')
        plt.yscale('linear')
        plt.ylabel("$EW/\lambda\,[\\times 10^{4}]$")
        plt.xlabel("$\lambda\,[\mathrm{\mu m}]$")
        plt.xlim([3.4,4.1])
        plt.ylim([2.5,-2.5])
        
        plt.savefig(figures+"HUMPHREYS_"+figname[k])
        
    sys.exit()




#############################
### Plotting Mennickent-based CMD
if 1==2:

    ###
    lamb1_BL=3.41 ; lamb2_BL=3.47
    lamb1_RL=3.93 ; lamb2_RL=4.00
    Nnpts=50
    xlp,ylp = lrr.VEGA_spct("spct1")
            
    llamb=np.array([lamb1_BL+(lamb2_BL-lamb1_BL)/\
        float(Nnpts-1)*float(i) for i in range(0,Nnpts)])*1e4
    dllamb=np.array([llamb[i+1]-llamb[i] for i in range(0,Nnpts-1)])
    ylpf=np.array([lrr.interpLinND([llamb[i]],[xlp],ylp) \
        for i in range(0,Nnpts)])
    B_Vega=lrr.integrate_trapezia(ylpf,dllamb)
    #print(B_Vega,B_Vega*0.5*(lamb1_BL+lamb2_BL)*1e-4/phc.c.cgs/phc.h.cgs)

    

    XL=[]
    YL=[]
    H14BL=[]
    figname=[]
    figtitle=[]
    annotate_vec=[]
    i_n = npar.index("3.0")
    i_sig = sigpar.index("1.65")
    i_M = Mpar.index("14.60")
    i_ob = obpar.index("1.40")
    i_cosi = cosipar.index("1.0")


    ###
    kinit = 0
    colorvec=[  "gray","black","brown","red","orange","green","blue","purple"]
    figname_now="n{0}_sigX.XX_M{1}_ob{2}_cosi_X.png".format(\
            npar[i_n],Mpar[i_M],obpar[i_ob])
    for iplot1 in range(0,len(sigpar)):
        auxi_XL=[]
        auxi_YL=[]
        auxi_H14BL=[]
        auxi_annotate_vec=[]
        for iplot2 in range(0,len(cosipar)):
            #auxi_XL.append(1.-np.log10(
            #    (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]/
            #    (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2]-\
            #    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1]))/\
            #    (RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]/
            #    (RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2]-\
            #    RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1]))
            #    )/np.log10(\
            #    (RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1]+\
            #    RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2])/\
            #    (BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1]+\
            #    BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2])
            #    ))
            auxi_XL.append(
                read_data.alphaL(BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0],\
                BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1],\
                BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2],\
                RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0],\
                RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,1],\
                RL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,2])
                )
            auxi_YL.append(-2.5*np.log10(
                BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                B_Vega))
            auxi_H14BL.append(LINE_HUMPHREY14[i_n,iplot1,i_M,i_ob,iplot2,0]/\
                BL_FLUX[i_n,iplot1,i_M,i_ob,iplot2,0]*(lamb2_BL-lamb1_BL)*1e4)
            auxi_annotate_vec.append("$\cos i$ = "+\
                    str(round(abs(float(cosipar[iplot2])),2)))
        XL.append(auxi_XL)
        YL.append(auxi_YL)
        H14BL.append(auxi_H14BL)
        annotate_vec.append(auxi_annotate_vec)
        figname.append("n{0}_sig{1}_M{2}_ob{3}_cosi_X.png".format(\
            npar[i_n],sigpar[iplot1],Mpar[i_M],obpar[i_ob]))
        figtitle.append("$n="+npar[i_n]+"$, $\Sigma_0="+sigpar[iplot1]+\
            "\,\mathrm{g\,cm^{-2}}$")



    ### 
    XL=[np.array(XL[k]) for k in range(0,len(XL))]
    YL=[np.array(YL[k]) for k in range(0,len(XL))]
    H14BL=[np.array(H14BL[k]) for k in range(0,len(XL))]

    plt.figure(0,figsize=(5.5, 5.5), dpi=100)

    for ifile in range(0,len(DATA_LBAND)):
        plt.errorbar([DATA_LBAND[ifile][5][4][0]],[DATA_LBAND[ifile][5][3][0]],\
                    xerr=DATA_LBAND[ifile][5][4][1],\
                    yerr=DATA_LBAND[ifile][5][3][1],color="gray",linewidth=0.3)
    for ifile in range(0,len(DATA_LBAND)):
        plt.text(DATA_LBAND[ifile][5][4][0],DATA_LBAND[ifile][5][3][0],\
                    DATA_LBAND[ifile][1], fontsize=8)


    for k in range(kinit,len(XL)):
    
        plt.plot(XL[k],YL[k],linewidth=0.3,color=colorvec[k])
        for i in xrange(0,len(XL[k])):
            if H14BL[k][i] >= 0.:
                markk="o"
            else:
                markk="^"
            plt.scatter([XL[k][i]],[YL[k][i]],marker=markk,\
                s=1e4*np.abs(H14BL[k][i])/(lamb2_BL-lamb1_BL)/1e4,\
                color=colorvec[k],facecolors="None")
        pass


    #plt.title(figtitle[k])
    plt.xscale('linear')
    plt.yscale('linear')
    plt.xlabel("$\\alpha_L$")
    plt.ylabel("$M_{B_L}\,[\mathrm{mag}]$")
    plt.xlim([-4.5,-0.5])
    plt.ylim([-0.5,-7.0])

    #plt.xlim([np.nanmin(alphaL)-0.1*(np.nanmax(alphaL)-np.nanmin(alphaL)),\
    #    np.nanmax(alphaL)+0.1*(np.nanmax(alphaL)-np.nanmin(alphaL))])
    #plt.ylim([np.nanmax(BL_Bvega)+0.1*(np.nanmax(BL_Bvega)-np.nanmin(BL_Bvega)),\
    #    np.nanmin(BL_Bvega)-0.1*(np.nanmax(BL_Bvega)-np.nanmin(BL_Bvega))])
        
    plt.tight_layout()
    #plt.show()
    plt.savefig(figures+"CMD_"+figname_now)

















#############################
### Plotting magnitude diagrams for the work with Alejandro and K. Vieira
if 1==2:
    
    ### The domain of the grids:
    npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
    ### Converting strings to float
    npar_vals = np.array([float(x) for x in npar])
    logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
            for x in sigpar])
    Mpar_vals = np.array([float(x) for x in Mpar])
    obpar_vals = np.array([float(x) for x in obpar])
    cosipar_vals = np.array([float(x) for x in cosipar])


    def get_xy(xmat,ymat):
        """
        
        """
        x = []
        y = []
        xylabel = []
        for i1 in range(0,len(npar_vals)):
            for i2 in range(0,len(logsigpar_vals)):
                for i3 in range(0,len(Mpar_vals)):
                    for i4 in range(0,len(obpar_vals)):
                        for i5 in range(0,len(cosipar_vals)):
                            x.append(xmat[i1,i2,i3,i4,i5])
                            y.append(ymat[i1,i2,i3,i4,i5])
                            xylabel.append([\
                                    npar_vals[i1],\
                                    logsigpar_vals[i2],\
                                    Mpar_vals[i3],\
                                    obpar_vals[i4],\
                                    cosipar_vals[i5]\
                                    ])

        return x,y,xylabel


    xmat = JHK[:,:,:,:,:,0]-JHK[:,:,:,:,:,2]
    ymat = UBVRI[:,:,:,:,:,2]-UBVRI[:,:,:,:,:,4]
    
    x,y,xylabel = get_xy(xmat,ymat)
    
    colorarr = np.array([[float(xylabel[i][4])/1.,0.,0.] \
            for i in range(0,len(xylabel))])
    plt.scatter(x,y,c="black",alpha = 0.01,marker = ".")
    plt.xlabel("J-K")
    plt.ylabel("V-I")
    plt.xlim([-0.5,2.5])
    plt.ylim([-0.5,1.0])
    plt.show()
    
    
    xmat = JHK[:,:,:,:,:,2]-IRAC[:,:,:,:,:,0]
    ymat = UBVRI[:,:,:,:,:,2]-UBVRI[:,:,:,:,:,4]
    
    x,y,xylabel = get_xy(xmat,ymat)
    
    plt.scatter(x,y,color="black",alpha = 0.01,marker = ".")
    plt.xlabel("K-[3.6]")
    plt.ylabel("V-I")
    plt.xlim([-1.5,3.0])
    plt.ylim([-0.5,1.0])
    plt.show()
    
    xmat = IRAC[:,:,:,:,:,0]-IRAC[:,:,:,:,:,1]
    ymat = UBVRI[:,:,:,:,:,2]-UBVRI[:,:,:,:,:,4]
    
    x,y,xylabel = get_xy(xmat,ymat)
    
    plt.scatter(x,y,color="black",alpha = 0.01,marker = ".")
    plt.xlabel("[3.6]-[5.8]")
    plt.ylabel("V-I")
    plt.xlim([-1.5,2.5])
    plt.ylim([-0.5,1.0])
    plt.show()




    xmat = JHK[:,:,:,:,:,0]-JHK[:,:,:,:,:,2]
    ymat = JHK[:,:,:,:,:,0]-IRAC[:,:,:,:,:,0]

    x,y,xylabel = get_xy(xmat,ymat)
    
    plt.scatter(x,y,color="black",alpha = 0.01,marker = ".")
    plt.xlabel("J-K")
    plt.ylabel("J-[3.6]")
    plt.xlim([-0.5,2.5])
    plt.ylim([-1.0,4.5])
    plt.show()
    
    
    xmat = JHK[:,:,:,:,:,2]-IRAC[:,:,:,:,:,0]
    ymat = JHK[:,:,:,:,:,0]-IRAC[:,:,:,:,:,0]
    
    x,y,xylabel = get_xy(xmat,ymat)
    
    plt.scatter(x,y,color="black",alpha = 0.01,marker = ".")
    plt.xlabel("K-[3.6]")
    plt.ylabel("J-[3.6]")
    plt.xlim([-1.5,3.0])
    plt.ylim([-1.0,4.5])
    plt.show()
    
    xmat = IRAC[:,:,:,:,:,0]-IRAC[:,:,:,:,:,1]
    ymat = JHK[:,:,:,:,:,0]-IRAC[:,:,:,:,:,0]
    
    x,y,xylabel = get_xy(xmat,ymat)
    
    plt.scatter(x,y,color="black",alpha = 0.01,marker = ".")
    plt.xlabel("[3.6]-[5.8]")
    plt.ylabel("J-[3.6]")
    plt.xlim([-1.5,2.5])
    plt.ylim([-1.0,4.5])
    plt.show()
    
    
    import sys; sys.exit()







### New analysis for Alejandro and K. Vieira
if 1==2:

    def selectfrom_xy(x,y,theta,Nmax=None):
        """
        
        """
        
        if Nmax != None:
            Nmax = np.nanmin([Nmax,len(x)])
        else:
            Nmax = len(x)
        
        xnow = []
        ynow = []
        thetanow = []
        for i in range(0,Nmax):
                    #4.2 <= theta[i][2] <= 14.6 and \            
            if 3.0 <= theta[i][0] <= 4.5 and \
                    0.02 <= 10.**theta[i][1] <= 4.00 and \
                    4.2 <= theta[i][2] <= 20. and \
                    1.1 <= theta[i][3] <= 1.45 and \
                    0.0 <= theta[i][4] <= 1.0:
        
                xnow.append(x[i])
                ynow.append(y[i])
                thetanow.append(theta[i])
                
        return xnow,ynow,thetanow
        
    
    prior_file = "prior2_and_derivs.out"
    #prior_file = "prior_and_derivs_IMF.out"
    prior_file = "prior_and_derivs_IMF_logSig.out"
    prior_file = "prior2_and_derivs_logSig.out"
    
    fp = open(prior_file,"r")
    fplines = fp.readlines()
    fp.close()
    
    labels_read = [
            "LNPROB",\
            "THETA_0","THETA_1","THETA_2","THETA_3","THETA_4",\
            "B","V","R","I","poldegB","poldegV","poldegR","poldegI",\
            "J","H","K","MW1","MW2","MW3","MW4",\
            "MIRAC1","MIRAC2","MIRAC3","MIRAC4"]
    
    dict_read = {}
    
    for iline in range(0,len(fplines)):
        thisline = fplines[iline].split()
        if thisline[0] in labels_read:
            dict_read[thisline[0]] = [float(thisline[i]) for i in \
                    range(1,len(thisline))]


    lnprob = [dict_read["LNPROB"][i] for i in \
            range(1,len(dict_read["LNPROB"]))]
    theta = [[dict_read["THETA_0"][i],dict_read["THETA_1"][i],\
            dict_read["THETA_2"][i],dict_read["THETA_3"][i],\
            dict_read["THETA_4"][i]] for i in \
            range(0,len(dict_read["THETA_0"]))]


    ### Write interesting points in an external file
    if 1==2:
        
        Nwrite = 100000
        
        tableKV = "tableKV.txt"
        
        
        if Nwrite != None:
            Nwrite = np.nanmin([Nwrite,len(lnprob)])
        else:
            Nwrite = len(lnprob)
        
        
        table_components = [["LNPROB","ln_prob"],\
            ["THETA_0","n"],["THETA_1","logSigma0"],["THETA_2","M/Msun"],\
            ["THETA_3","oblat"],["THETA_4","cosi"],\
            ["B","B"],["V","V"],["R","R"],["I","I"],\
            ["J","J"],["H","H"],["K","K"],\
            ["MW1","Wise1"],["MW2","Wise2"],["MW3","Wise3"],["MW4","Wise4"],\
            ["MIRAC1","IRAC1"],["MIRAC2","IRAC2"],\
            ["MIRAC3","IRAC3"],["MIRAC4","IRAC4"]]
            
        fw = open(tableKV,"w")
        idx_thisline = []
        fw.write("### ")
        for itab in range(0,len(table_components)):
            idx_thisline.append(labels_read.index(table_components[itab][0]))
            fw.write(table_components[itab][1]+" ")
        fw.write("\n")

        for iN in range(0,Nwrite):
            auxi = [
                    theta[iN][0],10.**theta[iN][1],theta[iN][2],theta[iN][3],\
                    theta[iN][4]\
                    ]
                    #4.2 <= auxi[2] <= 14.6 and \
            if      3.0 <= auxi[0] <= 4.5 and \
                    0.02 <= auxi[1] <= 4.00 and \
                    4.2 <= auxi[2] <= 20. and \
                    1.1 <= auxi[3] <= 1.45 and \
                    0.0 <= auxi[4] <= 1.0:            
                for itl in range(0,len(table_components)):
                    fw.write(str(dict_read[table_components[itl][0]][iN])+" ")
                fw.write("\n")
        
        fw.close()
        
        


    ### Here, I do the corner plots
    if 1==2:
        
        samplesx = []
        for i in range(0,len(theta)):
            derived = [
                dict_read["V"][i]-dict_read["I"][i], ### V-I
                dict_read["J"][i]-dict_read["K"][i], ### J-K
                dict_read["K"][i]-dict_read["MIRAC1"][i], ### K-MIRAC1
                dict_read["MIRAC1"][i]-dict_read["MIRAC2"][i], ### MIRAC1-MIRAC2
                dict_read["J"][i]-dict_read["MIRAC1"][i], ### J-MIRAC1
                    ]

            auxi = [
                    theta[i][0],10.**theta[i][1],theta[i][2],theta[i][3],\
                    theta[i][4]\
                    ]
                    #4.2 <= auxi[2] <= 14.6 and \
            if      3.0 <= auxi[0] <= 4.5 and \
                    0.02 <= auxi[1] <= 4.00 and \
                    4.2 <= auxi[2] <= 20. and \
                    1.1 <= auxi[3] <= 1.45 and \
                    0.0 <= auxi[4] <= 1.0:
                for el in derived:
                    auxi.append(el)
                samplesx.append([el for el in auxi])
        samplesx = np.array([el for el in samplesx])
            
        labels_list = ["$n$","$\Sigma_0$","$M/M_\odot$",\
                "oblat.","$\cos i$",\
                "V-I","J-K","K-[3.6]","[3.6]-[5.8]","J-[3.6]"]
                
        fig = corner.corner(samplesx, \
            labels = labels_list, \
            color = "black", \
            #range=rangetriang, 
            bins=60)
        fig.savefig("uv_triangx.png")


           
    if 1==2:
        
        fig, ((ax1,ax2,ax3),(ax4,ax5,ax6)) = plt.subplots(2,3)
        
        Nmax_now = 100000
        idxtheta = 0
        
        ### (J-K , V-I)
        x = [dict_read["J"][i]-dict_read["K"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["V"][i]-dict_read["I"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax1.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax1.set_xlabel("J-K")
        ax1.set_ylabel("V-I")
        #ax1.set_xlim([-0.5,2.5])
        #ax1.set_ylim([-0.5,1.0])

        ### (K-MIRAC1 , V-I)
        x = [dict_read["K"][i]-dict_read["MIRAC1"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["V"][i]-dict_read["I"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax2.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax2.set_xlabel("K-[3.6]$\mathrm{\mu m}$")
        ax2.set_ylabel("V-I")
        #ax2.set_xlim([-1.5,3.0])
        #ax2.set_ylim([-0.5,1.0])
        
        ### (MIRAC1-MIRAC2 , V-I)
        x = [dict_read["MIRAC1"][i]-dict_read["MIRAC2"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["V"][i]-dict_read["I"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax3.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax3.set_xlabel("[3.6]$\mathrm{\mu m}$-[5.8]$\mathrm{\mu m}$")
        ax3.set_ylabel("V-I")
        #ax3.set_xlim([-1.5,2.5])
        #ax3.set_ylim([-0.5,1.0])

        ### (J-K , J-MIRAC1)
        x = [dict_read["J"][i]-dict_read["K"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["J"][i]-dict_read["MIRAC1"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax4.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax4.set_xlabel("J-K")
        ax4.set_ylabel("J-[3.6]$\mathrm{\mu m}$")
        #ax4.set_xlim([-0.5,2.5])
        #ax4.set_ylim([-1.0,4.5])
        
        ### (K-MIRAC1 , J-MIRAC1)
        x = [dict_read["K"][i]-dict_read["MIRAC1"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["J"][i]-dict_read["MIRAC1"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax5.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax5.set_xlabel("K-[3.6]$\mathrm{\mu m}$")
        ax5.set_ylabel("J-[3.6]$\mathrm{\mu m}$")
        #ax5.set_xlim([-1.5,3.0])
        #ax5.set_ylim([-1.0,4.5])
        
        ### (MIRAC1-MIRAC2 , J-MIRAC1)
        x = [dict_read["MIRAC1"][i]-dict_read["MIRAC2"][i] \
                for i in range(0,len(dict_read["J"]))]
        y = [dict_read["J"][i]-dict_read["MIRAC1"][i] \
                for i in range(0,len(dict_read["V"]))]
        x,y,thetanow = selectfrom_xy(x,y,theta,Nmax=Nmax_now)
        colorarr = [thetanow[i][idxtheta] for i in range(0,len(thetanow))]
        ax6.scatter(x,y,c=colorarr,alpha=0.01,marker=".",cmap="gnuplot")
        ax6.set_xlabel("[3.6]$\mathrm{\mu m}$-[5.8]$\mathrm{\mu m}$")
        ax6.set_ylabel("J-[3.6]$\mathrm{\mu m}$")
        #ax6.set_xlim([-1.5,2.5])
        #ax6.set_ylim([-1.0,4.5])
        
        plt.show()







if 1==2:
    
    def lnprobPriorStar(theta, uvlims, Z):
        """ Returns the prior probability function. """
        n=theta[0]
        Sig0=theta[1]
        M=theta[2]
        W=theta[3]
        cosi=theta[4]
        
        p = priorn(n,uvlims[0][0],uvlims[0][1])*\
            priorSig0(Sig0,uvlims[1][0],uvlims[1][1])*\
            priorM(M,uvlims[2][0],uvlims[2][1],Z)*\
            priorW(W,uvlims[3][0],uvlims[3][1])*\
            priorcosi(cosi,uvlims[4][0],uvlims[4][1])
        if p == 0.:
            return -np.inf
        else:
            return np.log(p)

    def priorn(n,nmin,nmax):
        """ Returns the *a priori* probability of a star with main sequence
        age Tau be a Be star. """
        #interval check
        if n < nmin or n > nmax:
            return 0.
    
        return 1.
    
    def priorSig0(Sig0,Sig0min,Sig0max):
        """ Returns the *a priori* probability of a star with main sequence
        age Tau be a Be star. """
        #interval check
        if Sig0 < Sig0min or Sig0 > Sig0max:
            return 0.

        return 1./Sig0


    def priorM(M,Mmin,Mmax, Z=0.007):
        """ Returns the *a priori* probability of a star with mass M be a Be star.
    
        Masses always in Solar units. """
        #interval check
        if M < Mmin or M > Mmax:
            return 0.

        p = M**(-2.3)*fM(M, Z)

        return p

    def fM(M, Z):
        """ Function of the Be phenomenon as function of mass """
        if Z >= 0.045:
            a = .0017; b = 2.342
        else:
            a = .0107; b = 1.871
        #
        if M >= (1./a)**(1./b):
            p = 1.
        else:
            p = a*M**b
        return p
 

    def priorW(W,Wmin,Wmax):
        """ Returns the *a priori* probability of a star with rotation rate W be a
        Be star. """
        #interval check
        if W < Wmin or W > Wmax:
            return 0.

        Wmean = .81
        sigW = .12

        p = np.exp(-(W-Wmean)**2./(2.*sigW**2.))

        return p


    def priorcosi(cosi,cosimin,cosimax):
        """ Returns the *a priori* probability of a star at inclination angle i 
        be a Be star. """
        #interval check
        if cosi < cosimin or cosi > cosimax:
            return 0.

        return 1.


    nwalkers = 250  ### 250
    nsampling = 100 ### 100
    nchain = nsampling + 2000    ### 2000
    ndim = 5

    Z = 0.002
    uvlims= [   [3.0,4.5],\
                [0.02,4.0],\
                [3.2,14.6],\
                [0.,1.],\
                [0.,1.]\
            ]


    ### Choose an initial set of positions for the walkers.
    ### (It is a list of ndim-dimensional lists.)
    p0 = [  [np.random.uniform(uvlims[0][0],uvlims[0][1]),\
            np.random.uniform(uvlims[1][0],uvlims[1][1]),\
            np.random.uniform(uvlims[2][0],uvlims[2][1]),\
            np.random.uniform(uvlims[3][0],uvlims[3][1]),\
            np.random.uniform(uvlims[4][0],uvlims[4][1])] 
                for i in xrange(nwalkers)]



    ### Initialize the sampler with the chosen specs.
    sampler = emcee.EnsembleSampler(nwalkers, ndim, lnprobPriorStar, \
        args=[uvlims,Z], a=2, threads=1)


    print("SAMPLING...")
    pos, prob, state = sampler.run_mcmc(p0, nchain)
    print("SAMPLING DONE.")

    ### Uncheck this to see the evolution of the probabilities 
    ### for 'measuring x alone'
    if 1==2:
        lnprobability=[]
        lnprobability.append(sampler.lnprobability)

        poslnprob=np.arange(1,len(lnprobability[0][0])+1)
        fig=plt.figure(figsize=(6,6))
        ax=plt.subplot(1,1,1)
        
        for i in xrange(0,len(lnprobability[0])):
            plt.plot(poslnprob,[np.arcsinh(lnprobability[0][i][j]) \
                for j in range(0,len(lnprobability[0][0]))], \
                color='black', linewidth=0.05, linestyle='-')
        plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
        plt.xlabel("position in the chain")
        plt.show()


    walkerss = []
    for ii in range(0,nwalkers*nsampling):
        walkerss.append(sampler.flatchain[-1-ii])

    
    



    nparf = np.array([float(elem) for elem in npar])
    sigparf = np.array([float(elem) for elem in sigpar])
    Mparf = np.array([float(elem) for elem in Mpar])
    Wparf = np.array([np.sqrt(2.*float(elem)-2.) for elem in obpar])
    cosiparf = np.array([abs(float(elem)) for elem in cosipar])

    axis = [nparf,sigparf,Mparf,Wparf,cosiparf]


    print("INTERPOLATING...")
    ### Atributing values to every point in the grid.
    UBVRI1values=[]
    UBVRI2values=[]
    UBVRI3values=[]
    UBVRI4values=[]
    UBVRI5values=[]
    HALPHA_SOARvalues=[]
    JHK1values=[]
    JHK2values=[]
    JHK3values=[]
    IRAC1values=[]
    IRAC2values=[]
    IRAC3values=[]
    IRAC4values=[]
    for i in xrange(0,len(nparf)):
        for j in xrange(0,len(sigparf)):
            for k in xrange(0,len(Mparf)):
                for l in xrange(0,len(Wparf)):
                    for m in xrange(0,len(cosiparf)):
                        UBVRI1values.append(UBVRI[i,j,k,l,m,0])
                        UBVRI2values.append(UBVRI[i,j,k,l,m,1])
                        UBVRI3values.append(UBVRI[i,j,k,l,m,2])
                        UBVRI4values.append(UBVRI[i,j,k,l,m,3])
                        UBVRI5values.append(UBVRI[i,j,k,l,m,4])
                        HALPHA_SOARvalues.append(HALPHA_SOAR[i,j,k,l,m])
                        JHK1values.append(JHK[i,j,k,l,m,0])
                        JHK2values.append(JHK[i,j,k,l,m,1])
                        JHK3values.append(JHK[i,j,k,l,m,2])
                        IRAC1values.append(IRAC[i,j,k,l,m,0])
                        IRAC2values.append(IRAC[i,j,k,l,m,1])
                        IRAC3values.append(IRAC[i,j,k,l,m,2])
                        IRAC4values.append(IRAC[i,j,k,l,m,3])


    UBVRI1walkers = []
    UBVRI2walkers = []
    UBVRI3walkers = []
    UBVRI4walkers = []
    UBVRI5walkers = []
    HALPHA_SOARwalkers = []
    JHK1walkers = []
    JHK2walkers = []
    JHK3walkers = []
    IRAC1walkers = []
    IRAC2walkers = []
    IRAC3walkers = []
    IRAC4walkers = []
    print("INTERPOLATIONS FOR U FILTER...")
    for ii in range(0,len(walkerss)):
        UBVRI1walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,UBVRI1values))
    print("INTERPOLATIONS FOR B FILTER...")
    for ii in range(0,len(walkerss)):
        UBVRI2walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,UBVRI2values))
    print("INTERPOLATIONS FOR V FILTER...")
    for ii in range(0,len(walkerss)):
        UBVRI3walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,UBVRI3values))
    print("INTERPOLATIONS FOR R FILTER...")
    for ii in range(0,len(walkerss)):
        UBVRI4walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,UBVRI4values))
    print("INTERPOLATIONS FOR I FILTER...")
    for ii in range(0,len(walkerss)):
        UBVRI5walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,UBVRI5values))
    print("INTERPOLATIONS FOR SOAR'S HALPHA FILTER...")
    for ii in range(0,len(walkerss)):
        HALPHA_SOARwalkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,HALPHA_SOARvalues))
    print("INTERPOLATIONS FOR J FILTER...")
    for ii in range(0,len(walkerss)):
        JHK1walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,JHK1values))
    print("INTERPOLATIONS FOR H FILTER...")
    for ii in range(0,len(walkerss)):
        JHK2walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,JHK2values))
    print("INTERPOLATIONS FOR K FILTER...")
    for ii in range(0,len(walkerss)):
        JHK3walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,JHK3values))
    print("INTERPOLATIONS FOR IRAC 1 FILTER...")
    for ii in range(0,len(walkerss)):
        IRAC1walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,IRAC1values))
    print("INTERPOLATIONS FOR IRAC 2 FILTER...")
    for ii in range(0,len(walkerss)):
        IRAC2walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,IRAC2values))
    print("INTERPOLATIONS FOR IRAC 3 FILTER...")
    for ii in range(0,len(walkerss)):
        IRAC3walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,IRAC3values))
    print("INTERPOLATIONS FOR IRAC 4 FILTER...")
    for ii in range(0,len(walkerss)):
        IRAC4walkers.append(lrr.interpLinND(np.array(walkerss[ii]),axis,IRAC4values))
        
    print("INTERPOLATIONS DONE.")

    fileext = "KV_walkers.txt"
    f0 = open(fileext,"w")
    
    for ii in range(0,len(walkerss)):
        f0.write(   str(walkerss[ii][0])+str(" ")+\
                    str(walkerss[ii][1])+str(" ")+\
                    str(walkerss[ii][2])+str(" ")+\
                    str(walkerss[ii][3])+str(" ")+\
                    str(walkerss[ii][4])+str(" ")+\

                    str(UBVRI1walkers[ii])+str(" ")+\
                    str(UBVRI2walkers[ii])+str(" ")+\
                    str(UBVRI3walkers[ii])+str(" ")+\
                    str(UBVRI4walkers[ii])+str(" ")+\
                    str(UBVRI5walkers[ii])+str(" ")+\
                    str(JHK1walkers[ii])+str(" ")+\
                    str(JHK2walkers[ii])+str(" ")+\
                    str(JHK3walkers[ii])+str(" ")+\
                    str(IRAC1walkers[ii])+str(" ")+\
                    str(IRAC2walkers[ii])+str(" ")+\
                    str(IRAC3walkers[ii])+str(" ")+\
                    str(IRAC4walkers[ii])+str(" ")+\
                    "\n"
        )
    
    f0.close()



##########################################################
##########################################################
### Now, comes the part 2 of the analysis: MCMC bayesian inference for comparison 
### of models and observations.

Part2 = False
### File containing the operations to be performed on the Be stars
operations_on_stars = "operations_on_stars.inp"





def get_instructions(operations_on_stars):
    """
    This function reads the instructions of operations to be applied
    on the Be stars from our database.
    """

    ### Reading the contents of the file containing all instructions
    f0 = open(operations_on_stars,"r")
    lines = f0.readlines()
    f0.close()

    ### 'instructions' is a list that will contain all the instructions
    ### to be performed on all stars that are in the instructions file and 
    ### in our database.
    instructions = []
    ### Getting 'HDnames'
    data_folder, HDnames, Starnames, SIMBAD_Spt, YYYYMMDD_LBAND = \
                    read_data.List_Stars("stars")
    ### Loop over every line of the instructions file
    starkey = 0
    for iline in range(0,len(lines)):
        thisline = lines[iline].split()
        if len(thisline) > 0:
            ### Entering the "STAR" subfolder
            if thisline[0] == "STAR" and len(thisline) == 2:
                hdname = thisline[1]
                if hdname in HDnames:
                    instructions.append([hdname,[]])
                    starkey = 1
                else:
                    print("There is no Be star called HD "+hdname+\
                            " in the database.")
        
            ### For this specific star, reads instructions for bayesian 
            ### inference
            if (thisline[0] == "BINF_ALPHAW3W4_W3" or \
                thisline[0] == "BINF_ALPHAL_BL" or \
                thisline[0] == "BINF_2DLENORZER" or \
                thisline[0] == "BINF_WISEBESS" ) \
                        and len(thisline) == 6 and starkey == 1:
                if thisline[1] == "YES":
                    instructions[-1][1].append([    thisline[0],
                                                    thisline[2],
                                                    thisline[3],
                                                    thisline[4],
                                                    thisline[5]
                                                ])

            ### For this specific star, reads instructions for ...
            if (thisline[0] == "P3_GRAPHS__BINF_ALPHAW3W4_W3" or \
                thisline[0] == "P3_GRAPHS__BINF_ALPHAL_BL" or \
                thisline[0] == "P3_GRAPHS__BINF_2DLENORZER" )\
                        and len(thisline) == 4 and starkey == 1:
                if thisline[1] == "YES":
                    instructions[-1][1].append([    thisline[0],
                                                    thisline[2],
                                                    thisline[3]
                                                ])
                                        
            ### Leaves the "STAR" subfolder
            if thisline[0] == "END_STAR" and starkey == 1:
                starkey = 0
    
    return instructions




### 
if Part2:


    def inside_binflims(theta,binflims):
        """
        This function returns True if 'theta' is inside the limits 
        defined by 'binflims' and False otherwise.
        """
        if      binflims[0][0] <= theta[0] <= binflims[0][1] and \
                binflims[1][0] <= theta[1] <= binflims[1][1] and \
                binflims[2][0] <= theta[2] <= binflims[2][1] and \
                binflims[3][0] <= theta[3] <= binflims[3][1] and \
                binflims[4][0] <= theta[4] <= binflims[4][1]:
            return True
        else:
            return False





    ######################

    def BINF_ALPHAW3W4_W3_procedure(DATA_LBAND_now,\
            nwalkers, Nchain, folder_output, suffix,\
            binflims):
        """
        This function does bayesian inference using the observables
        alphaW3w4 and MW3 only. 
        It does it for a specific star in our database.
        It prints the results of emcee in an external file.
        """
    
        ### Type of interpolation and "allowing extrapolation" for the 
        ### bayesian inference.
        tp = "linear"
        allow_extrapolation = "yes"
    
        ###################
        ### Posterior for measuring alphaW3W4 and MW3:
        def lnposterior(theta, x, sigmax, interpars, binflims, other, Nchain):
        
            ### Printing the progress bar on the screen
            sys.stdout.write("\rSAMPLING: {:2.3%}".\
                        format(float(sampler.iteration+1)/float(Nchain))+"     ")
            sys.stdout.flush()
        
            ### If there are NaNs in the data, the probability is zero:
            if np.isnan(x[0]) or np.isnan(x[1]) or \
                    np.isnan(sigmax[0]) or np.isnan(sigmax[1]):
                return -np.inf
        
            ### Imposing the walkers to be inside the hyperrectangle 
            ### defined by 'binflims':
            is_inside = inside_binflims(theta, binflims)
            if not is_inside:
                return -np.inf
            
            ### Calculating the prior
            lnpr=lnprior(theta, other)
            ### If the prior isn't zero, calculate the likelihood also.
            if np.isinf(-lnpr):
                return lnpr
            else:
                return lnpr+lnlikelihood(theta, x, sigmax, interpars)


        ### Likelihood function for alphaW3W4 and MW3
        def lnlikelihood(theta, x, sigmax, interpars):
        
            ### 
            values1 = interpars[0]
            values2 = interpars[1]
            axis = interpars[2]
            tp = interpars[3]
            allow_extrapolation = interpars[4]

            ### alphaW3W4
            xmod0 = lrr.interpLinND(theta,axis,values1,tp,allow_extrapolation)
            ### MW3
            if np.isnan(xmod0):
                xmod1 = np.nan
            else:
                xmod1 = lrr.interpLinND(theta,axis,values2,tp,allow_extrapolation)
    
    
            if (not np.isnan(xmod0)) and (not np.isnan(xmod1)):
                return -0.5*(
                            ((xmod0-x[0])/sigmax[0])*((xmod0-x[0])/sigmax[0])+\
                            ((xmod1-x[1])/sigmax[1])*((xmod1-x[1])/sigmax[1])\
                            )
            else:
                return -np.inf
        ###################
    
    
    

        ### The domain of the grids:
        npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
        ### Converting strings to float
        npar_vals = np.array([float(x) for x in npar])
        logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
                for x in sigpar])
        Mpar_vals = np.array([float(x) for x in Mpar])
        obpar_vals = np.array([float(x) for x in obpar])
        cosipar_vals = np.array([float(x) for x in cosipar])

        ### Defining the domain of the grid
        axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
        ndim = len(axis)

        ### Attributing values for every element of the grid
        vals_alphaW3W4 = []
        vals_MW3 = []
        i4 = obpar.index("1.40")
        for i1 in range(0,len(npar_vals)):
            for i2 in range(0,len(logsigpar_vals)):
                for i3 in range(0,len(Mpar_vals)):
                    for i4_notused in range(0,len(obpar_vals)):
                        for i5 in range(0,len(cosipar_vals)):
                            vals_alphaW3W4.append(ALPHA_WISE[i1,i2,i3,i4,i5,2])
                            vals_MW3.append(WISE[i1,i2,i3,i4,i5,2])
    
        ### Turn this on to fill the NaNs in the values (probably due to 
        ### the fact that the grid was not entirely computed).
        if 1==1:
            ### folder for printing the results
            folder_filledNaNs = "./extrap01/"
            ### Below, "yes" means printing the progress of the 
            ### filling NaNs procedure
            prints = "yes"
            ### Allowing extrapolation for the filling the NaNs procedure
            allow_extrapolation_fill = "yes"
            ### filling the NaNs of alphaW3W4
            vals_alphaW3W4_name = "vals_alphaW3W4"
            vals_alphaW3W4 = fillingNaNs(folder_filledNaNs,\
                            vals_alphaW3W4_name,axis,\
                            vals_alphaW3W4,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of MW3
            vals_MW3_name = "vals_MW3"
            vals_MW3 = fillingNaNs(folder_filledNaNs,\
                            vals_MW3_name,axis,\
                            vals_MW3,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
    
    
    
        ### Data on this specific star (to go to bayesian inference)
        obs_alpha34 = DATA_LBAND_now[6][4][0]
        sig_alpha34 = DATA_LBAND_now[6][4][1]
        obs_MW3 = DATA_LBAND_now[6][5][4]
        sig_MW3 = DATA_LBAND_now[6][5][5]
        x = [obs_alpha34,obs_MW3]
        sigmax = [sig_alpha34,sig_MW3]
        ###
        interpars = [vals_alphaW3W4, vals_MW3, axis, tp, allow_extrapolation]
        other = [0.81, 0.12]
    
        ### Choose an initial set of positions for the walkers.
        ### (It is a list of ndim-dimensional lists.)
        p0 = [  [
                np.random.uniform(binflims[0][0],binflims[0][1]),
                np.random.uniform(binflims[1][0],binflims[1][1]),
                np.random.uniform(binflims[2][0],binflims[2][1]),
                np.random.uniform(binflims[3][0],binflims[3][1]),
                np.random.uniform(binflims[4][0],binflims[4][1])
                ] for i in range(nwalkers)
            ]
    
    
        ### Initializing the sampler with the chosen specs.
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnposterior,\
                args=[x, sigmax, interpars, binflims, other, Nchain])
        ### Sampling...
        print("SAMPLING for observables alphaW3W4 and MW3 of HD "+\
                DATA_LBAND_now[0]+"...")
        pos, prob, state = sampler.run_mcmc(p0, Nchain)
        print("\rSAMPLING: DONE         ")
        
        ### Writing results of the bayesian inference an external file,
        ### for future analysis
        writeline = []
        ### Printing the mean acceptance fraction
        ### (This number should be between 0.25 and 0.5)
        writeline.append("MAF "+str(np.mean(sampler.acceptance_fraction))+"\n")
        ### Printing the walkers's position for every element of the chain:
        for ichain in range(0,len(sampler.chain[0])):
            for iwalker in range(0,len(sampler.chain)):
                writeline.append(\
                        str(sampler.lnprobability[iwalker][ichain])+" "+\
                        str(sampler.chain[iwalker][ichain][0])+" "+\
                        str(sampler.chain[iwalker][ichain][1])+" "+\
                        str(sampler.chain[iwalker][ichain][2])+" "+\
                        str(sampler.chain[iwalker][ichain][3])+" "+\
                        str(sampler.chain[iwalker][ichain][4])+"\n"\
                        )
        output_filename = folder_output+\
            "BINF_ALPHAW3W4_W3__"+DATA_LBAND_now[0]+"__"+suffix+".out"
        f1 = open(output_filename,"w")
        for iwrite in range(0,len(writeline)):
            f1.write(writeline[iwrite])
        f1.close()
    
    
    
    
    
    
        ### Turn this on to see the evolution of the probabilities 
        if 1==1:
            lnprobability = sampler.lnprobability
    
            poslnprob=np.arange(1,len(lnprobability[0])+1)
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
        
            for iwalker in range(0,len(lnprobability)):
                plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][ichain]) \
                    for ichain in range(0,len(lnprobability[0]))], \
                    color='black', linewidth=0.05, linestyle='-')
            plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
            plt.xlabel("position in the chain")
            fig.savefig("convergencetwo_"+DATA_LBAND_now[0]+".png")
    
        ### Turn this on to make a corner plot of the results.
        if 1==1:
            if Nchain >= 1000:
                nburnin = 300
            if 0 <= Nchain < 1000:
                nburnin = int(
                Nchain*0.3)
            samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
            fig = corner.corner(samples, \
            labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
            "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
            fig.savefig("testeOne_"+DATA_LBAND_now[0]+".png")

        ### Turn this on to make a "CMD-WISE" plot of the results.
        if 1==2:
            if Nchain >= 1000:
                nburnin = 900
            if 0 <= Nchain < 1000:
                nburnin = int(Nchain*0.9)
            xx = []
            yy = []
            for ichain in range(nburnin,Nchain):
                for iwalker in range(0,len(sampler.chain)):
                    point = [   sampler.chain[iwalker][ichain][0],\
                                sampler.chain[iwalker][ichain][1],\
                                sampler.chain[iwalker][ichain][2],\
                                sampler.chain[iwalker][ichain][3],\
                                sampler.chain[iwalker][ichain][4]\
                            ]
                    xx.append(lrr.interpLinND(point,axis,vals_alphaW3W4,\
                            tp,allow_extrapolation))
                    yy.append(lrr.interpLinND(point,axis,vals_MW3,\
                            tp,allow_extrapolation))
    
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
            plt.scatter(xx,yy,alpha=np.nanmax([1./len(xx),2e-3]))
            plt.errorbar(obs_alpha34,obs_MW3,xerr=sig_alpha34,yerr=sig_MW3,\
                color="black",linewidth=2.0)
            plt.xlabel("$\\alpha_{W3-W4}$")
            plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
            plt.xlim([-5.,1.6])
            plt.ylim([0.,-7.])
            fig.savefig("CMD_WISE_"+DATA_LBAND_now[0]+".png")
        
    
        return 


    ######################

    def BINF_ALPHAL_BL_procedure(DATA_LBAND_now,\
            nwalkers, Nchain, folder_output, suffix,\
            binflims):
        """
        This function does bayesian inference using the observables
        alphaL and MBL only. 
        It does it for a specific star in our database.
        It prints the results of emcee in an external file.
        """
           ### Type of interpolation and "allowing extrapolation" for the 
        ### bayesian inference.
        tp = "linear"
        allow_extrapolation = "no"
    
        ###################
        ### Posterior for measuring alphaW3W4 and MW3:
        def lnposterior(theta, x, sigmax, interpars, binflims, other, Nchain):
        
            ### Printing the progress bar on the screen
            sys.stdout.write("\rSAMPLING: {:2.3%}".\
                        format(float(sampler.iteration+1)/float(Nchain))+"     ")
            sys.stdout.flush()
        
            ### If there are NaNs in the data, the probability is zero:
            if np.isnan(x[0]) or np.isnan(x[1]) or \
                    np.isnan(sigmax[0]) or np.isnan(sigmax[1]):
                return -np.inf
        
            ### Imposing the walkers to be inside the hyperrectangle 
            ### defined by 'binflims':
            is_inside = inside_binflims(theta, binflims)
            if not is_inside:
                return -np.inf
            
            ### Calculating the prior
            lnpr=lnprior(theta, other)
            ### If the prior isn't zero, calculate the likelihood also.
            if np.isinf(-lnpr):
                return lnpr
            else:
                return lnpr+lnlikelihood(theta, x, sigmax, interpars)


        ### Likelihood function for alphaW3W4 and MW3
        def lnlikelihood(theta, x, sigmax, interpars):
        
            ### 
            values1 = interpars[0]
            values2 = interpars[1]
            axis = interpars[2]
            tp = interpars[3]
            allow_extrapolation = interpars[4]

            ### alphaL
            xmod0 = lrr.interpLinND(theta,axis,values1,tp,allow_extrapolation)
            ### MBL
            if np.isnan(xmod0):
                xmod1 = np.nan
            else:
                xmod1 = lrr.interpLinND(theta,axis,values2,tp,allow_extrapolation)
    
    
            if (not np.isnan(xmod0)) and (not np.isnan(xmod1)):
                return -0.5*(
                            ((xmod0-x[0])/sigmax[0])*((xmod0-x[0])/sigmax[0])+\
                            ((xmod1-x[1])/sigmax[1])*((xmod1-x[1])/sigmax[1])\
                            )
            else:
                return -np.inf
        ###################
    
    
    

        ### The domain of the grids:
        npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
        ### Converting strings to float
        npar_vals = np.array([float(x) for x in npar])
        logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
                for x in sigpar])
        Mpar_vals = np.array([float(x) for x in Mpar])
        obpar_vals = np.array([float(x) for x in obpar])
        cosipar_vals = np.array([float(x) for x in cosipar])

        ### Defining the domain of the grid
        axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
        ndim = len(axis)

        ### Attributing values for every element of the grid
        vals_alphaL = []
        vals_MBL = []
        i4 = obpar.index("1.40")
        for i1 in range(0,len(npar_vals)):
            for i2 in range(0,len(logsigpar_vals)):
                for i3 in range(0,len(Mpar_vals)):
                    for i4_notused in range(0,len(obpar_vals)):
                        for i5 in range(0,len(cosipar_vals)):
                            vals_alphaL.append(ALPHA_WISE[i1,i2,i3,i4,i5])
                            vals_MBL.append(WISE[i1,i2,i3,i4,i5])
    
        ### Turn this on to fill the NaNs in the values (probably due to 
        ### the fact that the grid was not entirely computed).
        if 1==1:
            ### folder for printing the results
            folder_filledNaNs = "./extrap01/"
            ### Below, "yes" means printing the progress of the 
            ### filling NaNs procedure
            prints = "yes"
            ### Allowing extrapolation for the filling the NaNs procedure
            allow_extrapolation_fill = "yes"
            ### filling the NaNs of alphaW3W4
            vals_alphaL_name = "vals_alphaL"
            vals_alphaL = fillingNaNs(folder_filledNaNs,\
                            vals_alphaL_name,axis,\
                            vals_alphaL,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)

            ### filling the NaNs of MBL

            vals_MBL_name = "vals_MBL"
            vals_MBL = fillingNaNs(folder_filledNaNs,\
                            vals_MBL_name,axis,\
                            vals_MBL,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
    
    
    
        ### Data on this specific star (to go to bayesian inference)
        obs_alpha34 = DATA_LBAND_now[5][4][0]
        sig_alpha34 = DATA_LBAND_now[5][4][1]
        obs_MBL = DATA_LBAND_now[5][3][0]
        sig_MBL = DATA_LBAND_now[5][3][1]
        x = [obs_alpha34,obs_MBL]
        sigmax = [sig_alpha34,sig_MBL]
        ###
        interpars = [vals_alphaL, vals_MBL, axis, tp, allow_extrapolation]
        other = [0.81, 0.12]
    
        ### Choose an initial set of positions for the walkers.
        ### (It is a list of ndim-dimensional lists.)
        p0 = [  [
                np.random.uniform(binflims[0][0],binflims[0][1]),
                np.random.uniform(binflims[1][0],binflims[1][1]),
                np.random.uniform(binflims[2][0],binflims[2][1]),
                np.random.uniform(binflims[3][0],binflims[3][1]),
                np.random.uniform(binflims[4][0],binflims[4][1])
                ] for i in range(nwalkers)
            ]
    
    
        ### Initializing the sampler with the chosen specs.
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnposterior,\
                args=[x, sigmax, interpars, binflims, other, Nchain])
        ### Sampling...
        print("SAMPLING for observables alphaL and MBL of HD "+\
                DATA_LBAND_now[0]+"...")
        pos, prob, state = sampler.run_mcmc(p0, Nchain)
        print("\rSAMPLING: DONE         ")
        
        ### Writing results of the bayesian inference an external file,
        ### for future analysis
        writeline = []
        ### Printing the mean acceptance fraction
        ### (This number should be between 0.25 and 0.5)
        writeline.append("MAF "+str(np.mean(sampler.acceptance_fraction))+"\n")
        ### Printing the walkers's position for every element of the chain:
        for ichain in range(0,len(sampler.chain[0])):
            for iwalker in range(0,len(sampler.chain)):
                writeline.append(\
                        str(sampler.lnprobability[iwalker][ichain])+" "+\
                        str(sampler.chain[iwalker][ichain][0])+" "+\
                        str(sampler.chain[iwalker][ichain][1])+" "+\
                        str(sampler.chain[iwalker][ichain][2])+" "+\
                        str(sampler.chain[iwalker][ichain][3])+" "+\
                        str(sampler.chain[iwalker][ichain][4])+"\n"\
                        )
        output_filename = folder_output+\
            "BINF_ALPHAL_BL__"+DATA_LBAND_now[0]+"__"+suffix+".out"
        f1 = open(output_filename,"w")
        for iwrite in range(0,len(writeline)):
            f1.write(writeline[iwrite])
        f1.close()
    
    
    
    
    
    
        ### Turn this on to see the evolution of the probabilities 
        if 1==1:
            lnprobability = sampler.lnprobability
    
            poslnprob=np.arange(1,len(lnprobability[0])+1)
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
        
            for iwalker in range(0,len(lnprobability)):
                plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][ichain]) \
                    for ichain in range(0,len(lnprobability[0]))], \
                    color='black', linewidth=0.05, linestyle='-')
            plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
            plt.xlabel("position in the chain")
            fig.savefig("convergenceone_"+DATA_LBAND_now[0]+".png")
    
        ### Turn this on to make a corner plot of the results.
        if 1==1:
            if Nchain >= 1000:
                nburnin = 300
            if 0 <= Nchain < 1000:
                nburnin = int(Nchain*0.3)
            samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
            fig = corner.corner(samples, \
            labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
            "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
            fig.savefig("testetwo_"+DATA_LBAND_now[0]+".png")






        ### Turn this on to make a "CMD-WISE" plot of the results.
        if 1==2:
            if Nchain >= 1000:
                nburnin = 900
            if 0 <= Nchain < 1000:
                nburnin = int(Nchain*0.9)
            xx = []
            yy = []
            for ichain in range(nburnin,Nchain):
                for iwalker in range(0,len(sampler.chain)):
                    point = [   sampler.chain[iwalker][ichain][0],\
                                sampler.chain[iwalker][ichain][1],\
                                sampler.chain[iwalker][ichain][2],\
                                sampler.chain[iwalker][ichain][3],\
                                sampler.chain[iwalker][ichain][4]\
                            ]
                    xx.append(lrr.interpLinND(point,axis,vals_alphaW3W4,\
                            tp,allow_extrapolation))
                    yy.append(lrr.interpLinND(point,axis,vals_MW3,\
                            tp,allow_extrapolation))
    
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
            plt.scatter(xx,yy,alpha=np.nanmax([1./len(xx),2e-3]))
            plt.errorbar(obs_alpha34,obs_MW3,xerr=sig_alpha34,yerr=sig_MW3,\
                color="black",linewidth=2.0)
            plt.xlabel("$\\alpha_{W3-W4}$")
            plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
            plt.xlim([-5.,1.6])
            plt.ylim([0.,-7.])
            fig.savefig("CMD_WISE_"+DATA_LBAND_now[0]+".png")
        
    
        return 




    ######################

    def BINF_2DLENORZER_procedure(Lenor_data,DATA_LBAND_now,\
            nwalkers, Nchain, folder_output, suffix,\
            binflims):
        """
        This function does bayesian inference using the observables
        of the 2D Lenorzer diagram. 
        It does it for a specific star in our database.
        It prints the results of emcee in an external file.
        """
    
        ### Type of interpolation and "allowing extrapolation" for the 
        ### bayesian inference.
        tp = "linear"
        allow_extrapolation = "yes"
    
        ###################
        ### Posterior for measuring the observables of the 2D Lenorzer diagram:
        def lnposterior(theta, x, sigmax, interpars, binflims, other, Nchain):
        
            ### Printing the progress bar on the screen
            sys.stdout.write("\rSAMPLING: {:2.3%}".\
                        format(float(sampler.iteration+1)/float(Nchain))+"     ")
            sys.stdout.flush()
        
            ### If there are NaNs in the data, the probability is zero:
            if np.isnan(x[0]) or np.isnan(x[1]) or \
                    np.isnan(sigmax[0]) or np.isnan(sigmax[1]):
                return -np.inf
        
            ### Imposing the walkers to be inside the hyperrectangle 
            ### defined by 'binflims':
            is_inside = inside_binflims(theta, binflims)
            if not is_inside:
                return -np.inf
            
            ### Calculating the prior
            lnpr=lnprior(theta, other)
            ### If the prior isn't zero, calculate the likelihood also.
            if np.isinf(-lnpr):
                return lnpr
            else:
                return lnpr+lnlikelihood(theta, x, sigmax, interpars)


        ### Likelihood function for the observables of the 2D Lenorzer diagram
        def lnlikelihood(theta, x, sigmax, interpars):
        
            ### 
            values1 = interpars[0]
            values2 = interpars[1]
            axis = interpars[2]
            tp = interpars[3]
            allow_extrapolation = interpars[4]

            ### 
            xmod0 = lrr.interpLinND(theta,axis,values1,tp,allow_extrapolation)
            ### 
            if np.isnan(xmod0):
                xmod1 = np.nan
            else:
                xmod1 = lrr.interpLinND(theta,axis,values2,tp,allow_extrapolation)
    
    
            if (not np.isnan(xmod0)) and (not np.isnan(xmod1)):
                return -0.5*(
                            ((xmod0-x[0])/sigmax[0])*((xmod0-x[0])/sigmax[0])+\
                            ((xmod1-x[1])/sigmax[1])*((xmod1-x[1])/sigmax[1])\
                            )
            else:
                return -np.inf
        ###################
    
    
    

        ### The domain of the grids:
        npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
        ### Converting strings to float
        npar_vals = np.array([float(x) for x in npar])
        logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
                for x in sigpar])
        Mpar_vals = np.array([float(x) for x in Mpar])
        obpar_vals = np.array([float(x) for x in obpar])
        cosipar_vals = np.array([float(x) for x in cosipar])

        ### Defining the domain of the grid
        axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
        ndim = len(axis)

        ### Attributing values for every element of the grid
        vals_Hu14 = []
        vals_Bra = []
        vals_Pfg = []
        i4 = obpar.index("1.40")
        for i1 in range(0,len(npar_vals)):
            for i2 in range(0,len(logsigpar_vals)):
                for i3 in range(0,len(Mpar_vals)):
                    for i4_notused in range(0,len(obpar_vals)):
                        for i5 in range(0,len(cosipar_vals)):
                            vals_Hu14.append(LINE_HUMPHREY14[i1,i2,i3,i4,i5,0])
                            vals_Bra.append(LINE_BRALPHA[i1,i2,i3,i4,i5,0])
                            vals_Pfg.append(LINE_PFGAMMA[i1,i2,i3,i4,i5,0])
    
        ### Turn this on to fill the NaNs in the values (probably due to 
        ### the fact that the grid was not entirely computed).
        if 1==1:
            ### folder for printing the results
            folder_filledNaNs = "./extrap01/"
            ### Below, "yes" means printing the progress of the 
            ### filling NaNs procedure
            prints = "yes"
            ### Allowing extrapolation for the filling the NaNs procedure
            allow_extrapolation_fill = "yes"
            ### filling the NaNs of Hu14
            vals_Hu14_name = "vals_Hu14"
            vals_Hu14 = fillingNaNs(folder_filledNaNs,\
                            vals_Hu14_name,axis,\
                            vals_Hu14,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of Bra
            vals_Bra_name = "vals_Bra"
            vals_Bra = fillingNaNs(folder_filledNaNs,\
                            vals_Bra_name,axis,\
                            vals_Bra,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of Pfg
            vals_Pfg_name = "vals_Pfg"
            vals_Pfg = fillingNaNs(folder_filledNaNs,\
                            vals_Pfg_name,axis,\
                            vals_Pfg,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
    
        vals_Lenorx = []; vals_Lenory = []
        for ivals in range(0,len(vals_Hu14)):
            if not vals_Pfg[ivals] == 0.:
                vals_Lenorx.append(vals_Hu14[ivals]/vals_Pfg[ivals])
            else:
                vals_Lenorx.append(np.inf*np.sign(vals_Hu14[ivals]))

            if not vals_Bra[ivals] == 0.:
                vals_Lenory.append(vals_Hu14[ivals]/vals_Bra[ivals])
            else:
                vals_Lenory.append(np.inf*np.sign(vals_Hu14[ivals]))
    
    
        ### Data on this specific star (to go to bayesian inference)
        obs_x = Lenor_data[0]
        sig_x = Lenor_data[1]
        obs_y = Lenor_data[2]
        sig_y = Lenor_data[3]
        x = [obs_x,obs_y]
        sigmax = [sig_x,sig_y]
        ### 
        interpars = [vals_Lenorx, vals_Lenory, axis, tp, allow_extrapolation]
        other = [0.81, 0.12]
    
        ### Choose an initial set of positions for the walkers.
        ### (It is a list of ndim-dimensional lists.)
        p0 = [  [
                np.random.uniform(binflims[0][0],binflims[0][1]),
                np.random.uniform(binflims[1][0],binflims[1][1]),
                np.random.uniform(binflims[2][0],binflims[2][1]),
                np.random.uniform(binflims[3][0],binflims[3][1]),
                np.random.uniform(binflims[4][0],binflims[4][1])
                ] for i in range(nwalkers)
            ]
    
    
        ### Initializing the sampler with the chosen specs.
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnposterior,\
                args=[x, sigmax, interpars, binflims, other, Nchain])
        ### Sampling...
        print("SAMPLING for the observables of the 2D Lenorzer diagram of HD "+\
                DATA_LBAND_now[0]+"...")
        pos, prob, state = sampler.run_mcmc(p0, Nchain)
        print("\rSAMPLING: DONE         ")
        
        ### Writing results of the bayesian inference an external file,
        ### for future analysis
        writeline = []
        ### Printing the mean acceptance fraction
        ### (This number should be between 0.25 and 0.5)
        writeline.append("MAF "+str(np.mean(sampler.acceptance_fraction))+"\n")
        ### Printing the walkers's position for every element of the chain:
        for ichain in range(0,len(sampler.chain[0])):
            for iwalker in range(0,len(sampler.chain)):
                writeline.append(\
                        str(sampler.lnprobability[iwalker][ichain])+" "+\
                        str(sampler.chain[iwalker][ichain][0])+" "+\
                        str(sampler.chain[iwalker][ichain][1])+" "+\
                        str(sampler.chain[iwalker][ichain][2])+" "+\
                        str(sampler.chain[iwalker][ichain][3])+" "+\
                        str(sampler.chain[iwalker][ichain][4])+"\n"\
                        )
        output_filename = folder_output+\
            "BINF_2DLENORZER__"+DATA_LBAND_now[0]+"__"+suffix+".out"
        f1 = open(output_filename,"w")
        for iwrite in range(0,len(writeline)):
            f1.write(writeline[iwrite])
        f1.close()
    
    
    
    
    
    
        ### Turn this on to see the evolution of the probabilities 
        if 1==1:
            lnprobability = sampler.lnprobability
    
            poslnprob=np.arange(1,len(lnprobability[0])+1)
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
        
            for iwalker in range(0,len(lnprobability)):
                plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][ichain]) \
                    for ichain in range(0,len(lnprobability[0]))], \
                    color='black', linewidth=0.05, linestyle='-')
            plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
            plt.xlabel("position in the chain")
            fig.savefig("convergencetwo_"+DATA_LBAND_now[0]+".png")
    
        ### Turn this on to make a corner plot of the results.
        if 1==1:
            if Nchain >= 1000:
                nburnin = 300
            if 0 <= Nchain < 1000:
                nburnin = int(
                Nchain*0.3)
            samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
            fig = corner.corner(samples, \
            labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
            "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
            fig.savefig("testeOne_"+DATA_LBAND_now[0]+".png")

        ### Turn this on to make a "CMD-WISE" plot of the results.
        if 1==2:
            if Nchain >= 1000:
                nburnin = 900
            if 0 <= Nchain < 1000:
                nburnin = int(Nchain*0.9)
            xx = []
            yy = []
            for ichain in range(nburnin,Nchain):
                for iwalker in range(0,len(sampler.chain)):
                    point = [   sampler.chain[iwalker][ichain][0],\
                                sampler.chain[iwalker][ichain][1],\
                                sampler.chain[iwalker][ichain][2],\
                                sampler.chain[iwalker][ichain][3],\
                                sampler.chain[iwalker][ichain][4]\
                            ]
                    xx.append(lrr.interpLinND(point,axis,vals_alphaW3W4,\
                            tp,allow_extrapolation))
                    yy.append(lrr.interpLinND(point,axis,vals_MW3,\
                            tp,allow_extrapolation))
    
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
            plt.scatter(xx,yy,alpha=np.nanmax([1./len(xx),2e-3]))
            plt.errorbar(obs_alpha34,obs_MW3,xerr=sig_alpha34,yerr=sig_MW3,\
                color="black",linewidth=2.0)
            plt.xlabel("$\\alpha_{W3-W4}$")
            plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
            plt.xlim([-5.,1.6])
            plt.ylim([0.,-7.])
            fig.savefig("CMD_WISE_"+DATA_LBAND_now[0]+".png")
        
    
        return 




    ######################

    def BINF_WISEBESS_procedure(DATA_LBAND_now,\
            nwalkers, Nchain, folder_output, suffix,\
            binflims):
        """
        This function does bayesian inference using the observables
        WISE and BeSS only. 
        It does it for a specific star in our database.
        It prints the results of emcee in an external file.
        """
    
        ### Type of interpolation and "allowing extrapolation" for the 
        ### bayesian inference.
        tp = "linear"
        allow_extrapolation = "no"
    
        ###################
        ### Posterior for measuring WISE and BeSS:
        def lnposterior(theta, x, sigmax, interpars, binflims, other, Nchain):
        
            ### Printing the progress bar on the screen
            sys.stdout.write("\rSAMPLING: {:2.3%}".\
                        format(float(sampler.iteration+1)/float(Nchain))+"     ")
            sys.stdout.flush()
        
            ### If there are NaNs in the data, the probability is zero:
            if np.isnan(x[0]) or np.isnan(x[1]) or np.isnan(x[2]) or \
                    np.isnan(x[3]) or np.isnan(x[4]) or\
                    np.isnan(sigmax[0]) or np.isnan(sigmax[1]) or \
                    np.isnan(sigmax[2]) or np.isnan(sigmax[3]) or \
                    np.isnan(sigmax[4]):
                return -np.inf
        
            ### Imposing the walkers to be inside the hyperrectangle 
            ### defined by 'binflims':
            is_inside = inside_binflims(theta, binflims)
            if not is_inside:
                return -np.inf
            
            ### Calculating the prior
            lnpr=lnprior(theta, other)
            ### If the prior isn't zero, calculate the likelihood also.
            if np.isinf(-lnpr):
                return lnpr
            else:
                return lnpr+lnlikelihood(theta, x, sigmax, interpars)


        ### Likelihood function for WISE and BeSS
        def lnlikelihood(theta, x, sigmax, interpars):
        
            ### 
            values1 = interpars[0]
            values2 = interpars[1]
            values3 = interpars[2]
            values4 = interpars[3]
            values5 = interpars[4]
            axis = interpars[5]
            tp = interpars[6]
            allow_extrapolation = interpars[7]

            ### alphaW3W4
            xmod0 = lrr.interpLinND(theta,axis,values1,tp,allow_extrapolation)
            ### MW3
            if np.isnan(xmod0):
                xmod1 = np.nan
            else:
                xmod1 = lrr.interpLinND(theta,axis,values2,tp,allow_extrapolation)
            ### EWHalpha
            if np.isnan(xmod0) or np.isnan(xmod1):
                xmod2 = np.nan
            else:
                xmod2 = lrr.interpLinND(theta,axis,values3,tp,allow_extrapolation)
            ### PSHalpha
            if np.isnan(xmod0) or np.isnan(xmod1) or np.isnan(xmod2):
                xmod3 = np.nan
            else:
                xmod3 = lrr.interpLinND(theta,axis,values4,tp,allow_extrapolation)
            ### FWHMHalpha
            if np.isnan(xmod0) or np.isnan(xmod1) or np.isnan(xmod2) or np.isnan(xmod3):
                xmod4 = np.nan
            else:
                xmod4 = lrr.interpLinND(theta,axis,values5,tp,allow_extrapolation)
                
            ### 
            if (not np.isnan(xmod0)) and (not np.isnan(xmod1)) and \
                    (not np.isnan(xmod2)) and (not np.isnan(xmod3)) and \
                    (not np.isnan(xmod4)):
                return -0.5*(
                            ((xmod0-x[0])/sigmax[0])*((xmod0-x[0])/sigmax[0])+\
                            ((xmod1-x[1])/sigmax[1])*((xmod1-x[1])/sigmax[1])+\
                            ((xmod2-x[2])/sigmax[2])*((xmod2-x[2])/sigmax[2])+\
                            ((xmod3-x[3])/sigmax[3])*((xmod3-x[3])/sigmax[3])+\
                            ((xmod4-x[4])/sigmax[4])*((xmod4-x[4])/sigmax[4])\
                            )
            else:
                return -np.inf
        ###################
    
    
    

        ### The domain of the grids:
        npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
        ### Converting strings to float
        npar_vals = np.array([float(x) for x in npar])
        logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
                for x in sigpar])
        Mpar_vals = np.array([float(x) for x in Mpar])
        obpar_vals = np.array([float(x) for x in obpar])
        cosipar_vals = np.array([float(x) for x in cosipar])

        ### Defining the domain of the grid
        axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
        ndim = len(axis)

        ### Attributing values for every element of the grid
        vals_alphaW3W4 = []
        vals_MW3 = []
        vals_FWHMHalpha = []
        vals_PSHalpha = []
        vals_EWHalpha = []
        i4 = obpar.index("1.40")
        for i1 in range(0,len(npar_vals)):
            for i2 in range(0,len(logsigpar_vals)):
                for i3 in range(0,len(Mpar_vals)):
                    for i4_notused in range(0,len(obpar_vals)):
                        for i5 in range(0,len(cosipar_vals)):
                            vals_alphaW3W4.append(ALPHA_WISE[i1,i2,i3,i4,i5,2])
                            vals_MW3.append(WISE[i1,i2,i3,i4,i5,2])
                            vals_FWHMHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,3])
                            vals_PSHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,2])
                            vals_EWHalpha.append(LINE_HALPHA[i1,i2,i3,i4,i5,1])
    
        ### Turn this on to fill the NaNs in the values (probably due to 
        ### the fact that the grid was not entirely computed).
        if 1==1:
            ### folder for printing the results
            folder_filledNaNs = "./extrap01/"
            ### Below, "yes" means printing the progress of the 
            ### filling NaNs procedure
            prints = "yes"
            ### Allowing extrapolation for the filling the NaNs procedure
            allow_extrapolation_fill = "yes"
            ### filling the NaNs of alphaW3W4
            vals_alphaW3W4_name = "vals_alphaW3W4"
            vals_alphaW3W4 = fillingNaNs(folder_filledNaNs,\
                            vals_alphaW3W4_name,axis,\
                            vals_alphaW3W4,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of MW3
            vals_MW3_name = "vals_MW3"
            vals_MW3 = fillingNaNs(folder_filledNaNs,\
                            vals_MW3_name,axis,\
                            vals_MW3,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of FWHMHalpha
            vals_FWHMHalpha_name = "vals_FWHMHalpha"
            vals_FWHMHalpha = fillingNaNs(folder_filledNaNs,\
                            vals_FWHMHalpha_name,axis,\
                            vals_FWHMHalpha,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of PSHalpha
            vals_PSHalpha_name = "vals_PSHalpha"
            vals_PSHalpha = fillingNaNs(folder_filledNaNs,\
                            vals_PSHalpha_name,axis,\
                            vals_PSHalpha,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)
            ### filling the NaNs of EWHalpha
            vals_EWHalpha_name = "vals_EWHalpha"
            vals_EWHalpha = fillingNaNs(folder_filledNaNs,\
                            vals_EWHalpha_name,axis,\
                            vals_EWHalpha,\
                            tp,allow_extrapolation_fill,prints,overwrite = False)

    
        ### Data on this specific star (to go to bayesian inference)
        obs_alpha34 = DATA_LBAND_now[6][4][0]
        sig_alpha34 = DATA_LBAND_now[6][4][1]
        obs_MW3 = DATA_LBAND_now[6][5][4]
        sig_MW3 = DATA_LBAND_now[6][5][5]
        obs_EWHalpha = DATA_LBAND_now[10][0]
        sig_EWHalpha = DATA_LBAND_now[10][1]
        obs_PSHalpha = DATA_LBAND_now[10][2]
        sig_PSHalpha = DATA_LBAND_now[10][3]
        obs_FWHMHalpha = DATA_LBAND_now[10][4]
        sig_FWHMHalpha = DATA_LBAND_now[10][5]
        x = [obs_alpha34,obs_MW3,obs_EWHalpha,obs_PSHalpha,obs_FWHMHalpha]
        sigmax = [sig_alpha34,sig_MW3,sig_EWHalpha,sig_PSHalpha,sig_FWHMHalpha]
        ###
        interpars = [vals_alphaW3W4, vals_MW3, vals_EWHalpha, \
                vals_PSHalpha, vals_FWHMHalpha, \
                axis, tp, allow_extrapolation]
        other = [0.81, 0.12]
    
        ### Choose an initial set of positions for the walkers.
        ### (It is a list of ndim-dimensional lists.)
        p0 = [  [
                np.random.uniform(binflims[0][0],binflims[0][1]),
                np.random.uniform(binflims[1][0],binflims[1][1]),
                np.random.uniform(binflims[2][0],binflims[2][1]),
                np.random.uniform(binflims[3][0],binflims[3][1]),
                np.random.uniform(binflims[4][0],binflims[4][1])
                ] for i in range(nwalkers)
            ]
    
    
        ### Initializing the sampler with the chosen specs.
        sampler = emcee.EnsembleSampler(nwalkers, ndim, lnposterior,\
                args=[x, sigmax, interpars, binflims, other, Nchain])
        ### Sampling...
        print("SAMPLING for observables WISE and BeSS of HD "+\
                DATA_LBAND_now[0]+"...")
        pos, prob, state = sampler.run_mcmc(p0, Nchain)
        print("\rSAMPLING: DONE         ")
        
        ### Writing results of the bayesian inference an external file,
        ### for future analysis
        writeline = []
        ### Printing the mean acceptance fraction
        ### (This number should be between 0.25 and 0.5)
        writeline.append("MAF "+str(np.mean(sampler.acceptance_fraction))+"\n")
        ### Printing the walkers's position for every element of the chain:
        for ichain in range(0,len(sampler.chain[0])):
            for iwalker in range(0,len(sampler.chain)):
                writeline.append(\
                        str(sampler.lnprobability[iwalker][ichain])+" "+\
                        str(sampler.chain[iwalker][ichain][0])+" "+\
                        str(sampler.chain[iwalker][ichain][1])+" "+\
                        str(sampler.chain[iwalker][ichain][2])+" "+\
                        str(sampler.chain[iwalker][ichain][3])+" "+\
                        str(sampler.chain[iwalker][ichain][4])+"\n"\
                        )
        output_filename = folder_output+\
            "BINF_WISEBESS__"+DATA_LBAND_now[0]+"__"+suffix+".out"
        f1 = open(output_filename,"w")
        for iwrite in range(0,len(writeline)):
            f1.write(writeline[iwrite])
        f1.close()
    
    
    
    
    
    
        ### Turn this on to see the evolution of the probabilities 
        if 1==1:
            lnprobability = sampler.lnprobability
    
            poslnprob=np.arange(1,len(lnprobability[0])+1)
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
        
            for iwalker in range(0,len(lnprobability)):
                plt.plot(poslnprob,[np.arcsinh(lnprobability[iwalker][ichain]) \
                    for ichain in range(0,len(lnprobability[0]))], \
                    color='black', linewidth=0.05, linestyle='-')
            plt.ylabel("$\\arcsinh(\\ln(\\mathrm{prob}))$")
            plt.xlabel("position in the chain")
            fig.savefig("convergencetwo_"+DATA_LBAND_now[0]+".png")
    
        ### Turn this on to make a corner plot of the results.
        if 1==1:
            if Nchain >= 1000:
                nburnin = 300
            if 0 <= Nchain < 1000:
                nburnin = int(
                Nchain*0.3)
            samples = sampler.chain[:, nburnin:, :].reshape((-1, ndim))
            fig = corner.corner(samples, \
            labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
            "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
            fig.savefig("testeOne_"+DATA_LBAND_now[0]+".png")

        ### Turn this on to make a "CMD-WISE" plot of the results.
        if 1==2:
            if Nchain >= 1000:
                nburnin = 900
            if 0 <= Nchain < 1000:
                nburnin = int(Nchain*0.9)
            xx = []
            yy = []
            for ichain in range(nburnin,Nchain):
                for iwalker in range(0,len(sampler.chain)):
                    point = [   sampler.chain[iwalker][ichain][0],\
                                sampler.chain[iwalker][ichain][1],\
                                sampler.chain[iwalker][ichain][2],\
                                sampler.chain[iwalker][ichain][3],\
                                sampler.chain[iwalker][ichain][4]\
                            ]
                    xx.append(lrr.interpLinND(point,axis,vals_alphaW3W4,\
                            tp,allow_extrapolation))
                    yy.append(lrr.interpLinND(point,axis,vals_MW3,\
                            tp,allow_extrapolation))
    
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
            plt.scatter(xx,yy,alpha=np.nanmax([1./len(xx),2e-3]))
            plt.errorbar(obs_alpha34,obs_MW3,xerr=sig_alpha34,yerr=sig_MW3,\
                color="black",linewidth=2.0)
            plt.xlabel("$\\alpha_{W3-W4}$")
            plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
            plt.xlim([-5.,1.6])
            plt.ylim([0.,-7.])
            fig.savefig("CMD_WISE_"+DATA_LBAND_now[0]+".png")
        
    
        return 

    

    ######################




    ### Getting instructions of operations to be applied to the data on
    ### Be stars.
    instructions = get_instructions(operations_on_stars)
    ### Reading the data on our Be stars
    data_folder, HDnames, Starnames, SIMBAD_Spt, YYYYMMDD_LBAND = \
                    read_data.List_Stars("stars")
    DATA_LBAND = read_data.returnDATA_LBAND()
    fluxhumphreys, EWhumphreys, GFWHMhumphreys, \
                fluxBra, EWBra, GFWHMBra, \
                fluxPfg, EWPfg, GFWHMPfg = read_data.LBAND_lines_extract(DATA_LBAND)
                

    ### Now, this is the part in which the instructions are executed.
    for iinst in range(0,len(instructions)):
        intructs_now = [x for x in instructions[iinst]]
        istar = HDnames.index(intructs_now[0])
    
        ### Loop over the instructions for this specific Be star
        for iinow in range(0,len(intructs_now[1])):
            ### Instructions: bayesian inference with the observables
            ### alphaW3W4 and MW3.
            if intructs_now[1][iinow][0] == "BINF_ALPHAW3W4_W3":
                ### 
                ndim = 5 
                DATA_LBAND_now = [x for x in DATA_LBAND[istar]]
                nwalkers = int(intructs_now[1][iinow][1])*2*ndim
                Nchain = int(intructs_now[1][iinow][2])
                folder_output = intructs_now[1][iinow][3]
                suffix = intructs_now[1][iinow][4]
                ### Hyperrectangular limits for the bayesian inference.
                binflims = [
                        [3.0,4.5],
                        [read_data.newlog10abs(0.02,1e5),\
                                read_data.newlog10abs(4.00,1e5)],
                        [4.2,14.6],
                        [1.2,1.4],
                        [0.26,1.00]
                        ]
                ### 
                BINF_ALPHAW3W4_W3_procedure(DATA_LBAND_now,\
                        nwalkers, Nchain, folder_output, suffix,\
                        binflims)
        
            ### TODO: Fredy should complete this...
            if intructs_now[1][iinow][0] == "BINF_ALPHAL_BL":
                ### 
                ndim = 5
                DATA_LBAND_now = [x for x in DATA_LBAND[istar]]
                nwalkers = int(intructs_now[1][iinow][1])*2*ndim
                Nchain = int(intructs_now[1][iinow][2])
                folder_output = intructs_now[1][iinow][3]
                suffix = intructs_now[1][iinow][4]
         
                ### TODO (Fredy)
                ### Call procedure for bayesian inference
                ### Hyperrectangular limits for the bayesian inference.
                binflims = [
                        [3.0,4.5],
                        [read_data.newlog10abs(0.02,1e5),\
                                read_data.newlog10abs(4.00,1e5)],
                        [4.2,14.6],
                        [1.2,1.4],
                        [0.26,1.00]
                        ]

                ### 
                BINF_ALPHAL_BL_procedure(DATA_LBAND_now,\
                        nwalkers, Nchain, folder_output, suffix,\
                        binflims)


            ### Instructions: bayesian inference with the observables
            ### of the 2D Lenorzer diagram.
            if intructs_now[1][iinow][0] == "BINF_2DLENORZER":
                
                yLenor = fluxhumphreys[istar][14][0]/fluxBra[istar][0]
                xLenor = fluxhumphreys[istar][14][0]/fluxPfg[istar][0]
                sig_yLenor = read_data.err_frac(fluxhumphreys[istar][14][0],\
                        fluxBra[istar][0],fluxhumphreys[istar][14][1],\
                        fluxBra[istar][1])
                sig_xLenor = read_data.err_frac(fluxhumphreys[istar][14][0],\
                        fluxPfg[istar][0],fluxhumphreys[istar][14][1],\
                        fluxPfg[istar][1])
                        
                Lenor_data = [xLenor,sig_xLenor,yLenor,sig_yLenor]
                
                ### 
                ndim = 5 
                DATA_LBAND_now = [x for x in DATA_LBAND[istar]]
                nwalkers = int(intructs_now[1][iinow][1])*2*ndim
                Nchain = int(intructs_now[1][iinow][2])
                folder_output = intructs_now[1][iinow][3]
                suffix = intructs_now[1][iinow][4]
                ### Hyperrectangular limits for the bayesian inference.
                binflims = [
                        [3.0,4.5],
                        [read_data.newlog10abs(0.02,1e5),\
                                read_data.newlog10abs(4.00,1e5)],
                        [4.2,14.6],
                        [1.2,1.4],
                        [0.26,1.00]
                        ]
                ### 
                BINF_2DLENORZER_procedure(Lenor_data,DATA_LBAND_now,\
                        nwalkers, Nchain, folder_output, suffix,\
                        binflims)


            ### Instructions: bayesian inference with the observables
            ### WISE + BeSS.
            if intructs_now[1][iinow][0] == "BINF_WISEBESS":
                ### 
                ndim = 5 
                DATA_LBAND_now = [x for x in DATA_LBAND[istar]]
                nwalkers = int(intructs_now[1][iinow][1])*2*ndim
                Nchain = int(intructs_now[1][iinow][2])
                folder_output = intructs_now[1][iinow][3]
                suffix = intructs_now[1][iinow][4]
                ### Hyperrectangular limits for the bayesian inference.
                binflims = [
                    [3.0,4.5],\
                    [read_data.newlog10abs(0.02,1e5),\
                            read_data.newlog10abs(4.00,1e5)],\
                    [4.2,14.6],\
                    [1.2,1.4],\
                    [0.26,1.00]
                            ]
                ### 
                BINF_WISEBESS_procedure(DATA_LBAND_now,\
                        nwalkers, Nchain, folder_output, suffix,\
                        binflims)
















##########################################################
##########################################################
### Now, comes the part 3 of the analysis: analysis of the results 
### of the operations performed on the stars.

Part3 = False
if Part3:

    def other_thetas(W_lnprobs,W_theta,nburnin_fac):
    
        ### 
        Ndim = len(W_theta[0])
        W_theta_v2 = [[] for idim in range(0,Ndim)]
        for elem in W_theta:
            for idim in range(0,Ndim):
                W_theta_v2[idim].append(elem[idim])
        ### 
        Nnew = np.nanmin([5000,int((1-nburnin_fac)*len(W_theta_v2[0]))])
        reduced_W_theta_v2 = [[] for idim in range(0,Ndim)]
        reduced_W_lnprobs = []
        for ipoint in range(0,Nnew):
            for idim in range(0,Ndim):
                reduced_W_theta_v2[idim].append(W_theta_v2[idim][-1-ipoint])
            reduced_W_lnprobs.append(W_lnprobs[-1-ipoint])
                    
        return Ndim,W_theta_v2,reduced_W_theta_v2,reduced_W_lnprobs

    def theta_stats(reduced_W_theta_v2,val_analysis,Ndim,nburnin_fac):
        """
        
        """
        
        ### 
        if val_analysis == "HDR":
            bound_list = []
            val_list = []
            for idim in range(0,Ndim):
                hpd, x, y, modes = read_data.hpd_grid(reduced_W_theta_v2[idim], \
                        alpha=0.05, roundto=7)  
                bound_list.append(hpd)
                val_list.append(modes)
                print(val_list[-1],bound_list[-1])
        ### 
        elif val_analysis == "std":
            bound_list = []
            val_list = []
            for idim in range(0,Ndim):
                median = np.percentile(reduced_W_theta_v2[idim],50)
                per84 = np.percentile(reduced_W_theta_v2[idim],84)
                per16 = np.percentile(reduced_W_theta_v2[idim],16)
                bound_list.append([(per16,per84)])
                val_list.append([median])
                print(val_list[-1],bound_list[-1])
        ### 
        else:
            bound_list = []
            val_list = []        
            for idim in range(0,Ndim):
                bound_list.append([(np.nan,np.nan)])
                val_list.append([np.nan])
                    
        return val_list,bound_list



    def P3_GRAPHS__BINF_ALPHAW3W4_W3_procedure(intructs_now,\
            DATA_LBAND_now,W_lnprobs,W_theta,MAF):
        """
        This function does graphs and calculations for the bayesian 
        inference performed in Part 2 for
        alphaW3w4 and MW3 only. 
        It does it for a specific star in our database.
        It prints the results of emcee in an external file.
        """
        
        ### 
        figures_folder = "figures/"
        val_analysis = "HDR"
        
        ### 
        nburnin_fac = 0.3
        ### 
        Ndim,W_theta_v2,reduced_W_theta_v2,reduced_W_lnprobs = \
                other_thetas(W_lnprobs,W_theta,nburnin_fac)
        ### 
        val_list,bound_list = \
                theta_stats(reduced_W_theta_v2,val_analysis,Ndim,nburnin_fac)
                        
        
    
        ### Turn this on to make a corner plot of the results.
        if 1==1:
            nburnin = int(nburnin_fac*len(W_theta))
            samples = [W_theta[i] for i in range(nburnin,len(W_theta))]
            fig = corner.corner(samples, \
            labels = ["$n$","$\log(\\Sigma\,[\mathrm{g\,cm^{-2}}])$",\
            "$M\,[M_\odot]$","$1+0.5W^2$","$\cos i$"], bins=60)
            iinstr = [x[0] for x in intructs_now[1]].\
                    index("P3_GRAPHS__BINF_ALPHAW3W4_W3")
            fig.savefig(intructs_now[1][iinstr][1]+figures_folder+\
                    "cornertheta__"+DATA_LBAND_now[0]+"__"+\
                    intructs_now[1][iinstr][2]+".png")



        ### Type of interpolation and "allowing extrapolation" for the 
        ### bayesian inference.
        tp = "linear"
        allow_extrapolation = "yes"

        ### The domain of the grids:
        npar, sigpar, Mpar, obpar, cosipar = read_everything.domain_PLgrid()
        ### Converting strings to float
        npar_vals = np.array([float(x) for x in npar])
        logsigpar_vals = np.array([read_data.newlog10abs(float(x),1e5) \
                for x in sigpar])
        Mpar_vals = np.array([float(x) for x in Mpar])
        obpar_vals = np.array([float(x) for x in obpar])
        cosipar_vals = np.array([float(x) for x in cosipar])

        ### Defining the domain of the grid
        axis = [npar_vals,logsigpar_vals,Mpar_vals,obpar_vals,cosipar_vals]
        ndim = len(axis)


        ### Turn this on to make a "CMD-WISE" plot of the results.
        if 1==1:

            ### Attributing values for every element of the grid
            vals_alphaW3W4 = []
            vals_MW3 = []
            i4 = obpar.index("1.40")
            for i1 in range(0,len(npar_vals)):
                for i2 in range(0,len(logsigpar_vals)):
                    for i3 in range(0,len(Mpar_vals)):
                        for i4_notused in range(0,len(obpar_vals)):
                            for i5 in range(0,len(cosipar_vals)):
                                vals_alphaW3W4.append(ALPHA_WISE[i1,i2,i3,i4,i5,2])
                                vals_MW3.append(WISE[i1,i2,i3,i4,i5,2])
        
            ### Turn this on to fill the NaNs in the values (probably due to 
            ### the fact that the grid was not entirely computed).
            if 1==1:
                ### folder for printing the results
                folder_filledNaNs = "./extrap01/"
                ### Below, "yes" means printing the progress of the 
                ### filling NaNs procedure
                prints = "yes"
                ### Allowing extrapolation for the filling the NaNs procedure
                allow_extrapolation_fill = "yes"
                ### filling the NaNs of alphaW3W4
                vals_alphaW3W4_name = "vals_alphaW3W4"
                vals_alphaW3W4 = fillingNaNs(folder_filledNaNs,\
                                vals_alphaW3W4_name,axis,\
                                vals_alphaW3W4,\
                                tp,allow_extrapolation_fill,prints,\
                                overwrite = False)
                ### filling the NaNs of MW3
                vals_MW3_name = "vals_MW3"
                vals_MW3 = fillingNaNs(folder_filledNaNs,\
                                vals_MW3_name,axis,\
                                vals_MW3,\
                                tp,allow_extrapolation_fill,prints,\
                                overwrite = False)
    
            ### Data on this specific star (to go to bayesian inference)
            obs_alpha34 = DATA_LBAND_now[6][4][0]
            sig_alpha34 = DATA_LBAND_now[6][4][1]
            obs_MW3 = DATA_LBAND_now[6][5][4]
            sig_MW3 = DATA_LBAND_now[6][5][5]


            ### 
            Nplots = np.nanmin([200,len(W_theta)])
            ### 
            xx = []
            yy = []
            for ielem in range(0,Nplots):
                point = W_theta[-1-ielem]
                xx.append(lrr.interpLinND(point,axis,vals_alphaW3W4,\
                        tp,allow_extrapolation))
                yy.append(lrr.interpLinND(point,axis,vals_MW3,\
                        tp,allow_extrapolation))
    
            fig=plt.figure(figsize=(6,6))
            ax=plt.subplot(1,1,1)
            plt.scatter(xx,yy,alpha=0.1)
            plt.errorbar(obs_alpha34,obs_MW3,xerr=sig_alpha34,yerr=sig_MW3,\
                color="black",linewidth=2.0)
            plt.xlabel("$\\alpha_{W3-W4}$")
            plt.ylabel("$M_{W3}\,\mathrm{[mag]}$")
            plt.xlim([-5.,1.6])
            plt.ylim([0.,-7.])
            fig.savefig(intructs_now[1][iinstr][1]+figures_folder+\
                    "CMDWISE__"+DATA_LBAND_now[0]+"__"+\
                    intructs_now[1][iinstr][2]+".png")
            plt.close()


        return
    

    ### This number must be chosen according to the RAM memory of YOUR computer.
    Nlines_max = 100000

    ### Getting instructions of operations to be applied to the data on
    ### Be stars.
    instructions = get_instructions(operations_on_stars)
    ### Reading the data on our Be stars
    data_folder, HDnames, Starnames, SIMBAD_Spt, YYYYMMDD_LBAND = \
                    read_data.List_Stars("stars")
    DATA_LBAND = read_data.returnDATA_LBAND()
    fluxhumphreys, EWhumphreys, GFWHMhumphreys, \
                fluxBra, EWBra, GFWHMBra, \
                fluxPfg, EWPfg, GFWHMPfg = \
                read_data.LBAND_lines_extract(DATA_LBAND)

    ### Now, this is the part in which the instructions are executed.
    for iinst in range(0,len(instructions)):
        intructs_now = [x for x in instructions[iinst]]
        istar = HDnames.index(intructs_now[0])
    
        ### Loop over the instructions for this specific Be star
        for iinow in range(0,len(intructs_now[1])):
            
            ### Instructions: bayesian inference with the observables
            ### alphaW3W4 and MW3.
            if intructs_now[1][iinow][0] == "P3_GRAPHS__BINF_ALPHAW3W4_W3":
                ### 'possible_file' will contain the name of the file
                ### to be read. 
                possible_file = intructs_now[1][iinow][1]+\
                        "BINF_ALPHAW3W4_W3__"+\
                        HDnames[istar]+"__"+intructs_now[1][iinow][2]+".out"
                ### 
                files_list = glob.glob(intructs_now[1][iinow][1]+"*")
                if possible_file in files_list:
                    ### 
                    ifile = files_list.index(possible_file)
                    filenow = files_list[ifile]
                    
                    print("")
                    print("P3_GRAPHS__BINF_ALPHAW3W4_W3 for \n"+filenow)
                    ### Reading the output file from bayesian analysis
                    f1 = open(filenow,"r")
                    linesf1 = f1.readlines()
                    f1.close()
                    ### 
                    MAF = float(linesf1[0].split()[1])
                    W_lnprobs = []
                    W_theta = []
                    ### 
                    for iline in range(1,np.nanmin([Nlines_max,len(linesf1)])):
                        W_lnprobs.append(float(linesf1[iline].split()[0]))
                        W_theta.append([
                                        float(linesf1[iline].split()[1]),
                                        float(linesf1[iline].split()[2]),
                                        float(linesf1[iline].split()[3]),
                                        float(linesf1[iline].split()[4]),
                                        float(linesf1[iline].split()[5])
                                        ])
                    ### 
                    DATA_LBAND_now = [x for x in DATA_LBAND[istar]]
                        
                    ### 
                    P3_GRAPHS__BINF_ALPHAW3W4_W3_procedure(intructs_now,\
                            DATA_LBAND_now,W_lnprobs,W_theta,MAF)















